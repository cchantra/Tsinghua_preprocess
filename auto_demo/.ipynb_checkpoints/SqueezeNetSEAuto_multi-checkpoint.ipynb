{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SqueezeNet SE Auto MultiInput\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "IlThs1IzTffo"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-27 14:23:21.886033: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    " import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "RNHB1XmeTffs",
    "outputId": "34026877-5066-43df-a067-b28766f8f775"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZNvdN17fTfft",
    "outputId": "75a4e445-a2bc-461d-e60f-8b52442a5ba2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.11\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZgUuveIZTffu",
    "outputId": "de3fc623-69c6-47ff-9d2b-803d809a9107"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version:  2.4.3\n",
      "Eager mode:  True\n",
      "WARNING:tensorflow:From /tmp/ipykernel_5472/902984835.py:20: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "GPU is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-27 14:23:24.671569: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-27 14:23:24.673167: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-03-27 14:23:24.674898: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-03-27 14:23:24.954981: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-27 14:23:24.956342: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s\n",
      "2022-03-27 14:23:24.956454: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-27 14:23:24.957082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s\n",
      "2022-03-27 14:23:24.957112: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-03-27 14:23:24.975916: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2022-03-27 14:23:24.975980: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-03-27 14:23:25.000365: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-03-27 14:23:25.006235: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-03-27 14:23:25.051541: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11\n",
      "2022-03-27 14:23:25.057305: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-03-27 14:23:25.058291: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-03-27 14:23:25.058401: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-27 14:23:25.059131: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-27 14:23:25.059819: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-27 14:23:25.060470: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-27 14:23:25.061054: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1\n",
      "2022-03-27 14:23:25.061604: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-03-27 14:23:26.110059: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-03-27 14:23:26.110094: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 \n",
      "2022-03-27 14:23:26.110101: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N N \n",
      "2022-03-27 14:23:26.110105: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   N N \n",
      "2022-03-27 14:23:26.119187: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-27 14:23:26.119873: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-27 14:23:26.120530: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-27 14:23:26.121153: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-27 14:23:26.121751: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/device:GPU:0 with 10769 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:01:00.0, compute capability: 6.1)\n",
      "2022-03-27 14:23:26.123513: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-27 14:23:26.124185: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-27 14:23:26.124798: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/device:GPU:1 with 10772 MB memory) -> physical GPU (device: 1, name: NVIDIA TITAN Xp, pci bus id: 0000:02:00.0, compute capability: 6.1)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    " \n",
    "\n",
    "\n",
    "import glob, os\n",
    "\n",
    "from tensorflow import keras\n",
    "import cv2\n",
    "\n",
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"GPU is\", \"available\" if tf.test.is_gpu_available() else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2KCQyYJqiYzj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EeSDAgTiiZIG"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FU_OYc58Tffv"
   },
   "source": [
    "# Tsinghua DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xep8Wa77jwdZ",
    "outputId": "7a5f7663-a2ce-40a8-b3ae-d746686da6e0"
   },
   "outputs": [],
   "source": [
    " \n",
    "source_dir = './TsinghuaFEDimages'\n",
    "dest_dir = './TsinghuaFED_class' # landmarks of each subject_emotion\n",
    "data_dir = dest_dir\n",
    "\n",
    "preprocess_dir = './TsinghuaFED_preprocess' # landmarks of each subject_emotion\n",
    "\n",
    "preprocess_dir2 = './TsinghuaFEDimages_Depth' # depth image of each subject_emotion\n",
    "\n",
    "\n",
    "emotion_class = ['fear','neutral','surprise','anger','content','disgust','sad','happy']\n",
    "EPOCH = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 171328\n",
      "-rwxrwxrwx. 1 root root 1746962 Aug 13  2021 O04F-76.jpg\n",
      "-rwxrwxrwx. 1 root root 1875478 Aug 13  2021 O07F-65.jpg\n",
      "-rwxrwxrwx. 1 root root 1649009 Aug 13  2021 O08M-65.jpg\n",
      "-rwxrwxrwx. 1 root root 1317050 Aug 13  2021 O09F-64.jpg\n",
      "-rwxrwxrwx. 1 root root 1702584 Aug 13  2021 O10F-60.jpg\n",
      "-rwxrwxrwx. 1 root root 1607263 Aug 13  2021 O12M-64.jpg\n",
      "-rwxrwxrwx. 1 root root 1813788 Aug 13  2021 O15M-69.jpg\n",
      "-rwxrwxrwx. 1 root root 1691498 Aug 13  2021 O16F-64.jpg\n",
      "-rwxrwxrwx. 1 root root 1698214 Aug 13  2021 O17M-69.jpg\n",
      "-rwxrwxrwx. 1 root root 1544710 Aug 13  2021 O19F-60.jpg\n",
      "-rwxrwxrwx. 1 root root 1693950 Aug 13  2021 O20M-65.jpg\n",
      "-rwxrwxrwx. 1 root root 1580593 Aug 13  2021 O21M-65.jpg\n",
      "-rwxrwxrwx. 1 root root 1429600 Aug 13  2021 O22F-61.jpg\n",
      "-rwxrwxrwx. 1 root root 1614210 Aug 13  2021 O23F-66.jpg\n",
      "-rwxrwxrwx. 1 root root 1513692 Aug 13  2021 O24F-62.jpg\n",
      "-rwxrwxrwx. 1 root root 1788130 Aug 13  2021 O26F-64.jpg\n",
      "-rwxrwxrwx. 1 root root 1648745 Aug 13  2021 O27F-65.jpg\n",
      "-rwxrwxrwx. 1 root root 1707565 Aug 13  2021 O28F-64.jpg\n",
      "-rwxrwxrwx. 1 root root 1785190 Aug 13  2021 O29F-63.jpg\n",
      "-rwxrwxrwx. 1 root root 1637257 Aug 13  2021 O34F-65.jpg\n",
      "-rwxrwxrwx. 1 root root 1675085 Aug 13  2021 O35M-66.jpg\n",
      "-rwxrwxrwx. 1 root root 1483289 Aug 13  2021 O38F-65.jpg\n",
      "-rwxrwxrwx. 1 root root 1540199 Aug 13  2021 O40F-61.jpg\n",
      "-rwxrwxrwx. 1 root root 1406204 Aug 13  2021 O41F-72.jpg\n",
      "-rwxrwxrwx. 1 root root 1719583 Aug 13  2021 O42M-75.jpg\n",
      "-rwxrwxrwx. 1 root root 1482655 Aug 13  2021 O43F-62.jpg\n",
      "-rwxrwxrwx. 1 root root 1522819 Aug 13  2021 O45F-65.jpg\n",
      "-rwxrwxrwx. 1 root root 2032812 Aug 13  2021 O47F-60.jpg\n",
      "-rwxrwxrwx. 1 root root 1612192 Aug 13  2021 O48F-65.jpg\n",
      "-rwxrwxrwx. 1 root root 1766224 Aug 13  2021 O49F-65.jpg\n",
      "-rwxrwxrwx. 1 root root 1749532 Aug 13  2021 O50M-65.jpg\n",
      "-rwxrwxrwx. 1 root root 1678159 Aug 13  2021 O51F-60.jpg\n",
      "-rwxrwxrwx. 1 root root 1621563 Aug 13  2021 O52F-62.jpg\n",
      "-rwxrwxrwx. 1 root root 1693466 Aug 13  2021 O53F-64.jpg\n",
      "-rwxrwxrwx. 1 root root 1534333 Aug 13  2021 O55M-64.jpg\n",
      "-rwxrwxrwx. 1 root root 1528893 Aug 13  2021 O56F-65.jpg\n",
      "-rwxrwxrwx. 1 root root 1596451 Aug 13  2021 O58M-64.jpg\n",
      "-rwxrwxrwx. 1 root root 1464991 Aug 13  2021 O59M-65.jpg\n",
      "-rwxrwxrwx. 1 root root 1123977 Aug 13  2021 O63M-61.jpg\n",
      "-rwxrwxrwx. 1 root root 1161357 Aug 13  2021 O64M-65.jpg\n",
      "-rwxrwxrwx. 1 root root 1533904 Aug 13  2021 O65M.jpg\n",
      "-rwxrwxrwx. 1 root root 1401123 Aug 13  2021 O66M.jpg\n",
      "-rwxrwxrwx. 1 root root 1549129 Aug 13  2021 O67M.jpg\n",
      "-rwxrwxrwx. 1 root root 1597234 Aug 13  2021 O68M.jpg\n",
      "-rwxrwxrwx. 1 root root 1429148 Aug 13  2021 O69M.jpg\n",
      "-rwxrwxrwx. 1 root root 1593769 Aug 13  2021 O70M.jpg\n",
      "-rwxrwxrwx. 1 root root 1706977 Aug 13  2021 O71M.jpg\n",
      "-rwxrwxrwx. 1 root root 1702795 Aug 13  2021 Y10M-22.jpg\n",
      "-rwxrwxrwx. 1 root root 1590905 Aug 13  2021 Y11M-20.jpg\n",
      "-rwxrwxrwx. 1 root root 1805614 Aug 13  2021 Y12F-18.jpg\n",
      "-rwxrwxrwx. 1 root root 1684771 Aug 13  2021 Y13F-20.jpg\n",
      "-rwxrwxrwx. 1 root root 1801828 Aug 13  2021 Y14F-21.jpg\n",
      "-rwxrwxrwx. 1 root root 1659332 Aug 13  2021 Y15M-20.jpg\n",
      "-rwxrwxrwx. 1 root root 1579929 Aug 13  2021 Y16M-21.jpg\n",
      "-rwxrwxrwx. 1 root root 1761580 Aug 13  2021 Y17F-33.jpg\n",
      "-rwxrwxrwx. 1 root root 1413066 Aug 13  2021 Y18F-18.jpg\n",
      "-rwxrwxrwx. 1 root root 1430794 Aug 13  2021 Y19F-19.jpg\n",
      "-rwxrwxrwx. 1 root root 1652219 Aug 13  2021 Y1M-19.jpg\n",
      "-rwxrwxrwx. 1 root root 1682392 Aug 13  2021 Y21M-21.jpg\n",
      "-rwxrwxrwx. 1 root root 1541122 Aug 13  2021 Y22F-30.jpg\n",
      "-rwxrwxrwx. 1 root root 1666255 Aug 13  2021 Y23F-30.jpg\n",
      "-rwxrwxrwx. 1 root root 1701599 Aug 13  2021 Y24M-19_1.jpg\n",
      "-rwxrwxrwx. 1 root root 1697098 Aug 13  2021 Y25F-33_2.jpg\n",
      "-rwxrwxrwx. 1 root root 1557195 Aug 13  2021 Y26F-32.jpg\n",
      "-rwxrwxrwx. 1 root root 1592176 Aug 13  2021 Y27M-23.jpg\n",
      "-rwxrwxrwx. 1 root root 1654354 Aug 13  2021 Y28M-20.jpg\n",
      "-rwxrwxrwx. 1 root root 1685731 Aug 13  2021 Y29M-21.jpg\n",
      "-rwxrwxrwx. 1 root root 1684144 Aug 13  2021 Y2M-21.jpg\n",
      "-rwxrwxrwx. 1 root root 1561430 Aug 13  2021 Y30M-25.jpg\n",
      "-rwxrwxrwx. 1 root root 1619019 Aug 13  2021 Y31F-30.jpg\n",
      "-rwxrwxrwx. 1 root root 1642140 Aug 13  2021 Y32F-20.jpg\n",
      "-rwxrwxrwx. 1 root root 1748383 Aug 13  2021 Y33M-25.jpg\n",
      "-rwxrwxrwx. 1 root root 1480964 Aug 13  2021 Y35M-20.jpg\n",
      "-rwxrwxrwx. 1 root root 1663119 Aug 13  2021 Y36M-30.jpg\n",
      "-rwxrwxrwx. 1 root root 1430109 Aug 13  2021 Y37F-32.jpg\n",
      "-rwxrwxrwx. 1 root root 1692307 Aug 13  2021 Y38F-24.jpg\n",
      "-rwxrwxrwx. 1 root root 1535989 Aug 13  2021 Y39F-25.jpg\n",
      "-rwxrwxrwx. 1 root root 1604876 Aug 13  2021 Y3F-20.jpg\n",
      "-rwxrwxrwx. 1 root root 1532113 Aug 13  2021 Y40F-28.jpg\n",
      "-rwxrwxrwx. 1 root root 1523484 Aug 13  2021 Y41M-19.jpg\n",
      "-rwxrwxrwx. 1 root root 1455787 Aug 13  2021 Y42F-20.jpg\n",
      "-rwxrwxrwx. 1 root root 1719432 Aug 13  2021 Y44M-26.jpg\n",
      "-rwxrwxrwx. 1 root root 1691137 Aug 13  2021 Y46M-18.jpg\n",
      "-rwxrwxrwx. 1 root root 1555966 Aug 13  2021 Y47M-23.jpg\n",
      "-rwxrwxrwx. 1 root root 1618886 Aug 13  2021 Y48F-23.jpg\n",
      "-rwxrwxrwx. 1 root root 1539027 Aug 13  2021 Y49M-23.jpg\n",
      "-rwxrwxrwx. 1 root root 1640564 Aug 13  2021 Y4F-19.jpg\n",
      "-rwxrwxrwx. 1 root root 1457687 Aug 13  2021 Y50F-24.jpg\n",
      "-rwxrwxrwx. 1 root root 1539788 Aug 13  2021 Y51F-23.jpg\n",
      "-rwxrwxrwx. 1 root root 1445582 Aug 13  2021 Y52F-21.jpg\n",
      "-rwxrwxrwx. 1 root root 1563375 Aug 13  2021 Y53M-23.jpg\n",
      "-rwxrwxrwx. 1 root root 1424298 Aug 13  2021 Y54M-26.jpg\n",
      "-rwxrwxrwx. 1 root root 1651220 Aug 13  2021 Y55M-24.jpg\n",
      "-rwxrwxrwx. 1 root root 1531456 Aug 13  2021 Y56M-24.jpg\n",
      "-rwxrwxrwx. 1 root root 1439909 Aug 13  2021 Y57M-23.jpg\n",
      "-rwxrwxrwx. 1 root root 1674297 Aug 13  2021 Y58M-22.jpg\n",
      "-rwxrwxrwx. 1 root root 1529105 Aug 13  2021 Y59F-23.jpg\n",
      "-rwxrwxrwx. 1 root root 1301964 Aug 13  2021 Y5F-24.jpg\n",
      "-rwxrwxrwx. 1 root root 1907661 Aug 13  2021 Y60M-24.jpg\n",
      "-rwxrwxrwx. 1 root root 1412050 Aug 13  2021 Y65F.jpg\n",
      "-rwxrwxrwx. 1 root root 1386757 Aug 13  2021 Y66F-26.jpg\n",
      "-rwxrwxrwx. 1 root root 1518313 Aug 13  2021 Y67M.jpg\n",
      "-rwxrwxrwx. 1 root root 1516968 Aug 13  2021 Y68M.jpg\n",
      "-rwxrwxrwx. 1 root root 1337229 Aug 13  2021 Y69F.jpg\n",
      "-rwxrwxrwx. 1 root root 1639960 Aug 13  2021 Y6F-23.jpg\n",
      "-rwxrwxrwx. 1 root root 1556237 Aug 13  2021 Y71F.jpg\n",
      "-rwxrwxrwx. 1 root root 1650044 Aug 13  2021 Y72F.jpg\n",
      "-rwxrwxrwx. 1 root root 1566605 Aug 13  2021 Y74M.jpg\n",
      "-rwxrwxrwx. 1 root root 1514592 Aug 13  2021 Y75M.jpg\n",
      "-rwxrwxrwx. 1 root root 1626937 Aug 13  2021 Y8M-27.jpg\n"
     ]
    }
   ],
   "source": [
    "!ls -l ./TsinghuaFED_class/sad/ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t-jxpFz75r4n"
   },
   "source": [
    "# Load CSV feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "RHMXzHh0tb9p"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def load_csv_dataset(data_folder, dir):\n",
    "\n",
    "    file_list = data_folder+'/train.csv'\n",
    "\n",
    "    f = open(file_list)\n",
    "    text = f.read()\n",
    "    lines = text.split()\n",
    "    train_files = []\n",
    "    train_labels = []\n",
    "\n",
    "    train_array = []\n",
    "\n",
    "    for l in lines:\n",
    "        data = l.split(',')\n",
    "        name, _ = os.path.splitext(data[0])\n",
    "        pathname = dir+'/'+name+'_landmark.csv'\n",
    "\n",
    "        label = int(data[1])\n",
    "        csv_f = open(pathname)\n",
    "        data = csv_f.read()\n",
    "        landmarks = data.split('\\n')\n",
    "        points_array = []\n",
    "        for lm in landmarks:\n",
    "\n",
    "            points = lm.rstrip().split(',')\n",
    "\n",
    "            if points[0] == '':\n",
    "                continue\n",
    "            x, y, z = float(points[0]), float(points[1]), float(points[2])\n",
    "            points_array.append([x, y, z])\n",
    "        train_files.append(pathname)\n",
    "        train_labels.append(label)\n",
    "        train_array.append(points_array)\n",
    "\n",
    "    file_list = data_folder+'/test.csv'\n",
    "\n",
    "    f = open(file_list)\n",
    "    text = f.read()\n",
    "    lines = text.split()\n",
    "    test_files = []\n",
    "    test_labels = []\n",
    "\n",
    "    test_array = []\n",
    "\n",
    "    for l in lines:\n",
    "        data = l.split(',')\n",
    "        name, _ = os.path.splitext(data[0])\n",
    "        pathname = dir+'/'+name+'_landmark.csv'\n",
    "        label = int(data[1])\n",
    "\n",
    "        csv_f = open(pathname)\n",
    "        data = csv_f.read()\n",
    "        landmarks = data.split('\\n')\n",
    "        points_array = []\n",
    "        for lm in landmarks:\n",
    "            points = lm.rstrip().split(',')\n",
    "            if points[0] == '':\n",
    "                continue\n",
    "            x, y, z = float(points[0]), float(points[1]), float(points[2])\n",
    "            points_array.append([x, y, z])\n",
    "        test_files.append(pathname)\n",
    "        test_array.append(points_array)\n",
    "        test_labels.append(label)\n",
    "\n",
    "    return train_array, train_labels, test_array, test_labels\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_array1, train_labels, test_array1, test_labels = load_csv_dataset(\n",
    "    dest_dir, preprocess_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WwZKrBnSBgJM",
    "outputId": "a111e43f-181c-40b8-f2e1-5bac4eefe4d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "468"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_array1[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Wsti-0tSBdxi"
   },
   "outputs": [],
   "source": [
    "train_data = np.array (train_array1)\n",
    "X_test =    np.array(test_array1)\n",
    "y_test = np.array(test_labels)\n",
    "X_train1 = np.array(train_array1)\n",
    "y_train1 = np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z4HUyc8wBObL",
    "outputId": "50017ec2-c06e-49df-dcac-4e89a7ff544c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(175, 468, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AEQLjbP3ulyF",
    "outputId": "84e6bbd2-341e-4d25-e020-74e090ff836c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 468, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k6-fqiybHmFQ"
   },
   "source": [
    "# Load Depth Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 453
    },
    "id": "ICK5CRE3HwQF",
    "outputId": "97d4dadc-b02f-4187-d4a0-4463da9e0dc4"
   },
   "outputs": [],
   "source": [
    "\n",
    "# load image depth\n",
    "\n",
    "#source_dir = './TsinghuaFEDimages'\n",
    "# data_dir = './TsinghuaFED_class' # landmarks of each subject_emotion\n",
    "\n",
    "emotion_class = ['fear', 'neutral', 'surprise',\n",
    "                 'anger', 'content', 'disgust', 'sad', 'happy']\n",
    "\n",
    "IMG_WIDTH = 224\n",
    "IMG_HEIGHT = 224\n",
    "nb_classes = len(emotion_class)\n",
    "\n",
    "\n",
    "def load_depth_dataset(data_folder,   dir):\n",
    "\n",
    "    img_list = data_folder+'/train.csv'\n",
    " \n",
    "    f = open(img_list)\n",
    "    text = f.read()\n",
    "    lines = text.split()\n",
    "\n",
    "    train_labels = []\n",
    "\n",
    "    # for l in lines:\n",
    "    #  data = l.split(',')\n",
    "    #  train_img_files.append(img_dir+'/'+data[0])\n",
    "    #   train_labels.append(int(data[1]))\n",
    "    train_array = []\n",
    "\n",
    "    img_train_array = []\n",
    "    for l in lines:\n",
    "\n",
    "        data = l.split(',')\n",
    "        name, _ = os.path.splitext(data[0])\n",
    "        pathname = dir+'/'+name+'_Depth.png'\n",
    "\n",
    "        image = cv2.imread(pathname, cv2.COLOR_BGR2RGB)\n",
    "#         print(pathname)\n",
    "        if image.shape[0] == 0:\n",
    "            print(\"not found\")\n",
    "            continue\n",
    "\n",
    "        image = cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH),\n",
    "                           interpolation=cv2.INTER_AREA)\n",
    "        image = np.array(image)\n",
    "        image = image.astype('float32')\n",
    "        image /= 255\n",
    "        img_train_array.append(image)\n",
    "        train_labels.append(int(data[1]))\n",
    "\n",
    "    # ---------------------\n",
    "    img_list = data_folder+'/test.csv'\n",
    "\n",
    "    f = open(img_list)\n",
    "    text = f.read()\n",
    "    lines = text.split()\n",
    "\n",
    "    test_labels = []\n",
    "\n",
    "    img_test_array = []\n",
    "\n",
    "    for l in lines:\n",
    "\n",
    "        data = l.split(',')\n",
    "        name, _ = os.path.splitext(data[0])\n",
    "        pathname = dir+'/'+name+'_Depth.png'\n",
    "\n",
    "#         print(pathname)\n",
    "\n",
    "        image = cv2.imread(pathname, cv2.COLOR_BGR2RGB)\n",
    "        if image.shape[0] == 0:\n",
    "            print(\"not found\")\n",
    "            continue\n",
    "\n",
    "        image = cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH),\n",
    "                           interpolation=cv2.INTER_AREA)\n",
    "        image = np.array(image)\n",
    "        image = image.astype('float32')\n",
    "        image /= 255\n",
    "        img_test_array.append(image)\n",
    "        test_labels.append(int(data[1]))\n",
    "\n",
    "    return img_train_array,  train_labels, img_test_array,  test_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load data set\n",
    "x_train1,  y_train, x_test1, y_test = load_depth_dataset(\n",
    "    data_dir, preprocess_dir2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(175, 224, 224, 3)\n",
      "(700, 224, 224, 3)\n",
      "(175, 224, 224, 3)\n",
      "(175, 8) (700, 8)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "x_test1 = np.array(x_test1)\n",
    "x_test1.reshape(-1, IMG_HEIGHT, IMG_WIDTH, 3)\n",
    "\n",
    "print(x_test1.shape)\n",
    "\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "x_train1 = np.array(x_train1)\n",
    "x_train1.reshape(-1, IMG_HEIGHT, IMG_WIDTH, 3)\n",
    "\n",
    "\n",
    "print(x_train1.shape)\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "x_train = x_train1\n",
    "# x_train = np.expand_dims(x_train1, -1)\n",
    "\n",
    "\n",
    "x_test = x_test1\n",
    "# x_test = np.expand_dims(x_test1, -1)\n",
    "print(x_test.shape)\n",
    "\n",
    "y_test = keras.utils.to_categorical(y_test, len(emotion_class))\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, len(emotion_class))\n",
    "\n",
    "print(y_test.shape, y_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vHn8AGu05xjQ"
   },
   "source": [
    "# Load Image and CSV Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "415XRj1MTffx"
   },
   "outputs": [],
   "source": [
    "\n",
    "#source_dir = './TsinghuaFEDimages'\n",
    "# data_dir = './TsinghuaFED_class' # landmarks of each subject_emotion\n",
    "\n",
    "emotion_class = ['fear', 'neutral', 'surprise',\n",
    "                 'anger', 'content', 'disgust', 'sad', 'happy']\n",
    "\n",
    "IMG_WIDTH = 224\n",
    "IMG_HEIGHT = 224\n",
    "nb_classes = len(emotion_class)\n",
    "\n",
    "\n",
    "def load_image_csv_dataset(data_folder, img_dir, dir):\n",
    "\n",
    "    img_list = data_folder+'/train.csv'\n",
    "\n",
    "    f = open(img_list)\n",
    "    text = f.read()\n",
    "    lines = text.split()\n",
    "    train_img_files = []\n",
    "    train_labels = []\n",
    "    train_files = []\n",
    "\n",
    "    # for l in lines:\n",
    "    #  data = l.split(',')\n",
    "    #  train_img_files.append(img_dir+'/'+data[0])\n",
    "    #   train_labels.append(int(data[1]))\n",
    "    train_array = []\n",
    "\n",
    "    for l in lines:\n",
    "        data = l.split(',')\n",
    "        name, _ = os.path.splitext(data[0])\n",
    "        pathname = dir+'/'+name+'_landmark.csv'\n",
    "        train_img_files.append(img_dir+'/'+data[0])\n",
    "        train_files.append(pathname)\n",
    "        train_labels.append(int(data[1]))\n",
    "\n",
    "    img_train_array = []\n",
    "    for filename, label in zip(train_img_files, train_labels):\n",
    "\n",
    "        image = cv2.imread(filename, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH),\n",
    "                           interpolation=cv2.INTER_AREA)\n",
    "        image = np.array(image)\n",
    "        image = image.astype('float32')\n",
    "        image /= 255\n",
    "        img_train_array.append(image)\n",
    "\n",
    "    for filename, label in zip(train_files, train_labels):\n",
    "\n",
    "        csv_f = open(filename)\n",
    "        data = csv_f.read()\n",
    "        landmarks = data.split('\\n')\n",
    "        points_array = []\n",
    "        for lm in landmarks:\n",
    "\n",
    "            points = lm.rstrip().split(',')\n",
    "\n",
    "            if points[0] == '':\n",
    "                continue\n",
    "            x, y, z = float(points[0]), float(points[1]), float(points[2])\n",
    "            points_array.extend([x, y, z])\n",
    "\n",
    "        train_array.append(points_array)\n",
    "\n",
    "    # ---------------------\n",
    "    img_list = data_folder+'/test.csv'\n",
    "\n",
    "    f = open(img_list)\n",
    "    text = f.read()\n",
    "    lines = text.split()\n",
    "    test_img_files = []\n",
    "    test_labels = []\n",
    "    test_files = []\n",
    "    for l in lines:\n",
    "        data = l.split(',')\n",
    "        name, _ = os.path.splitext(data[0])\n",
    "        pathname = dir+'/'+name+'_landmark.csv'\n",
    "        test_files.append(pathname)\n",
    "        test_img_files.append(img_dir+'/'+data[0])\n",
    "        test_labels.append(int(data[1]))\n",
    "\n",
    "    img_test_array = []\n",
    "\n",
    "    test_array = []\n",
    "\n",
    "    for filename, label in zip(test_files, test_labels):\n",
    "\n",
    "        csv_f = open(filename)\n",
    "        data = csv_f.read()\n",
    "        landmarks = data.split('\\n')\n",
    "        points_array = []\n",
    "        for lm in landmarks:\n",
    "            points = lm.rstrip().split(',')\n",
    "            if points[0] == '':\n",
    "                continue\n",
    "            x, y, z = float(points[0]), float(points[1]), float(points[2])\n",
    "            points_array.extend([x, y, z])\n",
    "        test_array.append(points_array)\n",
    "\n",
    "    for filename, label in zip(test_img_files, test_labels):\n",
    "\n",
    "        image = cv2.imread(filename, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        image = cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH),\n",
    "                           interpolation=cv2.INTER_AREA)\n",
    "        image = np.array(image)\n",
    "        image = image.astype('float32')\n",
    "        image /= 255\n",
    "        img_test_array.append(image)\n",
    "\n",
    "    return img_train_array, train_array, train_labels, img_test_array, test_array, test_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load data set\n",
    "x_train1, x_train2, y_train, x_test1, x_test2, y_test = load_image_csv_dataset(\n",
    "    data_dir, source_dir, preprocess_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(175, 224, 224, 3) (700, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "x_test1 = np.array(x_test1)\n",
    "x_test1.reshape(-1, IMG_HEIGHT, IMG_WIDTH, 3)\n",
    "y_test = np.array(y_test)\n",
    "x_train1 = np.array(x_train1)\n",
    "x_train1.reshape(-1, IMG_HEIGHT, IMG_WIDTH, 3)\n",
    "\n",
    "print(x_test1.shape, x_train1.shape)\n",
    "\n",
    "# y_train = np.array(y_train)\n",
    "# x_train1 = np.expand_dims(x_train1, -1)\n",
    "# x_test1 = np.expand_dims(x_test1, -1)\n",
    "# y_test = keras.utils.to_categorical(y_test, len(emotion_class))\n",
    "# y_train = keras.utils.to_categorical(y_train, len(emotion_class))\n",
    "\n",
    "# x_train2 = np.array(x_train2)\n",
    "# X_test2 = np.array(x_test2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "r5ea2VtyTffy",
    "outputId": "b67fe7db-30b1-4f0e-d9c2-0ec16d82e01c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(175,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = './TsinghuaFED_class/anger/O04F-76.jpg'\n",
    "image= cv2.imread( fname, cv2.COLOR_BGR2RGB)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 1500, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " autokeras_test1.py\n",
      " autokeras_Tsinghua.ipynb\n",
      " auto_model\n",
      " autosklearn.ipynb\n",
      " auto_SqueezeNet_input_Tsinghua2-Copy1.ipynb\n",
      " auto_SqueezeNet_input_Tsinghua2.ipynb\n",
      " auto_SqueezeNet_input_Tsinghua.ipynb\n",
      " auto_SqueezeNet.ipynb\n",
      " auto_SqueezeNetSE01.ipynb\n",
      " auto_SqueezeNetSE.ipynb\n",
      " auto_SqueezeNet-Tsinghua.ipynb\n",
      " auto_SqueezeNet-Tsinghua-multi.ipynb\n",
      " auto_squeezeSE.py\n",
      "'boxing*'\n",
      " boxing1.jpg\n",
      " boxing2.jpeg\n",
      " EfficientNet\n",
      " EmotionW\n",
      " extract_68landmarks.ipynb\n",
      " extract_names.ipynb\n",
      " image_classification.ipynb\n",
      " image_classifier\n",
      " imagenet_data\n",
      " ImageNet-Datasets-Downloader\n",
      " imagenet.tar.gz\n",
      " Image_retraining_media_pipe.ipynb\n",
      " keras-tuner.ipynb\n",
      " keras_tuner.ipynb\n",
      " mediapipe_face_mesh2.ipynb\n",
      " mediapipe_multi_pose.ipynb\n",
      " MobileNet\n",
      " model_all.py\n",
      " model_Tsinghua_mobile.json\n",
      " muay.mp4\n",
      " my_dir\n",
      " mytest3_dir\n",
      " mytest4_dir\n",
      " mytest5_dir\n",
      " mytest_dir\n",
      " out\n",
      " out.txt\n",
      " __pycache__\n",
      " RAF-AU\n",
      " reading_large_img.ipynb\n",
      " ResNet\n",
      " RGBD\n",
      " RGBD_models.py\n",
      " save_Tsinghua_mobile.h5\n",
      " SFEW\n",
      " squeezenet.ipynb\n",
      " SqueezeNetSEAuto_01_Imagenet-Copy1.ipynb\n",
      " SqueezeNetSEAuto_01_Imagenet.ipynb\n",
      " SqueezeNetSEAuto01.ipynb\n",
      " SqueezeNetSEAuto_01_TSinghua-Copy2.ipynb\n",
      " SqueezeNetSEAuto04.ipynb\n",
      " SqueezeNetSEAuto1.ipynb\n",
      " test_multigpu.ipynb\n",
      " TsinghuaFED_class\n",
      " TsinghuaFED_class.zip\n",
      " TsinghuaFEDimages\n",
      " TsinghuaFEDimages_Depth\n",
      " TsinghuaFEDimages_Depth.tar.gz\n",
      " TsinghuaFED_preprocess\n",
      " TsinghuaFED_preprocess-20210823T022127Z-001.zip\n",
      " Untitled.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load image and depth image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#source_dir = './TsinghuaFEDimages'\n",
    "# data_dir = './TsinghuaFED_class' # landmarks of each subject_emotion\n",
    "\n",
    "emotion_class = ['fear', 'neutral', 'surprise',\n",
    "                 'anger', 'content', 'disgust', 'sad', 'happy']\n",
    "\n",
    "IMG_WIDTH = 224\n",
    "IMG_HEIGHT = 224\n",
    "nb_classes = len(emotion_class)\n",
    "\n",
    "\n",
    "def load_image_depth_dataset(data_folder, img_dir, dir):\n",
    "\n",
    "    img_list = data_folder+'/train.csv'\n",
    "\n",
    "    f = open(img_list)\n",
    "    text = f.read()\n",
    "    lines = text.split()\n",
    "    train_img_files = []\n",
    "    train_labels = []\n",
    "    train_files = []\n",
    "\n",
    "    # for l in lines:\n",
    "    #  data = l.split(',')\n",
    "    #  train_img_files.append(img_dir+'/'+data[0])\n",
    "    #   train_labels.append(int(data[1]))\n",
    "    train_array = []\n",
    "\n",
    "    for l in lines:\n",
    "\n",
    "        data = l.split(',')\n",
    "        name, _ = os.path.splitext(data[0])\n",
    "        pathname = dir+'/'+name+'_Depth.png'\n",
    "\n",
    "        image = cv2.imread(pathname, cv2.COLOR_BGR2RGB)\n",
    "#         print(pathname)\n",
    "        if image.shape[0] == 0:\n",
    "            print(\"depth not found\")\n",
    "            continue\n",
    "\n",
    "        train_img_files.append(img_dir+'/'+data[0])\n",
    "        train_files.append(pathname)\n",
    "        train_labels.append(int(data[1]))\n",
    "\n",
    "    img_train_array = []\n",
    "    depth_train_array = []\n",
    "    for filename, depth_file, label in zip(train_img_files, train_files, train_labels):\n",
    "\n",
    "        image = cv2.imread(filename, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH),\n",
    "                           interpolation=cv2.INTER_AREA)\n",
    "        image = np.array(image)\n",
    "        image = image.astype('float32')\n",
    "        image /= 255\n",
    "        img_train_array.append(image)\n",
    "\n",
    "        dimage = cv2.imread(depth_file, cv2.COLOR_BGR2RGB)\n",
    "        dimage = cv2.resize(dimage, (IMG_HEIGHT, IMG_WIDTH),\n",
    "                            interpolation=cv2.INTER_AREA)\n",
    "        dimage = np.array(dimage)\n",
    "        dimage = dimage.astype('float32')\n",
    "        dimage /= 255\n",
    "        depth_train_array.append(dimage)\n",
    "\n",
    "    # ---------------------\n",
    "    img_list = data_folder+'/test.csv'\n",
    "\n",
    "    f = open(img_list)\n",
    "    text = f.read()\n",
    "    lines = text.split()\n",
    "    test_img_files = []\n",
    "    test_labels = []\n",
    "    test_files = []\n",
    "    for l in lines:\n",
    "        data = l.split(',')\n",
    "        name, _ = os.path.splitext(data[0])\n",
    "        pathname = dir+'/'+name+'_Depth.png'\n",
    "\n",
    "        image = cv2.imread(pathname, cv2.COLOR_BGR2RGB)\n",
    "#         print(pathname)\n",
    "        if image.shape[0] == 0:\n",
    "            print(\"depth not found\")\n",
    "            continue\n",
    "\n",
    "        test_files.append(pathname)\n",
    "        test_img_files.append(img_dir+'/'+data[0])\n",
    "        test_labels.append(int(data[1]))\n",
    "\n",
    "    img_test_array = []\n",
    "\n",
    "    test_array = []\n",
    "\n",
    "    depth_test_array = []\n",
    "\n",
    "    for filename, depth_file, label in zip(test_img_files, test_files, test_labels):\n",
    "\n",
    "        image = cv2.imread(filename, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        image = cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH),\n",
    "                           interpolation=cv2.INTER_AREA)\n",
    "        image = np.array(image)\n",
    "        image = image.astype('float32')\n",
    "        image /= 255\n",
    "        img_test_array.append(image)\n",
    "\n",
    "        dimage = cv2.imread(depth_file, cv2.COLOR_BGR2RGB)\n",
    "        dimage = cv2.resize(dimage, (IMG_HEIGHT, IMG_WIDTH),\n",
    "                            interpolation=cv2.INTER_AREA)\n",
    "        dimage = np.array(dimage)\n",
    "        dimage = dimage.astype('float32')\n",
    "        dimage /= 255\n",
    "        depth_test_array.append(dimage)\n",
    "\n",
    "    return img_train_array, depth_train_array, train_labels, img_test_array, depth_test_array, test_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load data set\n",
    "x_train1, x_train2, y_train, x_test1, x_test2, y_test = load_image_depth_dataset(\n",
    "    data_dir, source_dir, preprocess_dir2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.972549  , 0.99215686, 0.98039216],\n",
       "         [0.44705883, 0.8666667 , 0.61960787],\n",
       "         [0.49803922, 0.8784314 , 0.65882355],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[0.8745098 , 0.96862745, 0.9137255 ],\n",
       "         [0.29411766, 0.83137256, 0.5176471 ],\n",
       "         [0.3372549 , 0.84313726, 0.54901963],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[0.6117647 , 0.90588236, 0.7372549 ],\n",
       "         [0.29411766, 0.83137256, 0.5176471 ],\n",
       "         [0.29411766, 0.83137256, 0.5176471 ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]]],\n",
       "\n",
       "\n",
       "       [[[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [0.8745098 , 0.96862745, 0.9137255 ],\n",
       "         [0.72156864, 0.93333334, 0.8117647 ],\n",
       "         [0.44705883, 0.8666667 , 0.61960787]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [0.29411766, 0.83137256, 0.5176471 ],\n",
       "         [0.29411766, 0.83137256, 0.5176471 ],\n",
       "         [0.4745098 , 0.8745098 , 0.6431373 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]]],\n",
       "\n",
       "\n",
       "       [[[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]]],\n",
       "\n",
       "\n",
       "       [[[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]]],\n",
       "\n",
       "\n",
       "       [[[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [0.9137255 , 0.89411765, 0.8392157 ],\n",
       "         [0.5568628 , 0.49803922, 0.15294118],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [0.9843137 , 0.98039216, 0.972549  ],\n",
       "         [0.6509804 , 0.60784316, 0.33333334],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [0.9490196 , 0.9411765 , 0.9019608 ],\n",
       "         [0.6       , 0.56078434, 0.23529412],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]]]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test1 = np.array(x_test1)\n",
    "x_test1.reshape(-1, IMG_HEIGHT, IMG_WIDTH, 3)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "x_train1 = np.array(x_train1)\n",
    "x_train1.reshape(-1, IMG_HEIGHT, IMG_WIDTH, 3)\n",
    "\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "# x_train1 = np.expand_dims(x_train1, -1)\n",
    "# x_test1 = np.expand_dims(x_test1, -1)\n",
    "\n",
    "y_test = keras.utils.to_categorical(y_test, len(emotion_class))\n",
    "y_train = keras.utils.to_categorical(y_train, len(emotion_class))\n",
    "\n",
    "x_train2 = np.array(x_train2)\n",
    "x_train2.reshape(-1, IMG_HEIGHT, IMG_WIDTH, 3)\n",
    "# x_train2 = np.expand_dims(x_train2, -1)\n",
    "\n",
    "x_test2 = np.array(x_test2)\n",
    "x_test2.reshape(-1, IMG_HEIGHT, IMG_WIDTH, 3)\n",
    "# x_test2 = np.expand_dims(x_test2, -1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 224, 224, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(175, 224, 224, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 224, 224, 3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(175, 224, 224, 3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test2.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 8)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(175, 8)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init Neptune "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neptunecontrib.monitoring.kerastuner as npt_utils\n",
    "\n",
    " \n",
    "import neptune\n",
    "neptune.init(project_qualified_name='cchantra/keras-tuner',api_token='eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiI0M2NkYzQyZC01M2MzLTRhYjQtOTQ5Ny05NGY0NTU5MmU2NjUifQ==') # your credentials\n",
    "\n",
    "\n",
    "from keras_tuner import HyperParameters, Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LLf0LzG41JSW"
   },
   "source": [
    "#  AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "rpytkc_m1Ieb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<autokeras.auto_model.AutoModel at 0x7f94a2e7a430>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The user specifies the high-level architecture.\n",
    "import autokeras as ak\n",
    "image_input = ak.ImageInput()\n",
    "image_output = ak.ImageBlock()(image_input)\n",
    "text_input = ak.TextInput()\n",
    "text_output = ak.TextBlock()(text_input)\n",
    "output = ak.Merge()([image_output, text_output])\n",
    "classification_output = ak.ClassificationHead()(output)\n",
    "regression_output = ak.RegressionHead()(output)\n",
    "ak.AutoModel(\n",
    "    inputs=[image_input, text_input],\n",
    "    outputs=[classification_output, regression_output]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RgzPcpTypYjl"
   },
   "source": [
    "# Multilayer perceptron Model\n",
    "\n",
    "for csv features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "z_Ap6tTvpPf1"
   },
   "outputs": [],
   "source": [
    "# multilayer perceptron\n",
    "from keras_tuner import HyperModel\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "class MultilayerModel(HyperModel):\n",
    "    def __init__(self, classes):\n",
    "        self.classes = classes\n",
    "\n",
    "    def build(self, hp):\n",
    "\n",
    "        input_csv = tf.keras.layers.Input(shape=(468, 3))  # size of CSV\n",
    "\n",
    "        num = hp.Choice('num_layers', [4, 5, 6, 7, 8, 9, 10], default=4)\n",
    "        for i in range(num):\n",
    "            num_hidden = hp.Choice(\n",
    "                'hidden'+str(i), [16, 32, 64, 128, 256, 512], default=16)\n",
    "            if i == 0:\n",
    "                x = layers.Flatten()(input_csv)\n",
    "\n",
    "            x = layers.Dense(num_hidden, activation=\"relu\")(x)\n",
    "\n",
    "        # last layers\n",
    "        x = layers.Dense(self.classes, activation=\"relu\")(x)\n",
    "\n",
    "        #model = keras.Model(inputs=[x.input, y.input], outputs=z)\n",
    "\n",
    "        #x =  output(x, self.classes)\n",
    "        model = keras.Model(inputs=[input_csv], outputs=x)\n",
    "        optimizer = hp.Choice(\"optimizer\", [\"adam\", \"sgd\", \"RMSprop\"])\n",
    "        model.compile(\n",
    "            optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "        )\n",
    "        model.summary()\n",
    "        return model\n",
    "\n",
    "    \n",
    "# multilayer perceptron\n",
    "from keras_tuner import HyperModel\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "class MultilayerModel_sp(HyperModel):\n",
    "    def __init__(self, classes):\n",
    "        self.classes = classes\n",
    "\n",
    "    def build(self, hp):\n",
    "\n",
    "        input_csv = tf.keras.layers.Input(shape=(468, 3))  # size of CSV\n",
    "\n",
    "        num = hp.Choice('num_layers', [4, 5, 6, 7, 8, 9, 10], default=4)\n",
    "        for i in range(num):\n",
    "            num_hidden = hp.Choice(\n",
    "                'hidden'+str(i), [16, 32, 64, 128, 256, 512], default=16)\n",
    "            if i == 0:\n",
    "                x = layers.Flatten()(input_csv)\n",
    "\n",
    "            x = layers.Dense(num_hidden, activation=\"relu\")(x)\n",
    "\n",
    "        # last layers\n",
    "        x = layers.Dense(self.classes, activation=\"relu\")(x)\n",
    "\n",
    "        #model = keras.Model(inputs=[x.input, y.input], outputs=z)\n",
    "\n",
    "        #x =  output(x, self.classes)\n",
    "        model = keras.Model(inputs=[input_csv], outputs=x)\n",
    "        optimizer = hp.Choice(\"optimizer\", [\"adam\", \"sgd\", \"RMSprop\"])\n",
    "        model.compile(\n",
    "            optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "        )\n",
    "        model.summary()\n",
    "        return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(175, 8)\n"
     ]
    }
   ],
   "source": [
    "print(y_test.shape)\n",
    "# y_test = keras.utils.to_categorical(y_test, len(emotion_class))\n",
    "# y_train = keras.utils.to_categorical(y_train, len(emotion_class))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train_array1, train_labels, test_array1, test_labels = load_csv_dataset(\n",
    "# #     dest_dir, preprocess_dir)\n",
    "\n",
    "# print(y_train.shape)\n",
    "\n",
    "# y_train1 = tf.squeeze(y_train, axis=-1)\n",
    "# y_test  = tf.squeeze(y_test, axis=-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oiIE9HTUGmyV",
    "outputId": "3341a98d-4ed1-4775-b9de-67c1a74626e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/cchantra/keras-tuner/e/KER-237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-27 14:26:59.866545: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-03-27 14:26:59.866785: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-27 14:26:59.867765: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s\n",
      "2022-03-27 14:26:59.867835: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-27 14:26:59.868740: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s\n",
      "2022-03-27 14:26:59.868770: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-03-27 14:26:59.868802: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2022-03-27 14:26:59.868818: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-03-27 14:26:59.868834: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-03-27 14:26:59.868851: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-03-27 14:26:59.868867: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11\n",
      "2022-03-27 14:26:59.868883: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-03-27 14:26:59.868899: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-03-27 14:26:59.868951: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-27 14:26:59.869889: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-27 14:26:59.870821: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-27 14:26:59.871763: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-27 14:26:59.872660: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1\n",
      "2022-03-27 14:26:59.872919: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-03-27 14:26:59.872993: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-27 14:26:59.873898: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s\n",
      "2022-03-27 14:26:59.873955: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-27 14:26:59.874854: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:02:00.0 name: NVIDIA TITAN Xp computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.90GiB deviceMemoryBandwidth: 510.07GiB/s\n",
      "2022-03-27 14:26:59.874871: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-03-27 14:26:59.874889: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2022-03-27 14:26:59.874904: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-03-27 14:26:59.874918: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-03-27 14:26:59.874932: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-03-27 14:26:59.874946: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11\n",
      "2022-03-27 14:26:59.874960: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-03-27 14:26:59.874975: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-03-27 14:26:59.875027: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-27 14:26:59.875974: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-27 14:26:59.876905: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-27 14:26:59.877839: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-27 14:26:59.878714: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1\n",
      "2022-03-27 14:26:59.878760: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-03-27 14:26:59.878767: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 \n",
      "2022-03-27 14:26:59.878772: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N N \n",
      "2022-03-27 14:26:59.878776: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   N N \n",
      "2022-03-27 14:26:59.878894: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-27 14:26:59.879846: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-27 14:26:59.880785: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-27 14:26:59.881686: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10769 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:01:00.0, compute capability: 6.1)\n",
      "2022-03-27 14:26:59.881752: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-27 14:26:59.882651: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10772 MB memory) -> physical GPU (device: 1, name: NVIDIA TITAN Xp, pci bus id: 0000:02:00.0, compute capability: 6.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 468, 3)]          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1404)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                22480     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 136       \n",
      "=================================================================\n",
      "Total params: 23,432\n",
      "Trainable params: 23,432\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Search space summary\n",
      "Default search space size: 7\n",
      "learning_rate (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001, 1e-05], 'ordered': True}\n",
      "num_layers (Choice)\n",
      "{'default': 4, 'conditions': [], 'values': [4, 5, 6, 7, 8, 9, 10], 'ordered': True}\n",
      "hidden0 (Choice)\n",
      "{'default': 16, 'conditions': [], 'values': [16, 32, 64, 128, 256, 512], 'ordered': True}\n",
      "hidden1 (Choice)\n",
      "{'default': 16, 'conditions': [], 'values': [16, 32, 64, 128, 256, 512], 'ordered': True}\n",
      "hidden2 (Choice)\n",
      "{'default': 16, 'conditions': [], 'values': [16, 32, 64, 128, 256, 512], 'ordered': True}\n",
      "hidden3 (Choice)\n",
      "{'default': 16, 'conditions': [], 'values': [16, 32, 64, 128, 256, 512], 'ordered': True}\n",
      "optimizer (Choice)\n",
      "{'default': 'adam', 'conditions': [], 'values': ['adam', 'sgd', 'RMSprop'], 'ordered': False}\n"
     ]
    }
   ],
   "source": [
    "from keras_tuner import HyperParameters\n",
    "from keras_tuner import RandomSearch\n",
    "\n",
    "ratio = 0.1\n",
    "PROJECT = \"MLP\"+str(ratio)\n",
    "neptune.create_experiment(PROJECT)\n",
    "\n",
    "hp = HyperParameters()\n",
    "\n",
    "\n",
    "# This will override the `learning_rate` parameter with your\n",
    "# own selection of choices\n",
    "hp.Choice(\"learning_rate\", values=[1e-2, 1e-3, 1e-4, 1e-5])\n",
    "\n",
    "nb_classes = len(emotion_class)\n",
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping('val_accuracy', patience=10),\n",
    "    #lr_finder,\n",
    "    #tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5'),\n",
    "    #tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "]\n",
    "\n",
    " \n",
    "                \n",
    "tuner = RandomSearch(\n",
    "  \n",
    "    hypermodel=MultilayerModel(classes=nb_classes),\n",
    "    hyperparameters = hp,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=50,\n",
    "    executions_per_trial=1,\n",
    "    overwrite=True,\n",
    "    directory=\"mytest3_dir\",\n",
    "    project_name=PROJECT,\n",
    "    logger = npt_utils.NeptuneLogger(),\n",
    "     \n",
    ")\n",
    "\n",
    "ratio = 0.4\n",
    "EPOCH = 100\n",
    "batch_size = 32\n",
    "\n",
    "tuner.search_space_summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 468, 3) (700, 8) (175, 468, 3) (175, 8)\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "X_train1.shape,\n",
    "y_train.shape,\n",
    "X_test.shape,\n",
    "y_test.shape\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 50 Complete [00h 00m 01s]\n",
      "val_accuracy: 0.10000000149011612\n",
      "\n",
      "Best val_accuracy So Far: 0.20000000298023224\n",
      "Total elapsed time: 00h 01m 19s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tuner.search(X_train1[:int(ratio*len(X_train1))], y_train[:int(ratio*len(y_train))], epochs=EPOCH, callbacks = my_callbacks,validation_data=(X_test[:int(ratio*len(X_test))], y_test[:int(ratio*len(y_test))]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 468, 3)]          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1404)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                22480     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               4352      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                2064      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 8)                 136       \n",
      "=================================================================\n",
      "Total params: 63,560\n",
      "Trainable params: 63,560\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 468, 3)]          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1404)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                44960     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               8448      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               33280     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                16416     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 8)                 264       \n",
      "=================================================================\n",
      "Total params: 124,168\n",
      "Trainable params: 124,168\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 468, 3)]          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1404)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                22480     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               4352      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                4112      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               8704      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 8)                 4104      \n",
      "=================================================================\n",
      "Total params: 44,024\n",
      "Trainable params: 44,024\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 468, 3)]          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1404)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                22480     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 1032      \n",
      "=================================================================\n",
      "Total params: 33,192\n",
      "Trainable params: 33,192\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 468, 3)]          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1404)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               179840    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                2064      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               8704      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                2064      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               16896     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 8)                 4104      \n",
      "=================================================================\n",
      "Total params: 279,880\n",
      "Trainable params: 279,880\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 468, 3)]          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1404)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                89920     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               33280     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                16416     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               8448      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 512)               16896     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 8)                 4104      \n",
      "=================================================================\n",
      "Total params: 195,912\n",
      "Trainable params: 195,912\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 468, 3)]          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1404)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               719360    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                16416     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               8448      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 8)                 136       \n",
      "=================================================================\n",
      "Total params: 794,904\n",
      "Trainable params: 794,904\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 468, 3)]          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1404)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               179840    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               4352      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               16896     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 8)                 2056      \n",
      "=================================================================\n",
      "Total params: 422,008\n",
      "Trainable params: 422,008\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 468, 3)]          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1404)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                22480     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               4352      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 8)                 4104      \n",
      "=================================================================\n",
      "Total params: 356,184\n",
      "Trainable params: 356,184\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 468, 3)]          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1404)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               719360    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                4112      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               16896     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 8)                 520       \n",
      "=================================================================\n",
      "Total params: 916,664\n",
      "Trainable params: 916,664\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Results summary\n",
      "Results in mytest3_dir/MLP0.1\n",
      "Showing 10 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.01\n",
      "num_layers: 10\n",
      "hidden0: 16\n",
      "hidden1: 256\n",
      "hidden2: 128\n",
      "hidden3: 16\n",
      "optimizer: sgd\n",
      "hidden4: 16\n",
      "hidden5: 16\n",
      "hidden6: 16\n",
      "hidden7: 16\n",
      "hidden8: 16\n",
      "hidden9: 16\n",
      "Score: 0.20000000298023224\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "num_layers: 10\n",
      "hidden0: 32\n",
      "hidden1: 256\n",
      "hidden2: 32\n",
      "hidden3: 64\n",
      "optimizer: RMSprop\n",
      "hidden4: 512\n",
      "hidden5: 32\n",
      "hidden6: 32\n",
      "hidden7: 32\n",
      "hidden8: 128\n",
      "hidden9: 32\n",
      "Score: 0.20000000298023224\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.001\n",
      "num_layers: 5\n",
      "hidden0: 16\n",
      "hidden1: 16\n",
      "hidden2: 256\n",
      "hidden3: 16\n",
      "optimizer: RMSprop\n",
      "hidden4: 512\n",
      "hidden5: 16\n",
      "hidden6: 32\n",
      "hidden7: 128\n",
      "hidden8: 512\n",
      "hidden9: 64\n",
      "Score: 0.20000000298023224\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "num_layers: 4\n",
      "hidden0: 16\n",
      "hidden1: 16\n",
      "hidden2: 64\n",
      "hidden3: 128\n",
      "optimizer: RMSprop\n",
      "hidden4: 256\n",
      "hidden5: 128\n",
      "hidden6: 128\n",
      "hidden7: 128\n",
      "hidden8: 512\n",
      "hidden9: 64\n",
      "Score: 0.20000000298023224\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "num_layers: 7\n",
      "hidden0: 128\n",
      "hidden1: 16\n",
      "hidden2: 512\n",
      "hidden3: 128\n",
      "optimizer: RMSprop\n",
      "hidden4: 16\n",
      "hidden5: 32\n",
      "hidden6: 512\n",
      "hidden7: 16\n",
      "hidden8: 32\n",
      "hidden9: 32\n",
      "Score: 0.20000000298023224\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.001\n",
      "num_layers: 9\n",
      "hidden0: 64\n",
      "hidden1: 64\n",
      "hidden2: 512\n",
      "hidden3: 32\n",
      "optimizer: RMSprop\n",
      "hidden4: 256\n",
      "hidden5: 64\n",
      "hidden6: 64\n",
      "hidden7: 32\n",
      "hidden8: 512\n",
      "hidden9: 64\n",
      "Score: 0.20000000298023224\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "num_layers: 8\n",
      "hidden0: 512\n",
      "hidden1: 32\n",
      "hidden2: 256\n",
      "hidden3: 128\n",
      "optimizer: RMSprop\n",
      "hidden4: 32\n",
      "hidden5: 128\n",
      "hidden6: 64\n",
      "hidden7: 16\n",
      "hidden8: 256\n",
      "hidden9: 16\n",
      "Score: 0.20000000298023224\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 1e-05\n",
      "num_layers: 9\n",
      "hidden0: 128\n",
      "hidden1: 256\n",
      "hidden2: 64\n",
      "hidden3: 16\n",
      "optimizer: adam\n",
      "hidden4: 256\n",
      "hidden5: 128\n",
      "hidden6: 32\n",
      "hidden7: 512\n",
      "hidden8: 256\n",
      "hidden9: 32\n",
      "Score: 0.20000000298023224\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.001\n",
      "num_layers: 9\n",
      "hidden0: 16\n",
      "hidden1: 256\n",
      "hidden2: 128\n",
      "hidden3: 512\n",
      "optimizer: sgd\n",
      "hidden4: 256\n",
      "hidden5: 64\n",
      "hidden6: 64\n",
      "hidden7: 128\n",
      "hidden8: 512\n",
      "hidden9: 64\n",
      "Score: 0.20000000298023224\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "num_layers: 9\n",
      "hidden0: 512\n",
      "hidden1: 128\n",
      "hidden2: 256\n",
      "hidden3: 16\n",
      "optimizer: RMSprop\n",
      "hidden4: 64\n",
      "hidden5: 32\n",
      "hidden6: 512\n",
      "hidden7: 128\n",
      "hidden8: 64\n",
      "hidden9: 64\n",
      "Score: 0.20000000298023224\n"
     ]
    }
   ],
   "source": [
    "models = tuner.get_best_models(num_models=10)\n",
    "tuner.results_summary()\n",
    "\n",
    "npt_utils.log_tuner_info(tuner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, 63560\n",
      "1, 124168\n",
      "2, 44024\n",
      "3, 33192\n",
      "4, 279880\n",
      "5, 195912\n",
      "6, 794904\n",
      "7, 422008\n",
      "8, 356184\n",
      "9, 916664\n"
     ]
    }
   ],
   "source": [
    "from keras_tuner.engine.hypermodel import maybe_compute_model_size\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"{}, {}\".format(i,maybe_compute_model_size(models[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 468, 3)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/cchantra/keras-tuner/e/KER-238\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 468, 3)]          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1404)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                22480     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 136       \n",
      "=================================================================\n",
      "Total params: 23,432\n",
      "Trainable params: 23,432\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Search space summary\n",
      "Default search space size: 7\n",
      "learning_rate (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001, 1e-05], 'ordered': True}\n",
      "num_layers (Choice)\n",
      "{'default': 4, 'conditions': [], 'values': [4, 5, 6, 7, 8, 9, 10], 'ordered': True}\n",
      "hidden0 (Choice)\n",
      "{'default': 16, 'conditions': [], 'values': [16, 32, 64, 128, 256, 512], 'ordered': True}\n",
      "hidden1 (Choice)\n",
      "{'default': 16, 'conditions': [], 'values': [16, 32, 64, 128, 256, 512], 'ordered': True}\n",
      "hidden2 (Choice)\n",
      "{'default': 16, 'conditions': [], 'values': [16, 32, 64, 128, 256, 512], 'ordered': True}\n",
      "hidden3 (Choice)\n",
      "{'default': 16, 'conditions': [], 'values': [16, 32, 64, 128, 256, 512], 'ordered': True}\n",
      "optimizer (Choice)\n",
      "{'default': 'adam', 'conditions': [], 'values': ['adam', 'sgd', 'RMSprop'], 'ordered': False}\n"
     ]
    }
   ],
   "source": [
    "#Bayesian\n",
    "\n",
    "from keras_tuner import HyperParameters\n",
    "from keras_tuner import RandomSearch,Hyperband,SklearnTuner,BayesianOptimization\n",
    " \n",
    "ratio = 0.8\n",
    "\n",
    "PROJECT = \"MLPBayes\"+str(ratio)\n",
    "neptune.create_experiment(PROJECT)\n",
    "\n",
    "hp = HyperParameters()\n",
    "\n",
    "\n",
    "# This will override the `learning_rate` parameter with your\n",
    "# own selection of choices\n",
    "hp.Choice(\"learning_rate\", values=[1e-2, 1e-3, 1e-4, 1e-5])\n",
    "\n",
    "nb_classes = len(emotion_class)\n",
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping('val_accuracy', patience=10),\n",
    "    #lr_finder,\n",
    "    #tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5'),\n",
    "    #tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "]\n",
    "\n",
    "# mymodel= MultilayerModel(classes=nb_classes)\n",
    " \n",
    "tuner = BayesianOptimization(\n",
    "    #build_SqueezeNet_11_fixed,\n",
    "    #build_squeezenet_auto_model,\n",
    "    #build_model,\n",
    "    \n",
    "    hypermodel=MultilayerModel(classes=nb_classes),\n",
    "    hyperparameters = hp,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=100,\n",
    "    executions_per_trial=1,\n",
    "    overwrite=True,\n",
    "    directory=\"mytest3_dir\",\n",
    "    project_name= PROJECT,\n",
    "    #distribution_strategy=tf.distribute.MirroredStrategy(),\n",
    "    num_initial_points=2,\n",
    "    alpha=0.0001,\n",
    "    beta=2.6,\n",
    "    seed=None,\n",
    "    tune_new_entries=True,\n",
    "    allow_new_entries=True,\n",
    "    logger = npt_utils.NeptuneLogger(),\n",
    "     \n",
    ")\n",
    " \n",
    "batch_size = 32\n",
    "\n",
    "tuner.search_space_summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 468, 3) (700, 8) (175, 468, 3) (175, 8)\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "X_train1.shape,\n",
    "y_train.shape,\n",
    "X_test.shape,\n",
    "y_test.shape\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "learning_rate     |1e-05             |?                 \n",
      "num_layers        |6                 |?                 \n",
      "hidden0           |16                |?                 \n",
      "hidden1           |32                |?                 \n",
      "hidden2           |64                |?                 \n",
      "hidden3           |64                |?                 \n",
      "optimizer         |sgd               |?                 \n",
      "\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 468, 3)]          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1404)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                22480     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 8)                 136       \n",
      "=================================================================\n",
      "Total params: 30,744\n",
      "Trainable params: 30,744\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 9.0841 - accuracy: 0.1508 - val_loss: 8.3440 - val_accuracy: 0.1357\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.5550 - accuracy: 0.1038 - val_loss: 8.3335 - val_accuracy: 0.1429\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9.0067 - accuracy: 0.1383 - val_loss: 8.3309 - val_accuracy: 0.1286\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9.2607 - accuracy: 0.0972 - val_loss: 8.3343 - val_accuracy: 0.1071\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.6423 - accuracy: 0.1547 - val_loss: 8.3305 - val_accuracy: 0.1357\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9.1364 - accuracy: 0.0977 - val_loss: 8.3316 - val_accuracy: 0.1357\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.9105 - accuracy: 0.0985 - val_loss: 8.3311 - val_accuracy: 0.1571\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9.1733 - accuracy: 0.1065 - val_loss: 8.3322 - val_accuracy: 0.1357\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9.1591 - accuracy: 0.1095 - val_loss: 8.3343 - val_accuracy: 0.1357\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.9732 - accuracy: 0.1347 - val_loss: 8.3320 - val_accuracy: 0.1429\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 8.5687 - accuracy: 0.1400 - val_loss: 8.3311 - val_accuracy: 0.1643\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.9746 - accuracy: 0.1751 - val_loss: 4.8274 - val_accuracy: 0.1214\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.4444 - accuracy: 0.1674 - val_loss: 4.7959 - val_accuracy: 0.1357\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.2435 - accuracy: 0.1599 - val_loss: 4.7833 - val_accuracy: 0.1214\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.2507 - accuracy: 0.1335 - val_loss: 4.7757 - val_accuracy: 0.1286\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.4838 - accuracy: 0.1501 - val_loss: 4.7712 - val_accuracy: 0.1143\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.4964 - accuracy: 0.1372 - val_loss: 4.7689 - val_accuracy: 0.1429\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.4444 - accuracy: 0.1334 - val_loss: 4.7662 - val_accuracy: 0.1143\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.4209 - accuracy: 0.1387 - val_loss: 4.7648 - val_accuracy: 0.1214\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.4470 - accuracy: 0.1441 - val_loss: 4.7641 - val_accuracy: 0.1214\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.2284 - accuracy: 0.1166 - val_loss: 4.7641 - val_accuracy: 0.1214\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "tuner.search(X_train1[:int(ratio*len(X_train1))], y_train[:int(ratio*len(y_train))], epochs=EPOCH, callbacks = my_callbacks,validation_data=(X_test[:int(ratio*len(X_test))], y_test[:int(ratio*len(y_test))]))\n",
    "\n",
    "# tuner.search(X_train1[:int(ratio*len(X_train1))], y_train1[:int(ratio*len(y_train1))], epochs=EPOCH, callbacks = my_callbacks,validation_data=(X_test[:int(ratio*len(X_test))], y_test[:int(ratio*len(y_test))]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = tuner.get_best_models(num_models=10)\n",
    "tuner.results_summary()\n",
    "\n",
    "npt_utils.log_tuner_info(tuner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_tuner.engine.hypermodel import maybe_compute_model_size\n",
    "\n",
    "for i in range(len(models)):\n",
    "    print(\"{}, {}\".format(i,maybe_compute_model_size(models[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperband\n",
    "#Bayesian\n",
    "\n",
    "from keras_tuner import HyperParameters\n",
    "from keras_tuner import RandomSearch,Hyperband,SklearnTuner,BayesianOptimization\n",
    " \n",
    "ratio=1.0\n",
    "PROJECT = \"MLPHyper\"+str(ratio)\n",
    "neptune.create_experiment(PROJECT)\n",
    "\n",
    "hp = HyperParameters()\n",
    "\n",
    "\n",
    "# This will override the `learning_rate` parameter with your\n",
    "# own selection of choices\n",
    "hp.Choice(\"learning_rate\", values=[1e-2, 1e-3, 1e-4, 1e-5])\n",
    "\n",
    "nb_classes = len(emotion_class)\n",
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping('val_accuracy', patience=10),\n",
    "    #lr_finder,\n",
    "    #tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5'),\n",
    "    #tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "]\n",
    "\n",
    "mymodel= MultilayerModel(classes=nb_classes)\n",
    " \n",
    "tuner = Hyperband(\n",
    "    #build_SqueezeNet_11_fixed,\n",
    "    #build_squeezenet_auto_model,\n",
    "    #build_model,\n",
    "    \n",
    "    hypermodel=mymodel,\n",
    "    hyperparameters = hp,\n",
    "    objective=\"val_accuracy\",\n",
    "    #max_trials=20,\n",
    "    executions_per_trial=1,\n",
    "    overwrite=True,\n",
    "    directory=\"mytest3_dir\",\n",
    "    project_name=PROJECT,\n",
    "    #distribution_strategy=tf.distribute.MirroredStrategy(),\n",
    "    max_epochs=EPOCH,\n",
    "    logger = npt_utils.NeptuneLogger(),\n",
    "     \n",
    ")\n",
    "batch_size = 32\n",
    "\n",
    "tuner.search_space_summary()\n",
    "\n",
    "\n",
    "tuner.search(X_train1[:int(ratio*len(X_train1))], y_train[:int(ratio*len(y_train))], epochs=EPOCH, callbacks = my_callbacks,validation_data=(X_test[:int(ratio*len(X_test))], y_test[:int(ratio*len(y_test))]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = tuner.get_best_models(num_models=10)\n",
    "tuner.results_summary()\n",
    "\n",
    "npt_utils.log_tuner_info(tuner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_tuner.engine.hypermodel import maybe_compute_model_size\n",
    "\n",
    "for i in range(len(models)):\n",
    "    print(\"{}, {}\".format(i,maybe_compute_model_size(models[i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4eDuBJhvTffz"
   },
   "source": [
    "# SQUEEZENET Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pxe0TzVzTffz"
   },
   "outputs": [],
   "source": [
    "# hyper paramter squeezenet\n",
    "import tensorflow.keras.backend as K\n",
    "from keras_tuner import HyperParameters\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from keras_tuner import RandomSearch\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_axis():\n",
    "    axis = -1 if K.image_data_format() == 'channels_last' else 1\n",
    "    return axis\n",
    "\n",
    "\n",
    "def create_fire_module(x, nb_squeeze_filter, name, use_bypass=False):\n",
    "    \"\"\"\n",
    "    Creates a fire module\n",
    "\n",
    "    Arguments:\n",
    "        x                 : input\n",
    "        nb_squeeze_filter : number of filters of squeeze. The filtersize of expand is 4 times of squeeze\n",
    "        use_bypass        : if True then a bypass will be added\n",
    "        name              : name of module e.g. fire123\n",
    "\n",
    "    Returns:\n",
    "        x                 : returns a fire module\n",
    "    \"\"\"\n",
    "\n",
    "    nb_expand_filter = 4 * nb_squeeze_filter\n",
    "    squeeze = layers.Conv2D(nb_squeeze_filter, (1, 1), activation='relu',\n",
    "                            padding='same', name='%s_squeeze' % name)(x)\n",
    "    expand_1x1 = layers.Conv2D(nb_expand_filter, (1, 1), activation='relu',\n",
    "                               padding='same', name='%s_expand_1x1' % name)(squeeze)\n",
    "    expand_3x3 = layers.Conv2D(nb_expand_filter, (3, 3), activation='relu',\n",
    "                               padding='same', name='%s_expand_3x3' % name)(squeeze)\n",
    "\n",
    "    axis = get_axis()\n",
    "    x_ret = layers.Concatenate(axis=axis, name='%s_concatenate' % name)([\n",
    "        expand_1x1, expand_3x3])\n",
    "\n",
    "    if use_bypass:\n",
    "        x_ret = layers.Add(name='%s_concatenate_bypass' % name)([x_ret, x])\n",
    "\n",
    "    return x_ret\n",
    "\n",
    "\n",
    "def output(x, nb_classes):\n",
    "    x = layers.Conv2D(nb_classes, (1, 1), strides=(1, 1),\n",
    "                      padding='valid', name='conv10')(x)\n",
    "    x = layers.GlobalAveragePooling2D(name='avgpool10')(x)\n",
    "    x = layers.Activation(\"softmax\", name='softmax')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def build_SqueezeNet_fixed(hp):\n",
    "    \"\"\"\n",
    "    Creating a SqueezeNet of version 1.0\n",
    "\n",
    "    Arguments:\n",
    "        input_shape  : shape of the input images e.g. (224,224,3)\n",
    "        nb_classes   : number of classes\n",
    "        use_bypass   : if true, bypass connections will be created at fire module 3, 5, 7, and 9 (default: False)\n",
    "        dropout_rate : defines the dropout rate that is accomplished after last fire module (default: None)\n",
    "        compression  : reduce the number of feature-maps (default: 1.0)\n",
    "\n",
    "    Returns:\n",
    "        Model        : Keras model instance\n",
    "    \"\"\"\n",
    "    use_bypass = hp.Boolean('use_bypass')\n",
    "    compression = hp.Fixed('compression', 1.0)\n",
    "\n",
    "    input_img = tf.keras.layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(int(96*compression), (7, 7), activation='relu',\n",
    "                               strides=(2, 2), padding='same', name='conv1')(input_img)\n",
    "\n",
    "    x = tf.keras.layers.MaxPooling2D(pool_size=(\n",
    "        3, 3), strides=(2, 2), name='maxpool1')(x)\n",
    "\n",
    "    x = create_fire_module(x, int(16*compression), name='fire2')\n",
    "    x = create_fire_module(x, int(16*compression),\n",
    "                           name='fire3', use_bypass=use_bypass)\n",
    "    x = create_fire_module(x, int(32*compression), name='fire4')\n",
    "\n",
    "    x = layers.MaxPooling2D(pool_size=(\n",
    "        3, 3), strides=(2, 2), name='maxpool4')(x)\n",
    "\n",
    "    x = create_fire_module(x, int(32*compression),\n",
    "                           name='fire5', use_bypass=use_bypass)\n",
    "    x = create_fire_module(x, int(48*compression), name='fire6')\n",
    "    x = create_fire_module(x, int(48*compression),\n",
    "                           name='fire7', use_bypass=use_bypass)\n",
    "    x = create_fire_module(x, int(64*compression), name='fire8')\n",
    "\n",
    "    x = layers.MaxPooling2D(pool_size=(\n",
    "        3, 3), strides=(2, 2), name='maxpool8')(x)\n",
    "\n",
    "    x = create_fire_module(x, int(64*compression),\n",
    "                           name='fire9', use_bypass=use_bypass)\n",
    "\n",
    "    dropout_rate = hp.Choice('dropout_rate', values=[0.0, 0.5, 0.8])\n",
    "\n",
    "    if dropout_rate:\n",
    "        x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "\n",
    "    x = output(x, nb_classes)\n",
    "    model = keras.Model(inputs=input_img, outputs=x)\n",
    "    optimizer = hp.Choice(\"optimizer\", [\"adam\", \"sgd\"])\n",
    "    model.compile(\n",
    "        optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_SqueezeNet_11_fixed(hp):\n",
    "    \"\"\"\n",
    "    Creating a SqueezeNet of version 1.1\n",
    "\n",
    "    2.4x less computation over SqueezeNet 1.0 implemented above.\n",
    "\n",
    "    Arguments:\n",
    "        input_shape  : shape of the input images e.g. (224,224,3)\n",
    "        nb_classes   : number of classes\n",
    "        dropout_rate : defines the dropout rate that is accomplished after last fire module (default: None)\n",
    "        compression  : reduce the number of feature-maps\n",
    "\n",
    "    Returns:\n",
    "        Model        : Keras model instance\n",
    "    \"\"\"\n",
    "\n",
    "    use_bypass = hp.Boolean('use_bypass')\n",
    "    compression = hp.Fixed('compression', 1.0)\n",
    "\n",
    "    input_img = layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "\n",
    "    x = layers.Conv2D(int(64*compression), (3, 3), activation='relu',\n",
    "                      strides=(2, 2), padding='same', name='conv1')(input_img)\n",
    "\n",
    "    x = layers.MaxPooling2D(pool_size=(\n",
    "        3, 3), strides=(2, 2), name='maxpool1')(x)\n",
    "\n",
    "    x = create_fire_module(x, int(16*compression), name='fire2')\n",
    "    x = create_fire_module(x, int(16*compression), name='fire3')\n",
    "\n",
    "    x = layers.MaxPooling2D(pool_size=(\n",
    "        3, 3), strides=(2, 2), name='maxpool3')(x)\n",
    "\n",
    "    x = create_fire_module(x, int(32*compression), name='fire4')\n",
    "    x = create_fire_module(x, int(32*compression), name='fire5')\n",
    "\n",
    "    x = layers.MaxPooling2D(pool_size=(\n",
    "        3, 3), strides=(2, 2), name='maxpool5')(x)\n",
    "\n",
    "    x = create_fire_module(x, int(48*compression), name='fire6')\n",
    "    x = create_fire_module(x, int(48*compression), name='fire7')\n",
    "    x = create_fire_module(x, int(64*compression), name='fire8')\n",
    "    x = create_fire_module(x, int(64*compression), name='fire9')\n",
    "\n",
    "    dropout_rate = hp.Choice('dropout_rate', values=[0.0, 0.5, 0.8])\n",
    "\n",
    "    if dropout_rate:\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "\n",
    "    # Creating last conv10\n",
    "    x = output(x, nb_classes)\n",
    "\n",
    "    model = keras.Model(inputs=input_img, outputs=x)\n",
    "    optimizer = hp.Choice(\"optimizer\", [\"adam\", \"sgd\"])\n",
    "    model.compile(\n",
    "        optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZDM3Xmbei-aW"
   },
   "outputs": [],
   "source": [
    "def create_input_layer_plus_depth():\n",
    "    inputA = layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "    inputB = layers.Input(shape=(468,3))\n",
    "    combined = layers.concatenate()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PLuRMPTOTff1"
   },
   "outputs": [],
   "source": [
    "#SqueezeNet 11\n",
    "from keras_tuner import HyperModel\n",
    "\n",
    "\n",
    "class SqueezeNet11Model(HyperModel):\n",
    "    def __init__(self, classes):\n",
    "        self.classes = classes\n",
    "\n",
    "    def build(self, hp):\n",
    "       \n",
    "        use_bypass = hp.Boolean('use_bypass')\n",
    "        compression = hp.Fixed('compression',1.0)\n",
    "\n",
    "        input_img =  layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "\n",
    "\n",
    "        x = layers.Conv2D(int(64*compression), (3,3), activation='relu', strides=(2,2), padding='same', name='conv1')(input_img)\n",
    "\n",
    "        x = layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool1')(x)\n",
    "\n",
    "        x = create_fire_module(x, int(16*compression), name='fire2')\n",
    "        x = create_fire_module(x, int(16*compression), name='fire3')\n",
    "\n",
    "        x = layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool3')(x)\n",
    "\n",
    "        x = create_fire_module(x, int(32*compression), name='fire4')\n",
    "        x = create_fire_module(x, int(32*compression), name='fire5')\n",
    "\n",
    "        x = layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool5')(x)\n",
    "\n",
    "        x = create_fire_module(x, int(48*compression), name='fire6')\n",
    "        x = create_fire_module(x, int(48*compression), name='fire7')\n",
    "        x = create_fire_module(x, int(64*compression), name='fire8')\n",
    "        x = create_fire_module(x, int(64*compression), name='fire9')\n",
    "\n",
    "        dropout_rate = hp.Choice('dropout_rate',values=[0.1,0.5,0.8])\n",
    "\n",
    "        if dropout_rate:\n",
    "            x = layers.Dropout(dropout_rate)(x)\n",
    "\n",
    "        # Creating last conv10\n",
    "        x = output(x, self.classes)\n",
    "        model = keras.Model(inputs=input_img, outputs=x)\n",
    "        optimizer = hp.Choice(\"optimizer\", [\"adam\", \"sgd\"])\n",
    "        model.compile(\n",
    "            optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "        )\n",
    "        model.summary()\n",
    "        return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OodQLuODTff2"
   },
   "outputs": [],
   "source": [
    "# SqueezeNet 11\n",
    "from keras_tuner import HyperModel\n",
    "\n",
    "\n",
    "class SqueezeNetModel(HyperModel):\n",
    "    def __init__(self, classes):\n",
    "        self.classes = classes\n",
    "\n",
    "    def build(self, hp):\n",
    "\n",
    "        use_bypass = hp.Boolean('use_bypass')\n",
    "        compression = hp.Fixed('compression', 1.0)\n",
    "\n",
    "        input_img = tf.keras.layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "\n",
    "        x = tf.keras.layers.Conv2D(int(96*compression), (7, 7), activation='relu',\n",
    "                                   strides=(2, 2), padding='same', name='conv1')(input_img)\n",
    "\n",
    "        x = tf.keras.layers.MaxPooling2D(pool_size=(\n",
    "            3, 3), strides=(2, 2), name='maxpool1')(x)\n",
    "\n",
    "        x = create_fire_module(x, int(16*compression), name='fire2')\n",
    "        x = create_fire_module(x, int(16*compression),\n",
    "                               name='fire3', use_bypass=use_bypass)\n",
    "        x = create_fire_module(x, int(32*compression), name='fire4')\n",
    "\n",
    "        x = layers.MaxPooling2D(pool_size=(\n",
    "            3, 3), strides=(2, 2), name='maxpool4')(x)\n",
    "\n",
    "        x = create_fire_module(x, int(32*compression),\n",
    "                               name='fire5', use_bypass=use_bypass)\n",
    "        x = create_fire_module(x, int(48*compression), name='fire6')\n",
    "        x = create_fire_module(x, int(48*compression),\n",
    "                               name='fire7', use_bypass=use_bypass)\n",
    "        x = create_fire_module(x, int(64*compression), name='fire8')\n",
    "\n",
    "        x = layers.MaxPooling2D(pool_size=(\n",
    "            3, 3), strides=(2, 2), name='maxpool8')(x)\n",
    "\n",
    "        x = create_fire_module(x, int(64*compression),\n",
    "                               name='fire9', use_bypass=use_bypass)\n",
    "\n",
    "        dropout_rate = hp.Choice('dropout_rate', values=[0.0, 0.5, 0.8])\n",
    "\n",
    "        if dropout_rate:\n",
    "            x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "\n",
    "        x = output(x, self.classes)\n",
    "        model = keras.Model(inputs=input_img, outputs=x)\n",
    "        optimizer = hp.Choice(\"optimizer\", [\"adam\", \"sgd\"])\n",
    "        model.compile(\n",
    "            optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "        )\n",
    "        model.summary()\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_tuner import HyperModel\n",
    "\n",
    "\n",
    "def squeeze_excitation_layer(input_layer, out_dim, ratio, conv=False):\n",
    "    squeeze = layers.GlobalAveragePooling2D()(input_layer)\n",
    "\n",
    "    excitation = layers.Dense(units=out_dim / ratio,\n",
    "                              activation='relu')(squeeze)\n",
    "    excitation = layers.Dense(out_dim, activation='sigmoid')(excitation)\n",
    "    excitation = tf.reshape(excitation, [-1, 1, 1, out_dim])\n",
    "\n",
    "    scale = layers.multiply([input_layer, excitation])\n",
    "\n",
    "    if conv:\n",
    "        shortcut = tf.keras.layers.Conv2D(out_dim, kernel_size=1, strides=1,\n",
    "                                          padding='same', kernel_initializer='he_normal')(input_layer)\n",
    "        shortcut = tf.keras.layers.BatchNormalization()(shortcut)\n",
    "    else:\n",
    "        shortcut = input_layer\n",
    "\n",
    "    out = scale  # tf.keras.layers.add([shortcut, scale])\n",
    "    return out\n",
    "\n",
    "\n",
    "# SqueezeNet auto\n",
    "\n",
    "\n",
    "class SqueezeNetSEAutoModel(HyperModel):\n",
    "    def __init__(self, classes):\n",
    "        self.classes = classes\n",
    "\n",
    "    def build(self, hp):\n",
    "\n",
    "        compression_val = hp.Fixed('compression', 1.0)\n",
    "\n",
    "        input_img = layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "\n",
    "        x = layers.Conv2D(int(96*compression_val), (3, 3), activation='relu',\n",
    "                          strides=(2, 2), padding='same', name='conv1')(input_img)\n",
    "\n",
    "        x = layers.MaxPooling2D(pool_size=(\n",
    "            3, 3), strides=(2, 2), name='maxpool1')(x)\n",
    "\n",
    "        j = 2\n",
    "        filter_size = 16\n",
    "\n",
    "        num_fire = hp.Int(\"fire_module\", 1, 2, default=2)\n",
    "        use_bypass = [hp.Boolean('use_bypass'+str(i)) for i in range(num_fire)]\n",
    "        pooling = [hp.Choice('pooling'+str(i), [\"max\", \"avg\"])\n",
    "                   for i in range(num_fire)]\n",
    "\n",
    "        print(use_bypass)\n",
    "        print(pooling)\n",
    "        for i in range(num_fire):\n",
    "\n",
    "            ratio = hp.Choice(\"squeeze_ratio\"+str(j), [8, 16, 32], default=32)\n",
    "            x_in = x\n",
    "            x = create_fire_module(\n",
    "                x, int(filter_size*compression_val), name='fire'+str(j), )\n",
    "\n",
    "            se_insert = hp.Boolean(\"SE_add\"+str(j))\n",
    "\n",
    "            if se_insert:\n",
    "                x = squeeze_excitation_layer(\n",
    "                    x, out_dim=x.shape[3], ratio=ratio)\n",
    "\n",
    "                if hp.Boolean(\"SE_skip\"+str(j)):\n",
    "                    if x_in.shape[3] != x.shape[3]:\n",
    "                        x_in = layers.Conv2D(x.shape[3], kernel_size=1, strides=1,\n",
    "                                             padding='same', kernel_initializer='he_normal')(x_in)\n",
    "                        x_in = tf.keras.layers.BatchNormalization()(x_in)\n",
    "\n",
    "                    x = tf.keras.layers.add([x_in, x])\n",
    "\n",
    "            ratio = hp.Choice(\"squeeze_ratio\"+str(j), [8, 16, 32], default=32)\n",
    "            x_in = x\n",
    "            x = create_fire_module(x, int(\n",
    "                filter_size*compression_val), name='fire'+str(j+1), use_bypass=use_bypass[i])\n",
    "\n",
    "            se_insert = hp.Boolean(\"SE_add\"+str(j+1))\n",
    "\n",
    "            if se_insert:\n",
    "\n",
    "                x = squeeze_excitation_layer(\n",
    "                    x, out_dim=x.shape[3], ratio=ratio)\n",
    "\n",
    "                if hp.Boolean(\"SE_skip\"+str(j+1)):\n",
    "                    if x_in.shape[3] != x.shape[3]:\n",
    "                        x_in = layers.Conv2D(x.shape[3], kernel_size=1, strides=1,\n",
    "                                             padding='same', kernel_initializer='he_normal')(x_in)\n",
    "                        x_in = tf.keras.layers.BatchNormalization()(x_in)\n",
    "\n",
    "                    x = tf.keras.layers.add([x_in, x])\n",
    "\n",
    "            # if hp.Choice(\"pooling\", [\"max\", \"avg\"]) == \"max\":\n",
    "            if pooling[i] == \"max\":\n",
    "\n",
    "                x = layers.MaxPooling2D(pool_size=(3, 3), strides=(\n",
    "                    2, 2), name='maxpool'+str(j+1))(x)\n",
    "            else:\n",
    "                x = layers.AveragePooling2D(pool_size=(\n",
    "                    3, 3), strides=(2, 2), name='avgpool'+str(j+1))(x)\n",
    "\n",
    "            j = j+2\n",
    "            filter_size = filter_size+16\n",
    "\n",
    "        num_fire2 = hp.Int('num_fire_2', 0, 2, default=2)\n",
    "        use_bypass2 = [hp.Boolean('use_bypass_2'+str(i))\n",
    "                       for i in range(num_fire2)]\n",
    "\n",
    "        print(use_bypass2)\n",
    "\n",
    "        for i in range(num_fire2):\n",
    "\n",
    "            ratio = hp.Choice(\"squeeze_ratio\"+str(j), [8, 16, 32], default=32)\n",
    "\n",
    "            x_in = x\n",
    "            x = create_fire_module(\n",
    "                x, int(filter_size*compression_val), name='fire'+str(j))\n",
    "\n",
    "            se_insert = hp.Boolean(\"SE_add\"+str(j))\n",
    "\n",
    "            if se_insert:\n",
    "                x = squeeze_excitation_layer(\n",
    "                    x, out_dim=x.shape[3], ratio=ratio)\n",
    "                if hp.Boolean(\"SE_skip\"+str(j)):\n",
    "                    if x_in.shape[3] != x.shape[3]:\n",
    "                        x_in = layers.Conv2D(x.shape[3], kernel_size=1, strides=1,\n",
    "                                             padding='same', kernel_initializer='he_normal')(x_in)\n",
    "                        x_in = tf.keras.layers.BatchNormalization()(x_in)\n",
    "                    x = tf.keras.layers.add([x_in, x])\n",
    "\n",
    "            ratio = hp.Choice(\"squeeze_ratio\"+str(j), [8, 16, 32], default=32)\n",
    "\n",
    "            x_in = x\n",
    "            x = create_fire_module(x, int(\n",
    "                filter_size*compression_val), name='fire'+str(j+1), use_bypass=use_bypass2[i])\n",
    "\n",
    "            se_insert = hp.Boolean(\"SE_add\"+str(j+1))\n",
    "\n",
    "            if se_insert:\n",
    "                x = squeeze_excitation_layer(\n",
    "                    x, out_dim=x.shape[3], ratio=ratio)\n",
    "                if hp.Boolean(\"SE_skip\"+str(j+1)):\n",
    "                    if x_in.shape[3] != x.shape[3]:\n",
    "                        x_in = layers.Conv2D(x.shape[3], kernel_size=1, strides=1,\n",
    "                                             padding='same', kernel_initializer='he_normal')(x_in)\n",
    "                        x_in = tf.keras.layers.BatchNormalization()(x_in)\n",
    "                    x = tf.keras.layers.add([x_in, x])\n",
    "\n",
    "            filter_size = filter_size+16\n",
    "            j = j+2\n",
    "\n",
    "            #x = create_fire_module(x, int(filter_size*compression_val), name='fire8')\n",
    "            #x = create_fire_module(x, int(filter_size*compression_val), name='fire9',use_bypass=hp.Boolean('use_bypass'))\n",
    "\n",
    "        dropout_rate = hp.Float('dropout_rate', 0.0, 0.8)\n",
    "        if dropout_rate:\n",
    "            x = layers.Dropout(dropout_rate)(x)\n",
    "\n",
    "        x = output(x, self.classes)\n",
    "\n",
    "        model = keras.Model(inputs=input_img, outputs=x)\n",
    "\n",
    "        optimizer = hp.Choice(\"optimizer\", [\"RMSprop\", \"sgd\"])\n",
    "        model.compile(\n",
    "            optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "        )\n",
    "        model.summary()\n",
    "\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Squeeze SE Auto Multi 1 layer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_tuner import HyperModel\n",
    "\n",
    "\n",
    "def squeeze_excitation_layer(input_layer, out_dim, ratio, conv=False):\n",
    "    squeeze = layers.GlobalAveragePooling2D()(input_layer)\n",
    "\n",
    "    excitation = layers.Dense(units=out_dim / ratio,\n",
    "                              activation='relu')(squeeze)\n",
    "    excitation = layers.Dense(out_dim, activation='sigmoid')(excitation)\n",
    "    excitation = tf.reshape(excitation, [-1, 1, 1, out_dim])\n",
    "\n",
    "    scale = layers.multiply([input_layer, excitation])\n",
    "\n",
    "    if conv:\n",
    "        shortcut = tf.keras.layers.Conv2D(out_dim, kernel_size=1, strides=1,\n",
    "                                          padding='same', kernel_initializer='he_normal')(input_layer)\n",
    "        shortcut = tf.keras.layers.BatchNormalization()(shortcut)\n",
    "    else:\n",
    "        shortcut = input_layer\n",
    "\n",
    "    out = scale  # tf.keras.layers.add([shortcut, scale])\n",
    "    return out\n",
    "\n",
    "\n",
    "# SqueezeNet auto\n",
    "\n",
    "\n",
    "class SqueezeNetSEMulti_1_AutoModel(HyperModel):\n",
    "    def __init__(self, classes):\n",
    "        self.classes = classes\n",
    "\n",
    "    def build(self, hp):\n",
    "\n",
    "        compression_val = hp.Fixed('compression', 1.0)\n",
    "\n",
    "        input_img = layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "        input_depth_img = layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "\n",
    "        x = layers.Conv2D(int(96*compression_val), (3, 3), activation='relu',\n",
    "                          strides=(2, 2), padding='same', name='conv1x')(input_img)\n",
    "\n",
    "        x = layers.MaxPooling2D(pool_size=(\n",
    "            3, 3), strides=(2, 2), name='maxpool1x')(x)\n",
    "\n",
    "        y = layers.Conv2D(int(96*compression_val), (3, 3), activation='relu',\n",
    "                          strides=(2, 2), padding='same', name='conv1y')(input_depth_img)\n",
    "\n",
    "        y = layers.MaxPooling2D(pool_size=(\n",
    "            3, 3), strides=(2, 2), name='maxpool1y')(y)\n",
    "\n",
    "        x = layers.Add(name='concat_input')([x, y])  # merge\n",
    "\n",
    "        j = 2\n",
    "        filter_size = 16\n",
    "\n",
    "        num_fire = hp.Int(\"fire_module\", 1, 2, default=2)\n",
    "        use_bypass = [hp.Boolean('use_bypass'+str(i)) for i in range(num_fire)]\n",
    "        pooling = [hp.Choice('pooling'+str(i), [\"max\", \"avg\"])\n",
    "                   for i in range(num_fire)]\n",
    "\n",
    "        print(use_bypass)\n",
    "        print(pooling)\n",
    "        for i in range(num_fire):\n",
    "\n",
    "            ratio = hp.Choice(\"squeeze_ratio\"+str(j), [8, 16, 32], default=32)\n",
    "            x_in = x\n",
    "            x = create_fire_module(\n",
    "                x, int(filter_size*compression_val), name='fire'+str(j), )\n",
    "\n",
    "            se_insert = hp.Boolean(\"SE_add\"+str(j))\n",
    "\n",
    "            if se_insert:\n",
    "                x = squeeze_excitation_layer(\n",
    "                    x, out_dim=x.shape[3], ratio=ratio)\n",
    "\n",
    "                if hp.Boolean(\"SE_skip\"+str(j)):\n",
    "                    if x_in.shape[3] != x.shape[3]:\n",
    "                        x_in = layers.Conv2D(x.shape[3], kernel_size=1, strides=1,\n",
    "                                             padding='same', kernel_initializer='he_normal')(x_in)\n",
    "                        x_in = tf.keras.layers.BatchNormalization()(x_in)\n",
    "\n",
    "                    x = tf.keras.layers.add([x_in, x])\n",
    "\n",
    "            ratio = hp.Choice(\"squeeze_ratio\"+str(j), [8, 16, 32], default=32)\n",
    "            x_in = x\n",
    "            x = create_fire_module(x, int(\n",
    "                filter_size*compression_val), name='fire'+str(j+1), use_bypass=use_bypass[i])\n",
    "\n",
    "            se_insert = hp.Boolean(\"SE_add\"+str(j+1))\n",
    "\n",
    "            if se_insert:\n",
    "\n",
    "                x = squeeze_excitation_layer(\n",
    "                    x, out_dim=x.shape[3], ratio=ratio)\n",
    "\n",
    "                if hp.Boolean(\"SE_skip\"+str(j+1)):\n",
    "                    if x_in.shape[3] != x.shape[3]:\n",
    "                        x_in = layers.Conv2D(x.shape[3], kernel_size=1, strides=1,\n",
    "                                             padding='same', kernel_initializer='he_normal')(x_in)\n",
    "                        x_in = tf.keras.layers.BatchNormalization()(x_in)\n",
    "\n",
    "                    x = tf.keras.layers.add([x_in, x])\n",
    "\n",
    "            # if hp.Choice(\"pooling\", [\"max\", \"avg\"]) == \"max\":\n",
    "            if pooling[i] == \"max\":\n",
    "\n",
    "                x = layers.MaxPooling2D(pool_size=(3, 3), strides=(\n",
    "                    2, 2), name='maxpool'+str(j+1))(x)\n",
    "            else:\n",
    "                x = layers.AveragePooling2D(pool_size=(\n",
    "                    3, 3), strides=(2, 2), name='avgpool'+str(j+1))(x)\n",
    "\n",
    "            j = j+2\n",
    "            filter_size = filter_size+16\n",
    "\n",
    "        num_fire2 = hp.Int('num_fire_2', 0, 2, default=2)\n",
    "        use_bypass2 = [hp.Boolean('use_bypass_2'+str(i))\n",
    "                       for i in range(num_fire2)]\n",
    "\n",
    "        print(use_bypass2)\n",
    "\n",
    "        for i in range(num_fire2):\n",
    "\n",
    "            ratio = hp.Choice(\"squeeze_ratio\"+str(j), [8, 16, 32], default=32)\n",
    "\n",
    "            x_in = x\n",
    "            x = create_fire_module(\n",
    "                x, int(filter_size*compression_val), name='fire'+str(j))\n",
    "\n",
    "            se_insert = hp.Boolean(\"SE_add\"+str(j))\n",
    "\n",
    "            if se_insert:\n",
    "                x = squeeze_excitation_layer(\n",
    "                    x, out_dim=x.shape[3], ratio=ratio)\n",
    "                if hp.Boolean(\"SE_skip\"+str(j)):\n",
    "                    if x_in.shape[3] != x.shape[3]:\n",
    "                        x_in = layers.Conv2D(x.shape[3], kernel_size=1, strides=1,\n",
    "                                             padding='same', kernel_initializer='he_normal')(x_in)\n",
    "                        x_in = tf.keras.layers.BatchNormalization()(x_in)\n",
    "                    x = tf.keras.layers.add([x_in, x])\n",
    "\n",
    "            ratio = hp.Choice(\"squeeze_ratio\"+str(j), [8, 16, 32], default=32)\n",
    "\n",
    "            x_in = x\n",
    "            x = create_fire_module(x, int(\n",
    "                filter_size*compression_val), name='fire'+str(j+1), use_bypass=use_bypass2[i])\n",
    "\n",
    "            se_insert = hp.Boolean(\"SE_add\"+str(j+1))\n",
    "\n",
    "            if se_insert:\n",
    "                x = squeeze_excitation_layer(\n",
    "                    x, out_dim=x.shape[3], ratio=ratio)\n",
    "                if hp.Boolean(\"SE_skip\"+str(j+1)):\n",
    "                    if x_in.shape[3] != x.shape[3]:\n",
    "                        x_in = layers.Conv2D(x.shape[3], kernel_size=1, strides=1,\n",
    "                                             padding='same', kernel_initializer='he_normal')(x_in)\n",
    "                        x_in = tf.keras.layers.BatchNormalization()(x_in)\n",
    "                    x = tf.keras.layers.add([x_in, x])\n",
    "\n",
    "            filter_size = filter_size+16\n",
    "            j = j+2\n",
    "\n",
    "            #x = create_fire_module(x, int(filter_size*compression_val), name='fire8')\n",
    "            #x = create_fire_module(x, int(filter_size*compression_val), name='fire9',use_bypass=hp.Boolean('use_bypass'))\n",
    "\n",
    "        dropout_rate = hp.Float('dropout_rate', 0.0, 0.8)\n",
    "        if dropout_rate:\n",
    "            x = layers.Dropout(dropout_rate)(x)\n",
    "\n",
    "        x = output(x, self.classes)\n",
    "\n",
    "        model = keras.Model(inputs=[input_img, input_depth_img], outputs=x)\n",
    "\n",
    "        optimizer = hp.Choice(\"optimizer\", [\"RMSprop\", \"sgd\"])\n",
    "        model.compile(\n",
    "            optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "        )\n",
    "        model.summary()\n",
    "\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Dense, concatenate\n",
    "# define two sets of inputs\n",
    "inputA = Input(shape=(128,))\n",
    "inputB = Input(shape=(128,))\n",
    "# the first branch operates on the first input\n",
    "x = Dense(8, activation=\"relu\")(inputA)\n",
    "x = Dense(4, activation=\"relu\")(x)\n",
    "x = Model(inputs=inputA, outputs=x)\n",
    "# the second branch opreates on the second input\n",
    "y = Dense(64, activation=\"relu\")(inputB)\n",
    "y = Dense(32, activation=\"relu\")(y)\n",
    "y = Dense(4, activation=\"relu\")(y)\n",
    "y = Model(inputs=inputB, outputs=y)\n",
    "# combine the output of the two branches\n",
    "combined = concatenate([x.output, y.output])\n",
    "# apply a FC layer and then a regression prediction on the\n",
    "# combined outputs\n",
    "z = Dense(2, activation=\"relu\")(combined)\n",
    "z = Dense(1, activation=\"linear\")(z)\n",
    "# our model will accept the inputs of the two branches and\n",
    "# then output a single value\n",
    "model = Model(inputs=[x.input, y.input], outputs=z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W8N45E-xTff3",
    "outputId": "80f3b288-8108-4068-d646-e281abd1de41"
   },
   "outputs": [],
   "source": [
    "#SqueezeSEAuto random\n",
    "hp = HyperParameters()\n",
    "\n",
    "import neptune\n",
    "\n",
    "ratio = 1.0\n",
    "PROJECT = \"squeezeSEAutoDepthRandom\"+str(ratio)\n",
    "neptune.create_experiment(PROJECT)\n",
    "\n",
    " \n",
    "# This will override the `learning_rate` parameter with your\n",
    "# own selection of choices\n",
    "\n",
    "hp.Choice(\"learning_rate\", values=[ 1e-3, 1e-4])\n",
    "\n",
    "\n",
    "\n",
    "#fn_name = globals()[\"build_SqueezeNet_11_fixed\"](hp)\n",
    "# SqueezeNet \n",
    "\n",
    "mymodel = SqueezeNetSEAutoModel(classes=nb_classes)\n",
    "\n",
    " \n",
    "     \n",
    "tuner = RandomSearch(\n",
    "    #build_SqueezeNet_11_fixed,\n",
    "    #build_squeezenet_auto_model,\n",
    "    #build_model,\n",
    "    \n",
    "    hypermodel=mymodel,\n",
    "    hyperparameters = hp,\n",
    "    objective=Objective(\"val_accuracy\", direction=\"max\"),\n",
    "    max_trials=100,\n",
    "    executions_per_trial=1,\n",
    "    overwrite=True,\n",
    "    directory=\"mytest3_dir\",\n",
    "    project_name=PROJECT,\n",
    "    #distribution_strategy=tf.distribute.MirroredStrategy(),\n",
    "    logger = npt_utils.NeptuneLogger(),\n",
    "     \n",
    ")\n",
    "tuner.search_space_summary()\n",
    "\n",
    " \n",
    "\"\"\"\"lr_finder = LRFinder(min_lr=1e-5, \n",
    "                    max_lr=1e-3,\n",
    "                    steps_per_epoch=np.ceil(EPOCH/batch_size),\n",
    "                    epochs=3)\"\"\"\n",
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping('val_accuracy', patience=10),\n",
    "    #lr_finder,\n",
    "    #tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5'),\n",
    "    #tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "]\n",
    "\n",
    "tuner.search(x_train[:int(ratio*len(x_train))], y_train[:int(ratio*len(y_train))], epochs=EPOCH, callbacks = my_callbacks,validation_data=(x_test[:int(ratio*len(x_test))], y_test[:int(ratio*len(y_test))]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "models = tuner.get_best_models(num_models=10)\n",
    "tuner.results_summary()\n",
    "npt_utils.log_tuner_info(tuner)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_tuner.engine.hypermodel import maybe_compute_model_size\n",
    "\n",
    "for i in range(len(models)):\n",
    "    print(\"{}, {}\".format(i,maybe_compute_model_size(models[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Baysian Depth\n",
    "#SqueezeSEAuto random\n",
    "hp = HyperParameters()\n",
    "\n",
    "import neptune\n",
    "\n",
    "ratio = 1.0\n",
    "PROJECT = \"squeezeSEAutoDepthBaysian2\"+str(ratio)\n",
    "neptune.create_experiment(PROJECT)\n",
    "\n",
    " \n",
    "# This will override the `learning_rate` parameter with your\n",
    "# own selection of choices\n",
    "\n",
    "hp.Choice(\"learning_rate\", values=[ 1e-3, 1e-4])\n",
    "\n",
    "\n",
    "\n",
    "#fn_name = globals()[\"build_SqueezeNet_11_fixed\"](hp)\n",
    "# SqueezeNet \n",
    "\n",
    "mymodel = SqueezeNetSEAutoModel  (classes=nb_classes)\n",
    "\n",
    " \n",
    "     \n",
    "\n",
    "\n",
    "tuner = BayesianOptimization(\n",
    "    #build_SqueezeNet_11_fixed,\n",
    "    #build_squeezenet_auto_model,\n",
    "    #build_model,\n",
    "    \n",
    "    hypermodel=mymodel,\n",
    "    hyperparameters = hp,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=100,\n",
    "    executions_per_trial=1,\n",
    "    overwrite=True,\n",
    "    directory=\"mytest3_dir\",\n",
    "    project_name= PROJECT,\n",
    "    #distribution_strategy=tf.distribute.MirroredStrategy(),\n",
    "    num_initial_points=2,\n",
    "    alpha=0.0001,\n",
    "    beta=2.6,\n",
    "    seed=None,\n",
    "    tune_new_entries=True,\n",
    "    allow_new_entries=True,\n",
    "    logger = npt_utils.NeptuneLogger(),\n",
    "     \n",
    ")\n",
    " \n",
    "    \n",
    "tuner.search_space_summary()\n",
    "\n",
    " \n",
    "\"\"\"\"lr_finder = LRFinder(min_lr=1e-5, \n",
    "                    max_lr=1e-3,\n",
    "                    steps_per_epoch=np.ceil(EPOCH/batch_size),\n",
    "                    epochs=3)\"\"\"\n",
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping('val_accuracy', patience=10),\n",
    "    #lr_finder,\n",
    "    #tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5'),\n",
    "    #tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "]\n",
    "\n",
    "tuner.search(x_train[:int(ratio*len(x_train))], y_train[:int(ratio*len(y_train))], epochs=EPOCH, callbacks = my_callbacks,validation_data=(x_test[:int(ratio*len(x_test))], y_test[:int(ratio*len(y_test))]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "models = tuner.get_best_models(num_models=10)\n",
    "tuner.results_summary()\n",
    "npt_utils.log_tuner_info(tuner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_tuner.engine.hypermodel import maybe_compute_model_size\n",
    "\n",
    "for i in range(len(models)):\n",
    "    print(\"{}, {}\".format(i,maybe_compute_model_size(models[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyper\n",
    "#Baysian Depth\n",
    "#SqueezeSEAuto random\n",
    "from keras_tuner import HyperParameters\n",
    "from keras_tuner import RandomSearch,Hyperband,SklearnTuner,BayesianOptimization\n",
    "from tensorflow.keras import layers\n",
    "    \n",
    "hp = HyperParameters()\n",
    "\n",
    "import neptune\n",
    "\n",
    "ratio = 1.0\n",
    "PROJECT = \"squeezeSEAutoDepthHyperband\"+str(ratio)\n",
    "neptune.create_experiment(PROJECT)\n",
    "EPOCH = 100\n",
    " \n",
    "# This will override the `learning_rate` parameter with your\n",
    "# own selection of choices\n",
    "\n",
    "hp.Choice(\"learning_rate\", values=[ 1e-3, 1e-4])\n",
    "\n",
    "\n",
    "\n",
    "#fn_name = globals()[\"build_SqueezeNet_11_fixed\"](hp)\n",
    "# SqueezeNet \n",
    "\n",
    "mymodel = SqueezeNetSEAutoModel  (classes=nb_classes)\n",
    "\n",
    " \n",
    "     \n",
    "\n",
    "\n",
    "    \n",
    "tuner = Hyperband(\n",
    "    #build_SqueezeNet_11_fixed,\n",
    "    #build_squeezenet_auto_model,\n",
    "    #build_model,\n",
    "    \n",
    "    hypermodel=mymodel,\n",
    "    hyperparameters = hp,\n",
    "    objective=\"val_accuracy\",\n",
    "    #max_trials=20,\n",
    "    executions_per_trial=1,\n",
    "    overwrite=True,\n",
    "    directory=\"mytest3_dir\",\n",
    "    project_name=PROJECT,\n",
    "    #distribution_strategy=tf.distribute.MirroredStrategy(),\n",
    "    max_epochs=EPOCH,\n",
    "    logger = npt_utils.NeptuneLogger(),\n",
    "     \n",
    ")\n",
    "    \n",
    "tuner.search_space_summary()\n",
    "\n",
    " \n",
    "\"\"\"\"lr_finder = LRFinder(min_lr=1e-5, \n",
    "                    max_lr=1e-3,\n",
    "                    steps_per_epoch=np.ceil(EPOCH/batch_size),\n",
    "                    epochs=3)\"\"\"\n",
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping('val_accuracy', patience=10),\n",
    "    #lr_finder,\n",
    "    #tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5'),\n",
    "    #tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "]\n",
    "\n",
    "tuner.search(x_train[:int(ratio*len(x_train))], y_train[:int(ratio*len(y_train))], epochs=EPOCH, callbacks = my_callbacks,validation_data=(x_test[:int(ratio*len(x_test))], y_test[:int(ratio*len(y_test))]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = tuner.get_best_models(num_models=10)\n",
    "tuner.results_summary()\n",
    "npt_utils.log_tuner_info(tuner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras_tuner.engine.hypermodel import maybe_compute_model_size\n",
    "\n",
    "for i in range(len(models)):\n",
    "    print(\"{}, {}\".format(i,maybe_compute_model_size(models[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SqueezeSE Multi 1 Auto random\n",
    "hp = HyperParameters()\n",
    "\n",
    "import neptune\n",
    "\n",
    "ratio = 1.0\n",
    "PROJECT = \"squeezeSE_Multi_1_AutoDepthRandom\"+str(ratio)\n",
    "neptune.create_experiment(PROJECT)\n",
    "\n",
    " \n",
    "# This will override the `learning_rate` parameter with your\n",
    "# own selection of choices\n",
    "\n",
    "hp.Choice(\"learning_rate\", values=[ 1e-3, 1e-4])\n",
    "\n",
    "\n",
    "\n",
    "#fn_name = globals()[\"build_SqueezeNet_11_fixed\"](hp)\n",
    "# SqueezeNet \n",
    "\n",
    "mymodel = SqueezeNetSEMulti_1_AutoModel (classes=nb_classes)\n",
    "\n",
    " \n",
    "     \n",
    "tuner = RandomSearch(\n",
    "    #build_SqueezeNet_11_fixed,\n",
    "    #build_squeezenet_auto_model,\n",
    "    #build_model,\n",
    "    \n",
    "    hypermodel=mymodel,\n",
    "    hyperparameters = hp,\n",
    "    objective=Objective(\"val_accuracy\", direction=\"max\"),\n",
    "    max_trials=100,\n",
    "    executions_per_trial=1,\n",
    "    overwrite=True,\n",
    "    directory=\"mytest4_dir\",\n",
    "    project_name=PROJECT,\n",
    "    #distribution_strategy=tf.distribute.MirroredStrategy(),\n",
    "    logger = npt_utils.NeptuneLogger(),\n",
    "     \n",
    ")\n",
    "tuner.search_space_summary()\n",
    "\n",
    " \n",
    "\"\"\"\"lr_finder = LRFinder(min_lr=1e-5, \n",
    "                    max_lr=1e-3,\n",
    "                    steps_per_epoch=np.ceil(EPOCH/batch_size),\n",
    "                    epochs=3)\"\"\"\n",
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping('val_accuracy', patience=10),\n",
    "    #lr_finder,\n",
    "    #tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5'),\n",
    "    #tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "]\n",
    "\n",
    "tuner.search(\n",
    "    x=[x_train1[:int(ratio*len(x_train1))], x_train2[:int(ratio*len(x_train2))]],y= y_train[:int(ratio*len(y_train))], epochs=EPOCH, callbacks = my_callbacks,validation_data=([x_test1[:int(ratio*len(x_test1))], x_test2[:int(ratio*len(x_test2))]], y_test[:int(ratio*len(y_test))]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = tuner.get_best_models(num_models=10)\n",
    "tuner.results_summary()\n",
    "npt_utils.log_tuner_info(tuner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras_tuner.engine.hypermodel import maybe_compute_model_size\n",
    "\n",
    "for i in range(len(models)):\n",
    "    print(\"{}, {}\".format(i,maybe_compute_model_size(models[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SqueezeSE Multi 1 Auto Bayes\n",
    "import neptune\n",
    "hp = HyperParameters()\n",
    "\n",
    "\n",
    "ratio = 1.0\n",
    "PROJECT = \"squeezeSE_Multi_1_AutoDepthBayes\"+str(ratio)\n",
    "neptune.create_experiment(PROJECT)\n",
    "\n",
    "\n",
    "# This will override the `learning_rate` parameter with your\n",
    "# own selection of choices\n",
    "\n",
    "hp.Choice(\"learning_rate\", values=[1e-3, 1e-4])\n",
    "\n",
    "\n",
    "#fn_name = globals()[\"build_SqueezeNet_11_fixed\"](hp)\n",
    "# SqueezeNet\n",
    "\n",
    "mymodel = SqueezeNetSEMulti_1_AutoModel(classes=nb_classes)\n",
    "\n",
    "\n",
    "tuner = BayesianOptimization(\n",
    "    # build_SqueezeNet_11_fixed,\n",
    "    # build_squeezenet_auto_model,\n",
    "    # build_model,\n",
    "\n",
    "    hypermodel=mymodel,\n",
    "    hyperparameters=hp,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=100,\n",
    "    executions_per_trial=1,\n",
    "    overwrite=True,\n",
    "    directory=\"mytest4_dir\",\n",
    "    project_name=PROJECT,\n",
    "    # distribution_strategy=tf.distribute.MirroredStrategy(),\n",
    "    num_initial_points=2,\n",
    "    alpha=0.0001,\n",
    "    beta=2.6,\n",
    "    seed=None,\n",
    "    tune_new_entries=True,\n",
    "    allow_new_entries=True,\n",
    "    logger=npt_utils.NeptuneLogger(),\n",
    "\n",
    "\n",
    ")\n",
    "tuner.search_space_summary()\n",
    "\n",
    "\n",
    "\"\"\"\"lr_finder = LRFinder(min_lr=1e-5, \n",
    "                    max_lr=1e-3,\n",
    "                    steps_per_epoch=np.ceil(EPOCH/batch_size),\n",
    "                    epochs=3)\"\"\"\n",
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping('val_accuracy', patience=10),\n",
    "    # lr_finder,\n",
    "    # tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5'),\n",
    "    # tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "]\n",
    "\n",
    "tuner.search(\n",
    "    x=[x_train1[:int(ratio*len(x_train1))], x_train2[:int(ratio*len(x_train2))]], y=y_train[:int(ratio*len(y_train))], epochs=EPOCH, callbacks=my_callbacks, validation_data=([x_test1[:int(ratio*len(x_test1))], x_test2[:int(ratio*len(x_test2))]], y_test[:int(ratio*len(y_test))]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = tuner.get_best_models(num_models=10)\n",
    "tuner.results_summary()\n",
    "npt_utils.log_tuner_info(tuner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras_tuner.engine.hypermodel import maybe_compute_model_size\n",
    "\n",
    "for i in range(len(models)):\n",
    "    print(\"{}, {}\".format(i,maybe_compute_model_size(models[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neptune\n",
    "\n",
    "from keras_tuner import HyperParameters\n",
    "from keras_tuner import RandomSearch,Hyperband,SklearnTuner,BayesianOptimization\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SqueezeSEAuto  Multi Hyper\n",
    "hp = HyperParameters()\n",
    "\n",
    "\n",
    "ratio = 1.0\n",
    "PROJECT = \"squeezeSE_Multi_1_AutoDepthHyper\"+str(ratio)\n",
    "neptune.create_experiment(PROJECT)\n",
    "\n",
    "\n",
    "# This will override the `learning_rate` parameter with your\n",
    "# own selection of choices\n",
    "\n",
    "hp.Choice(\"learning_rate\", values=[1e-3, 1e-4])\n",
    "\n",
    "\n",
    "#fn_name = globals()[\"build_SqueezeNet_11_fixed\"](hp)\n",
    "# SqueezeNet\n",
    "\n",
    "mymodel = SqueezeNetSEMulti_1_AutoModel(classes=nb_classes)\n",
    "\n",
    "\n",
    "EPOCH = 100\n",
    "\n",
    "\n",
    "tuner = Hyperband(\n",
    "    # build_SqueezeNet_11_fixed,\n",
    "    # build_squeezenet_auto_model,\n",
    "    # build_model,\n",
    "\n",
    "    hypermodel=mymodel,\n",
    "    hyperparameters=hp,\n",
    "    objective=\"val_accuracy\",\n",
    "    # max_trials=20,\n",
    "    executions_per_trial=1,\n",
    "    overwrite=True,\n",
    "    directory=\"mytest4_dir\",\n",
    "    project_name=PROJECT,\n",
    "    # distribution_strategy=tf.distribute.MirroredStrategy(),\n",
    "    max_epochs=EPOCH,\n",
    "    logger=npt_utils.NeptuneLogger(),\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "tuner.search_space_summary()\n",
    "\n",
    "\n",
    "\"\"\"\"lr_finder = LRFinder(min_lr=1e-5, \n",
    "                    max_lr=1e-3,\n",
    "                    steps_per_epoch=np.ceil(EPOCH/batch_size),\n",
    "                    epochs=3)\"\"\"\n",
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping('val_accuracy', patience=10),\n",
    "    # lr_finder,\n",
    "    # tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5'),\n",
    "    # tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "]\n",
    "\n",
    "tuner.search(\n",
    "    x=[x_train1[:int(ratio*len(x_train1))], x_train2[:int(ratio*len(x_train2))]], y=y_train[:int(ratio*len(y_train))], epochs=EPOCH, callbacks=my_callbacks, validation_data=([x_test1[:int(ratio*len(x_test1))], x_test2[:int(ratio*len(x_test2))]], y_test[:int(ratio*len(y_test))]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = tuner.get_best_models(num_models=10)\n",
    "tuner.results_summary()\n",
    "npt_utils.log_tuner_info(tuner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_tuner.engine.hypermodel import maybe_compute_model_size\n",
    "\n",
    "for i in range(len(models)):\n",
    "    print(\"{}, {}\".format(i,maybe_compute_model_size(models[i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SqueezeNet SE Auto Multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_tuner import HyperModel\n",
    "\n",
    "\n",
    "def squeeze_excitation_layer(input_layer, out_dim, ratio, conv=False):\n",
    "    squeeze = layers.GlobalAveragePooling2D()(input_layer)\n",
    "\n",
    "    excitation = layers.Dense(units=out_dim / ratio,\n",
    "                              activation='relu')(squeeze)\n",
    "    excitation = layers.Dense(out_dim, activation='sigmoid')(excitation)\n",
    "    excitation = tf.reshape(excitation, [-1, 1, 1, out_dim])\n",
    "\n",
    "    scale = layers.multiply([input_layer, excitation])\n",
    "\n",
    "    if conv:\n",
    "        shortcut = tf.keras.layers.Conv2D(out_dim, kernel_size=1, strides=1,\n",
    "                                          padding='same', kernel_initializer='he_normal')(input_layer)\n",
    "        shortcut = tf.keras.layers.BatchNormalization()(shortcut)\n",
    "    else:\n",
    "        shortcut = input_layer\n",
    "\n",
    "    out = scale  # tf.keras.layers.add([shortcut, scale])\n",
    "    return out\n",
    "\n",
    "\n",
    "# SqueezeNet auto\n",
    "\n",
    "\n",
    "class SqueezeNetSEMulti_AutoModel(HyperModel):\n",
    "    def __init__(self, classes):\n",
    "        self.classes = classes\n",
    "\n",
    "    def build(self, hp):\n",
    "\n",
    "        compression_val = hp.Fixed('compression', 1.0)\n",
    "\n",
    "        input_img = layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "        input_depth_img = layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "\n",
    "        x = layers.Conv2D(int(96*compression_val), (3, 3), activation='relu',\n",
    "                          strides=(2, 2), padding='same', name='conv1x')(input_img)\n",
    "\n",
    "        x = layers.MaxPooling2D(pool_size=(\n",
    "            3, 3), strides=(2, 2), name='maxpool1x')(x)\n",
    "\n",
    "        y = layers.Conv2D(int(96*compression_val), (3, 3), activation='relu',\n",
    "                          strides=(2, 2), padding='same', name='conv1y')(input_depth_img)\n",
    "\n",
    "        y = layers.MaxPooling2D(pool_size=(\n",
    "            3, 3), strides=(2, 2), name='maxpool1y')(y)\n",
    "\n",
    "        # x = layers.Add (name='concat_input')([x, y])  ## merge\n",
    "\n",
    "        j = 2\n",
    "        filter_size = 16\n",
    "\n",
    "        num_fire = hp.Int(\"fire_module\", 1, 2, default=2)\n",
    "        use_bypass = [hp.Boolean('use_bypass'+str(i)) for i in range(num_fire)]\n",
    "        pooling = [hp.Choice('pooling'+str(i), [\"max\", \"avg\"])\n",
    "                   for i in range(num_fire)]\n",
    "\n",
    "        print(use_bypass)\n",
    "        print(pooling)\n",
    "\n",
    "        done_merge = False\n",
    "\n",
    "        for i in range(num_fire):\n",
    "\n",
    "            ratio = hp.Choice(\"squeeze_ratio\"+str(j), [8, 16, 32], default=32)\n",
    "            x_in = x\n",
    "            x = create_fire_module(\n",
    "                x, int(filter_size*compression_val), name='fire'+str(j), )\n",
    "\n",
    "            if not done_merge:\n",
    "                y_in = y\n",
    "                y = create_fire_module(\n",
    "                    y, int(filter_size*compression_val), name='fire_y'+str(j), )\n",
    "\n",
    "            se_insert = hp.Boolean(\"SE_add\"+str(j))\n",
    "\n",
    "            if se_insert:\n",
    "                x = squeeze_excitation_layer(\n",
    "                    x, out_dim=x.shape[3], ratio=ratio)\n",
    "                if not done_merge:\n",
    "                    y = squeeze_excitation_layer(\n",
    "                        y, out_dim=y.shape[3], ratio=ratio)\n",
    "\n",
    "                if hp.Boolean(\"SE_skip\"+str(j)):\n",
    "                    if x_in.shape[3] != x.shape[3]:\n",
    "                        x_in = layers.Conv2D(x.shape[3], kernel_size=1, strides=1,\n",
    "                                             padding='same', kernel_initializer='he_normal')(x_in)\n",
    "                        x_in = tf.keras.layers.BatchNormalization()(x_in)\n",
    "\n",
    "                        if not done_merge:\n",
    "                            y_in = layers.Conv2D(y.shape[3], kernel_size=1, strides=1,\n",
    "                                                 padding='same', kernel_initializer='he_normal')(y_in)\n",
    "                            y_in = tf.keras.layers.BatchNormalization()(y_in)\n",
    "\n",
    "                    x = tf.keras.layers.add([x_in, x])\n",
    "                    if not done_merge:\n",
    "                        y = tf.keras.layers.add([y_in, y])\n",
    "\n",
    "            if not done_merge:\n",
    "                merge_f = hp.Boolean(\"Merge\"+str(j))\n",
    "                if merge_f:\n",
    "                    x = layers.Add(name='merge'+str(i))([x, y])  # merge\n",
    "                    done_merge = True\n",
    "\n",
    "            ratio = hp.Choice(\"squeeze_ratio\"+str(j), [8, 16, 32], default=32)\n",
    "            x_in = x\n",
    "            x = create_fire_module(x, int(\n",
    "                filter_size*compression_val), name='fire'+str(j+1), use_bypass=use_bypass[i])\n",
    "\n",
    "            if not done_merge:\n",
    "                y_in = y\n",
    "                y = create_fire_module(y, int(\n",
    "                    filter_size*compression_val), name='fire_y'+str(j+1), use_bypass=use_bypass[i])\n",
    "\n",
    "            se_insert = hp.Boolean(\"SE_add\"+str(j+1))\n",
    "\n",
    "            if se_insert:\n",
    "\n",
    "                x = squeeze_excitation_layer(\n",
    "                    x, out_dim=x.shape[3], ratio=ratio)\n",
    "\n",
    "                if not done_merge:\n",
    "                    y = squeeze_excitation_layer(\n",
    "                        y, out_dim=y.shape[3], ratio=ratio)\n",
    "\n",
    "                if hp.Boolean(\"SE_skip\"+str(j+1)):\n",
    "                    if x_in.shape[3] != x.shape[3]:\n",
    "                        x_in = layers.Conv2D(x.shape[3], kernel_size=1, strides=1,\n",
    "                                             padding='same', kernel_initializer='he_normal')(x_in)\n",
    "                        x_in = tf.keras.layers.BatchNormalization()(x_in)\n",
    "\n",
    "                        if not done_merge:\n",
    "                            y_in = layers.Conv2D(y.shape[3], kernel_size=1, strides=1,\n",
    "                                                 padding='same', kernel_initializer='he_normal')(y_in)\n",
    "                            y_in = tf.keras.layers.BatchNormalization()(y_in)\n",
    "\n",
    "                    x = tf.keras.layers.add([x_in, x])\n",
    "                    if not done_merge:\n",
    "                        y = tf.keras.layers.add([y_in, y])\n",
    "\n",
    "            if not done_merge:\n",
    "                merge_f = hp.Boolean(\"Merge\"+str(j+1))\n",
    "                if merge_f:\n",
    "                    x = layers.Add(name='merge')([x, y])  # merge\n",
    "                    done_merge = True\n",
    "\n",
    "            # if hp.Choice(\"pooling\", [\"max\", \"avg\"]) == \"max\":\n",
    "            if pooling[i] == \"max\":\n",
    "\n",
    "                x = layers.MaxPooling2D(pool_size=(3, 3), strides=(\n",
    "                    2, 2), name='maxpool'+str(j+1))(x)\n",
    "                if not done_merge:\n",
    "\n",
    "                    y = layers.MaxPooling2D(pool_size=(3, 3), strides=(\n",
    "                        2, 2), name='maxpool_y'+str(j+1))(y)\n",
    "\n",
    "            else:\n",
    "                x = layers.AveragePooling2D(pool_size=(\n",
    "                    3, 3), strides=(2, 2), name='avgpool'+str(j+1))(x)\n",
    "                if not done_merge:\n",
    "\n",
    "                    y = layers.MaxPooling2D(pool_size=(3, 3), strides=(\n",
    "                        2, 2), name='maxpool_y'+str(j+1))(y)\n",
    "\n",
    "            if not done_merge:\n",
    "                merge_f = hp.Boolean(\"Merge\"+str(j+1))\n",
    "                if merge_f:\n",
    "                    x = layers.Add(name='merge')([x, y])  # merge\n",
    "                    done_merge = True\n",
    "\n",
    "            j = j+2\n",
    "            filter_size = filter_size+16\n",
    "\n",
    "        num_fire2 = hp.Int('num_fire_2', 0, 2, default=2)\n",
    "        use_bypass2 = [hp.Boolean('use_bypass_2'+str(i))\n",
    "                       for i in range(num_fire2)]\n",
    "\n",
    "        print(use_bypass2)\n",
    "\n",
    "        for i in range(num_fire2):\n",
    "\n",
    "            ratio = hp.Choice(\"squeeze_ratio\"+str(j), [8, 16, 32], default=32)\n",
    "\n",
    "            x_in = x\n",
    "            x = create_fire_module(\n",
    "                x, int(filter_size*compression_val), name='fire'+str(j))\n",
    "\n",
    "            if not done_merge:\n",
    "                y_in = y\n",
    "                y = create_fire_module(\n",
    "                    y, int(filter_size*compression_val), name='fire_y'+str(j))\n",
    "\n",
    "            if not done_merge:\n",
    "                merge_f = hp.Boolean(\"Merge\"+str(j))\n",
    "                if merge_f:\n",
    "                    x = layers.Add(name='merge')([x, y])  # merge\n",
    "                    done_merge = True\n",
    "\n",
    "            se_insert = hp.Boolean(\"SE_add\"+str(j))\n",
    "\n",
    "            if se_insert:\n",
    "                x = squeeze_excitation_layer(\n",
    "                    x, out_dim=x.shape[3], ratio=ratio)\n",
    "                if not done_merge:\n",
    "                    y = squeeze_excitation_layer(\n",
    "                        y, out_dim=x.shape[3], ratio=ratio)\n",
    "\n",
    "                if hp.Boolean(\"SE_skip\"+str(j)):\n",
    "                    if x_in.shape[3] != x.shape[3]:\n",
    "                        x_in = layers.Conv2D(x.shape[3], kernel_size=1, strides=1,\n",
    "                                             padding='same', kernel_initializer='he_normal')(x_in)\n",
    "                        x_in = tf.keras.layers.BatchNormalization()(x_in)\n",
    "\n",
    "                        if not done_merge:\n",
    "                            y_in = layers.Conv2D(y.shape[3], kernel_size=1, strides=1,\n",
    "                                                 padding='same', kernel_initializer='he_normal')(y_in)\n",
    "                            y_in = tf.keras.layers.BatchNormalization()(y_in)\n",
    "\n",
    "                    x = tf.keras.layers.add([x_in, x])\n",
    "                    if not done_merge:\n",
    "\n",
    "                        y = tf.keras.layers.add([y_in, y])\n",
    "\n",
    "            if not done_merge:\n",
    "                merge_f = hp.Boolean(\"Merge\"+str(j))\n",
    "                if merge_f:\n",
    "                    x = layers.Add(name='merge')([x, y])  # merge\n",
    "                    done_merge = True\n",
    "\n",
    "            ratio = hp.Choice(\"squeeze_ratio\"+str(j), [8, 16, 32], default=32)\n",
    "\n",
    "            x_in = x\n",
    "            x = create_fire_module(x, int(\n",
    "                filter_size*compression_val), name='fire'+str(j+1), use_bypass=use_bypass2[i])\n",
    "\n",
    "            if not done_merge:\n",
    "                y_in = y\n",
    "                y = create_fire_module(y, int(\n",
    "                    filter_size*compression_val), name='fire_y'+str(j+1), use_bypass=use_bypass2[i])\n",
    "\n",
    "            se_insert = hp.Boolean(\"SE_add\"+str(j+1))\n",
    "\n",
    "            if se_insert:\n",
    "                x = squeeze_excitation_layer(\n",
    "                    x, out_dim=x.shape[3], ratio=ratio)\n",
    "\n",
    "                if not done_merge:\n",
    "                    y = squeeze_excitation_layer(\n",
    "                        y, out_dim=y.shape[3], ratio=ratio)\n",
    "\n",
    "                if hp.Boolean(\"SE_skip\"+str(j+1)):\n",
    "                    if x_in.shape[3] != x.shape[3]:\n",
    "                        x_in = layers.Conv2D(x.shape[3], kernel_size=1, strides=1,\n",
    "                                             padding='same', kernel_initializer='he_normal')(x_in)\n",
    "                        x_in = tf.keras.layers.BatchNormalization()(x_in)\n",
    "\n",
    "                        if not done_merge:\n",
    "                            y_in = layers.Conv2D(y.shape[3], kernel_size=1, strides=1,\n",
    "                                                 padding='same', kernel_initializer='he_normal')(y_in)\n",
    "                            y_in = tf.keras.layers.BatchNormalization()(y_in)\n",
    "\n",
    "                    x = tf.keras.layers.add([x_in, x])\n",
    "                    if not done_merge:\n",
    "                        y = tf.keras.layers.add([y_in, y])\n",
    "\n",
    "            if not done_merge:\n",
    "                merge_f = hp.Boolean(\"Merge\"+str(j+1))\n",
    "                if merge_f:\n",
    "                    layers.Add(name='merge')([x, y])  # merge\n",
    "                    done_merge = True\n",
    "\n",
    "            filter_size = filter_size+16\n",
    "            j = j+2\n",
    "\n",
    "            #x = create_fire_module(x, int(filter_size*compression_val), name='fire8')\n",
    "            #x = create_fire_module(x, int(filter_size*compression_val), name='fire9',use_bypass=hp.Boolean('use_bypass'))\n",
    "\n",
    "        if not done_merge:\n",
    "\n",
    "            x = layers.Add(name='merge')([x, y])  # merge\n",
    "            done_merge = True\n",
    "\n",
    "        dropout_rate = hp.Float('dropout_rate', 0.0, 0.8)\n",
    "        if dropout_rate:\n",
    "            x = layers.Dropout(dropout_rate)(x)\n",
    "\n",
    "        x = output(x, self.classes)\n",
    "\n",
    "        model = keras.Model(inputs=[input_img, input_depth_img], outputs=x)\n",
    "\n",
    "        optimizer = hp.Choice(\"optimizer\", [\"RMSprop\", \"sgd\"])\n",
    "        model.compile(\n",
    "            optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "        )\n",
    "        model.summary()\n",
    "\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SqueezeSE Multi 1 Auto random\n",
    "hp = HyperParameters()\n",
    "\n",
    "import neptune\n",
    "\n",
    "ratio = 1.0\n",
    "PROJECT = \"squeezeSE_Multi_n_AutoDepthRandom\"+str(ratio)\n",
    "neptune.create_experiment(PROJECT)\n",
    "\n",
    " \n",
    "# This will override the `learning_rate` parameter with your\n",
    "# own selection of choices\n",
    "\n",
    "hp.Choice(\"learning_rate\", values=[ 1e-3, 1e-4])\n",
    "\n",
    "\n",
    "\n",
    "#fn_name = globals()[\"build_SqueezeNet_11_fixed\"](hp)\n",
    "# SqueezeNet \n",
    "\n",
    "mymodel = SqueezeNetSEMulti_AutoModel (classes=nb_classes)\n",
    "\n",
    " \n",
    "     \n",
    "tuner = RandomSearch(\n",
    "    #build_SqueezeNet_11_fixed,\n",
    "    #build_squeezenet_auto_model,\n",
    "    #build_model,\n",
    "    \n",
    "    hypermodel=mymodel,\n",
    "    hyperparameters = hp,\n",
    "    objective=Objective(\"val_accuracy\", direction=\"max\"),\n",
    "    max_trials=100,\n",
    "    executions_per_trial=1,\n",
    "    overwrite=True,\n",
    "    directory=\"mytest4_dir\",\n",
    "    project_name=PROJECT,\n",
    "    #distribution_strategy=tf.distribute.MirroredStrategy(),\n",
    "    logger = npt_utils.NeptuneLogger(),\n",
    "     \n",
    ")\n",
    "tuner.search_space_summary()\n",
    "\n",
    " \n",
    "\"\"\"\"lr_finder = LRFinder(min_lr=1e-5, \n",
    "                    max_lr=1e-3,\n",
    "                    steps_per_epoch=np.ceil(EPOCH/batch_size),\n",
    "                    epochs=3)\"\"\"\n",
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping('val_accuracy', patience=10),\n",
    "    #lr_finder,\n",
    "    #tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5'),\n",
    "    #tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "]\n",
    "\n",
    "tuner.search(\n",
    "    x=[x_train1[:int(ratio*len(x_train1))], x_train2[:int(ratio*len(x_train2))]],y= y_train[:int(ratio*len(y_train))], epochs=EPOCH, callbacks = my_callbacks,validation_data=([x_test1[:int(ratio*len(x_test1))], x_test2[:int(ratio*len(x_test2))]], y_test[:int(ratio*len(y_test))]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = tuner.get_best_models(num_models=10)\n",
    "tuner.results_summary()\n",
    "npt_utils.log_tuner_info(tuner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_tuner.engine.hypermodel import maybe_compute_model_size\n",
    "\n",
    "for i in range(len(models)):\n",
    "    print(\"{}, {}\".format(i,maybe_compute_model_size(models[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SqueezeSE Multi  Auto bayes\n",
    "import neptune\n",
    "hp = HyperParameters()\n",
    "\n",
    "\n",
    "ratio = 1.0\n",
    "PROJECT = \"squeezeSE_Multi_n_AutoDepthBayes\"+str(ratio)\n",
    "neptune.create_experiment(PROJECT)\n",
    "\n",
    "\n",
    "# This will override the `learning_rate` parameter with your\n",
    "# own selection of choices\n",
    "\n",
    "hp.Choice(\"learning_rate\", values=[1e-3, 1e-4])\n",
    "\n",
    "\n",
    "#fn_name = globals()[\"build_SqueezeNet_11_fixed\"](hp)\n",
    "# SqueezeNet\n",
    "\n",
    "mymodel = SqueezeNetSEMulti_AutoModel(classes=nb_classes)\n",
    "\n",
    "\n",
    "tuner = BayesianOptimization(\n",
    "    # build_SqueezeNet_11_fixed,\n",
    "    # build_squeezenet_auto_model,\n",
    "    # build_model,\n",
    "\n",
    "    hypermodel=mymodel,\n",
    "    hyperparameters=hp,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=100,\n",
    "    executions_per_trial=1,\n",
    "    overwrite=True,\n",
    "    directory=\"mytest4_dir\",\n",
    "    project_name=PROJECT,\n",
    "    # distribution_strategy=tf.distribute.MirroredStrategy(),\n",
    "    num_initial_points=2,\n",
    "    alpha=0.0001,\n",
    "    beta=2.6,\n",
    "    seed=None,\n",
    "    tune_new_entries=True,\n",
    "    allow_new_entries=True,\n",
    "    logger=npt_utils.NeptuneLogger(),\n",
    "\n",
    "\n",
    ")\n",
    "tuner.search_space_summary()\n",
    "\n",
    "\n",
    "\"\"\"\"lr_finder = LRFinder(min_lr=1e-5, \n",
    "                    max_lr=1e-3,\n",
    "                    steps_per_epoch=np.ceil(EPOCH/batch_size),\n",
    "                    epochs=3)\"\"\"\n",
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping('val_accuracy', patience=10),\n",
    "    # lr_finder,\n",
    "    # tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5'),\n",
    "    # tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "]\n",
    "\n",
    "tuner.search(\n",
    "    x=[x_train1[:int(ratio*len(x_train1))], x_train2[:int(ratio*len(x_train2))]], y=y_train[:int(ratio*len(y_train))], epochs=EPOCH, callbacks=my_callbacks, validation_data=([x_test1[:int(ratio*len(x_test1))], x_test2[:int(ratio*len(x_test2))]], y_test[:int(ratio*len(y_test))]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = tuner.get_best_models(num_models=10)\n",
    "tuner.results_summary()\n",
    "npt_utils.log_tuner_info(tuner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_tuner.engine.hypermodel import maybe_compute_model_size\n",
    "\n",
    "for i in range(len(models)):\n",
    "    print(\"{}, {}\".format(i,maybe_compute_model_size(models[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SqueezeSEAuto  Multi Hyper\n",
    "hp = HyperParameters()\n",
    "\n",
    "\n",
    "ratio = 1.0\n",
    "PROJECT = \"squeezeSE_Multi_n_AutoDepthHyper\"+str(ratio)\n",
    "neptune.create_experiment(PROJECT)\n",
    "\n",
    "\n",
    "# This will override the `learning_rate` parameter with your\n",
    "# own selection of choices\n",
    "\n",
    "hp.Choice(\"learning_rate\", values=[1e-3, 1e-4])\n",
    "\n",
    "\n",
    "#fn_name = globals()[\"build_SqueezeNet_11_fixed\"](hp)\n",
    "# SqueezeNet\n",
    "\n",
    "mymodel = SqueezeNetSEMulti_AutoModel(classes=nb_classes)\n",
    "\n",
    "\n",
    "EPOCH = 100\n",
    "\n",
    "\n",
    "tuner = Hyperband(\n",
    "    # build_SqueezeNet_11_fixed,\n",
    "    # build_squeezenet_auto_model,\n",
    "    # build_model,\n",
    "\n",
    "    hypermodel=mymodel,\n",
    "    hyperparameters=hp,\n",
    "    objective=\"val_accuracy\",\n",
    "    # max_trials=20,\n",
    "    executions_per_trial=1,\n",
    "    overwrite=True,\n",
    "    directory=\"mytest4_dir\",\n",
    "    project_name=PROJECT,\n",
    "    # distribution_strategy=tf.distribute.MirroredStrategy(),\n",
    "    max_epochs=EPOCH,\n",
    "    logger=npt_utils.NeptuneLogger(),\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "tuner.search_space_summary()\n",
    "\n",
    "\n",
    "\"\"\"\"lr_finder = LRFinder(min_lr=1e-5, \n",
    "                    max_lr=1e-3,\n",
    "                    steps_per_epoch=np.ceil(EPOCH/batch_size),\n",
    "                    epochs=3)\"\"\"\n",
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping('val_accuracy', patience=10),\n",
    "    # lr_finder,\n",
    "    # tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5'),\n",
    "    # tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "]\n",
    "\n",
    "tuner.search(\n",
    "    x=[x_train1[:int(ratio*len(x_train1))], x_train2[:int(ratio*len(x_train2))]], y=y_train[:int(ratio*len(y_train))], epochs=EPOCH, callbacks=my_callbacks, validation_data=([x_test1[:int(ratio*len(x_test1))], x_test2[:int(ratio*len(x_test2))]], y_test[:int(ratio*len(y_test))]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = tuner.get_best_models(num_models=10)\n",
    "tuner.results_summary()\n",
    "npt_utils.log_tuner_info(tuner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_tuner.engine.hypermodel import maybe_compute_model_size\n",
    "\n",
    "for i in range(len(models)):\n",
    "    print(\"{}, {}\".format(i,maybe_compute_model_size(models[i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SAjyE6wXTff3"
   },
   "source": [
    "# Tsinghua dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UDH35bpdTff3"
   },
   "outputs": [],
   "source": [
    "\n",
    "source_dir = '../TsinghuaFEDImages'\n",
    "data_dir = '../TsinghuaFEDClass'  # landmarks of each subject_emotion\n",
    "\n",
    "emotion_class = ['fear', 'neutral', 'surprise',\n",
    "                 'anger', 'content', 'disgust', 'sad', 'happy']\n",
    "\n",
    "IMG_WIDTH = 224\n",
    "IMG_HEIGHT = 224\n",
    "nb_classes = len(emotion_class)\n",
    "\n",
    "\n",
    "def load_dataset(data_folder, img_dir):\n",
    "\n",
    "    img_list = data_folder+'/train.csv'\n",
    "\n",
    "    f = open(img_list)\n",
    "    text = f.read()\n",
    "    lines = text.split()\n",
    "    train_img_files = []\n",
    "    train_labels = []\n",
    "    for l in lines:\n",
    "        data = l.split(',')\n",
    "        train_img_files.append(img_dir+'/'+data[0])\n",
    "        train_labels.append(int(data[1]))\n",
    "\n",
    "    img_train_array = []\n",
    "\n",
    "    img_train_array = []\n",
    "    for filename, label in zip(train_img_files, train_labels):\n",
    "\n",
    "        image = cv2.imread(filename, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH),\n",
    "                           interpolation=cv2.INTER_AREA)\n",
    "        image = np.array(image)\n",
    "        image = image.astype('float32')\n",
    "        image /= 255\n",
    "        img_train_array.append(image)\n",
    "\n",
    "    img_list = data_folder+'/test.csv'\n",
    "\n",
    "    f = open(img_list)\n",
    "    text = f.read()\n",
    "    lines = text.split()\n",
    "    test_img_files = []\n",
    "    test_labels = []\n",
    "    for l in lines:\n",
    "        data = l.split(',')\n",
    "        test_img_files.append(img_dir+'/'+data[0])\n",
    "        test_labels.append(int(data[1]))\n",
    "\n",
    "    img_test_array = []\n",
    "\n",
    "    for filename, label in zip(test_img_files, test_labels):\n",
    "\n",
    "        image = cv2.imread(filename, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        image = cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH),\n",
    "                           interpolation=cv2.INTER_AREA)\n",
    "        image = np.array(image)\n",
    "        image = image.astype('float32')\n",
    "        image /= 255\n",
    "        img_test_array.append(image)\n",
    "\n",
    "    return img_train_array, train_labels, img_test_array, test_labels\n",
    "\n",
    "\n",
    "# load data set\n",
    "x_train, y_train, x_test, y_test = load_dataset(data_dir, source_dir)\n",
    "x_test = np.array(x_test)\n",
    "x_test.reshape(-1, IMG_HEIGHT, IMG_WIDTH, 3)\n",
    "y_test = np.array(y_test)\n",
    "x_train = np.array(x_train)\n",
    "x_train.reshape(-1, IMG_HEIGHT, IMG_WIDTH, 3)\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "y_test = keras.utils.to_categorical(y_test, len(emotion_class))\n",
    "y_train = keras.utils.to_categorical(y_train, len(emotion_class))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tGYzC4LUTff4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "auto_SqueezeNet-input-Tsinghua.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
