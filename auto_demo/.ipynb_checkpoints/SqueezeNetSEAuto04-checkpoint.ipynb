{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b079a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-04 11:47:55.825596: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version:  2.5.0\n",
      "Eager mode:  True\n",
      "WARNING:tensorflow:From /tmp/ipykernel_379834/2268129818.py:20: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "GPU is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-04 11:47:56.520336: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-09-04 11:47:56.525210: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-09-04 11:47:56.608242: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-04 11:47:56.608582: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2070 SUPER computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 40 deviceMemorySize: 7.76GiB deviceMemoryBandwidth: 417.29GiB/s\n",
      "2021-09-04 11:47:56.608601: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-04 11:47:56.610974: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-09-04 11:47:56.611001: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-09-04 11:47:56.612131: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2021-09-04 11:47:56.612295: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2021-09-04 11:47:56.612606: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2021-09-04 11:47:56.613123: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-09-04 11:47:56.613206: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-09-04 11:47:56.613260: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-04 11:47:56.613590: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-04 11:47:56.613893: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-09-04 11:47:56.613916: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-04 11:47:57.037830: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-09-04 11:47:57.037868: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2021-09-04 11:47:57.037875: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2021-09-04 11:47:57.038226: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-04 11:47:57.038793: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-04 11:47:57.039175: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-04 11:47:57.039541: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/device:GPU:0 with 6643 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2070 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    " \n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "import glob, os\n",
    "\n",
    "from tensorflow import keras\n",
    "import cv2\n",
    "\n",
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"GPU is\", \"available\" if tf.test.is_gpu_available() else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9334e468",
   "metadata": {},
   "outputs": [],
   "source": [
    "import neptunecontrib.monitoring.kerastuner as npt_utils\n",
    "from keras_tuner import HyperParameters, Objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faa3e2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "nb_classes = 10\n",
    "IMG_HEIGHT = 32\n",
    "IMG_WIDTH = 32\n",
    "y_train = np.squeeze(y_train)\n",
    "y_test = np.squeeze(y_test)\n",
    "\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "y_test = keras.utils.to_categorical(y_test,10)\n",
    "y_train = keras.utils.to_categorical(y_train,10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e851e8",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96e0b679",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyper paramter squeezenet\n",
    "\n",
    " \n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from keras_tuner import RandomSearch, Hyperband,SklearnTuner,BayesianOptimization\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def get_axis():\n",
    "    axis = -1 if K.image_data_format() == 'channels_last' else 1\n",
    "    return axis\n",
    "\n",
    "def create_fire_module(x, nb_squeeze_filter, name, use_bypass=False):\n",
    "    \"\"\"\n",
    "    Creates a fire module\n",
    "    \n",
    "    Arguments:\n",
    "        x                 : input\n",
    "        nb_squeeze_filter : number of filters of squeeze. The filtersize of expand is 4 times of squeeze\n",
    "        use_bypass        : if True then a bypass will be added\n",
    "        name              : name of module e.g. fire123\n",
    "    \n",
    "    Returns:\n",
    "        x                 : returns a fire module\n",
    "    \"\"\"\n",
    "    \n",
    "    nb_expand_filter = 4 * nb_squeeze_filter\n",
    "    squeeze    = layers.Conv2D(nb_squeeze_filter,(1,1), activation='relu', padding='same', name='%s_squeeze'%name)(x)\n",
    "    expand_1x1 = layers.Conv2D(nb_expand_filter, (1,1), activation='relu', padding='same', name='%s_expand_1x1'%name)(squeeze)\n",
    "    expand_3x3 = layers.Conv2D(nb_expand_filter, (3,3), activation='relu', padding='same', name='%s_expand_3x3'%name)(squeeze)\n",
    "    \n",
    "    axis = get_axis()\n",
    "    x_ret =  layers.Concatenate(axis=axis, name='%s_concatenate'%name)([expand_1x1, expand_3x3])\n",
    "    \n",
    "    if use_bypass:\n",
    "        x_ret =  layers.Add(name='%s_concatenate_bypass'%name)([x_ret, x])\n",
    "        \n",
    "    return x_ret\n",
    "\n",
    "\n",
    "def output(x, nb_classes):\n",
    "    x = layers.Conv2D(nb_classes, (1,1), strides=(1,1), padding='valid', name='conv10')(x)\n",
    "    x = layers.GlobalAveragePooling2D(name='avgpool10')(x)\n",
    "    x = layers.Activation(\"softmax\", name='softmax')(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1161d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def squeeze_excitation_layer(input_layer, out_dim, ratio, conv=False):\n",
    "  squeeze =  layers.GlobalAveragePooling2D()(input_layer)\n",
    "\n",
    "  excitation =  layers.Dense(units=out_dim / ratio, activation='relu')(squeeze)\n",
    "  excitation =  layers.Dense(out_dim,activation='sigmoid')(excitation)\n",
    "  excitation =  tf.reshape(excitation, [-1,1,1,out_dim])\n",
    "\n",
    "  scale =  layers.multiply([input_layer, excitation])\n",
    "\n",
    "  if conv:\n",
    "    shortcut = tf.keras.layers.Conv2D(out_dim,kernel_size=1,strides=1,\n",
    "                                      padding='same',kernel_initializer='he_normal')(input_layer)\n",
    "    shortcut = tf.keras.layers.BatchNormalization()(shortcut)\n",
    "  else:\n",
    "    shortcut = input_layer\n",
    "    \n",
    "  out = scale # tf.keras.layers.add([shortcut, scale])\n",
    "  return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98eceab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SqueezeNet auto\n",
    "from keras_tuner import HyperModel\n",
    "\n",
    "\n",
    "class SqueezeNetSEAutoModel(HyperModel):\n",
    "    def __init__(self, classes):\n",
    "        self.classes = classes\n",
    "\n",
    "    def build(self, hp):\n",
    "       \n",
    "          \n",
    "        compression_val = hp.Fixed('compression',1.0)\n",
    "    \n",
    "        \n",
    "        \n",
    "        input_img =  layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "\n",
    "        \n",
    "        x = layers.Conv2D(int(96*compression_val), (3,3), activation='relu', strides=(2,2), padding='same', name='conv1')(input_img)\n",
    "\n",
    "        x = layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool1')(x)\n",
    "    \n",
    "         \n",
    "\n",
    "        j = 2\n",
    "        filter_size = 16\n",
    "\n",
    "        num_fire = hp.Int(\"fire_module\", 1,2, default=2)\n",
    "        use_bypass = [ hp.Boolean('use_bypass'+str(i)) for i in range(num_fire)]\n",
    "        pooling = [ hp.Choice('pooling'+str(i), [\"max\", \"avg\"]) for i in range(num_fire) ]\n",
    "        \n",
    "        print(use_bypass)\n",
    "        print(pooling)\n",
    "        for i in range(num_fire):\n",
    "         \n",
    "            ratio = hp.Choice(\"squeeze_ratio\"+str(j),[8,16,32], default=32)\n",
    "            x_in = x\n",
    "            x = create_fire_module(x, int(filter_size*compression_val), name='fire'+str(j), )\n",
    "            \n",
    "            se_insert = hp.Boolean(\"SE_add\"+str(j))\n",
    "            \n",
    "            if se_insert:\n",
    "                x = squeeze_excitation_layer(x, out_dim=x.shape[3], ratio=ratio)\n",
    "                \n",
    "                if hp.Boolean(\"SE_skip\"+str(j)):\n",
    "                    if x_in.shape[3] != x.shape[3] :\n",
    "                        x_in =  layers.Conv2D(x.shape[3],kernel_size=1,strides=1,\n",
    "                                      padding='same',kernel_initializer='he_normal')(x_in)\n",
    "                        x_in = tf.keras.layers.BatchNormalization()(x_in)\n",
    "                        \n",
    "                    x = tf.keras.layers.add([x_in, x])\n",
    "                                     \n",
    "            \n",
    "            ratio = hp.Choice(\"squeeze_ratio\"+str(j+1),[8,16,32], default=32)\n",
    "            x_in = x\n",
    "            x = create_fire_module(x, int(filter_size*compression_val), name='fire'+str(j+1),use_bypass=use_bypass[i])\n",
    "\n",
    "            se_insert = hp.Boolean(\"SE_add\"+str(j+1))\n",
    "            \n",
    "            if se_insert:\n",
    "                 \n",
    "                x = squeeze_excitation_layer(x, out_dim=x.shape[3], ratio=ratio)\n",
    "                \n",
    "                if hp.Boolean(\"SE_skip\"+str(j+1)):\n",
    "                    if x_in.shape[3] != x.shape[3] :\n",
    "                        x_in =  layers.Conv2D(x.shape[3],kernel_size=1,strides=1,\n",
    "                                      padding='same',kernel_initializer='he_normal')(x_in)\n",
    "                        x_in = tf.keras.layers.BatchNormalization()(x_in)\n",
    "                        \n",
    "                    x = tf.keras.layers.add([x_in, x])\n",
    "                     \n",
    "            \n",
    "                \n",
    "            #if hp.Choice(\"pooling\", [\"max\", \"avg\"]) == \"max\":\n",
    "            if pooling[i] == \"max\":\n",
    "\n",
    "                x =  layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool'+str(j+1))(x)\n",
    "            else:\n",
    "                x =  layers.AveragePooling2D(pool_size=(3,3), strides=(2,2), name='avgpool'+str(j+1))(x)\n",
    "\n",
    "\n",
    "            j = j+2\n",
    "            filter_size = filter_size+16\n",
    "            \n",
    "        num_fire2 = hp.Int('num_fire_2',0,2, default=2)\n",
    "        use_bypass2 = [ hp.Boolean('use_bypass_2'+str(i)) for i in range(num_fire2)]\n",
    "         \n",
    "        print(use_bypass2)\n",
    "         \n",
    "        for i in range(num_fire2): \n",
    "            \n",
    "            ratio = hp.Choice(\"squeeze_ratio\"+str(j),[8,16,32], default=32)\n",
    "            \n",
    "            x_in = x\n",
    "            x = create_fire_module(x, int(filter_size*compression_val), name='fire'+str(j))\n",
    "            \n",
    "            se_insert = hp.Boolean(\"SE_add\"+str(j))\n",
    "            \n",
    "            if se_insert:\n",
    "                x = squeeze_excitation_layer(x, out_dim=x.shape[3], ratio=ratio)\n",
    "                if hp.Boolean(\"SE_skip\"+str(j)):\n",
    "                    if x_in.shape[3] != x.shape[3] :\n",
    "                        x_in =  layers.Conv2D(x.shape[3],kernel_size=1,strides=1,\n",
    "                                          padding='same',kernel_initializer='he_normal')(x_in)\n",
    "                        x_in = tf.keras.layers.BatchNormalization()(x_in)\n",
    "                    x = tf.keras.layers.add([x_in, x])\n",
    "                \n",
    "            ratio = hp.Choice(\"squeeze_ratio\"+str(j+1),[8,16,32], default=32)\n",
    "            \n",
    "            x_in = x\n",
    "            x = create_fire_module(x, int(filter_size*compression_val), name='fire'+str(j+1),use_bypass=use_bypass2[i])\n",
    "            \n",
    "            se_insert = hp.Boolean(\"SE_add\"+str(j+1))\n",
    "            \n",
    "            if se_insert:\n",
    "                x = squeeze_excitation_layer(x, out_dim=x.shape[3], ratio=ratio)\n",
    "                if hp.Boolean(\"SE_skip\"+str(j+1)):\n",
    "                    if x_in.shape[3] != x.shape[3] :\n",
    "                        x_in =  layers.Conv2D(x.shape[3],kernel_size=1,strides=1,\n",
    "                                          padding='same',kernel_initializer='he_normal')(x_in)\n",
    "                        x_in = tf.keras.layers.BatchNormalization()(x_in)\n",
    "                    x = tf.keras.layers.add([x_in, x])\n",
    "                    \n",
    "            filter_size = filter_size+16\n",
    "            j = j+2\n",
    "\n",
    "            #x = create_fire_module(x, int(filter_size*compression_val), name='fire8')\n",
    "            #x = create_fire_module(x, int(filter_size*compression_val), name='fire9',use_bypass=hp.Boolean('use_bypass'))\n",
    "        \n",
    "        \n",
    "        \n",
    "        dropout_rate = hp.Float('dropout_rate',0.0,0.8)\n",
    "        if dropout_rate:\n",
    "            x = layers.Dropout(dropout_rate)(x)\n",
    "\n",
    "        x = output(x, self.classes)\n",
    "\n",
    "        model = keras.Model(inputs=input_img, outputs=x)\n",
    "\n",
    "        optimizer = hp.Choice(\"optimizer\", [\"RMSprop\", \"sgd\"])\n",
    "        model.compile(\n",
    "            optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "866105cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://gist.github.com/jeremyjordan/ac0229abd4b2b7000aca1643e88e0f02\n",
    "\n",
    "#learning rate callbacks\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "\n",
    "class LRFinder(Callback):\n",
    "    \n",
    "    '''\n",
    "    A simple callback for finding the optimal learning rate range for your model + dataset. \n",
    "    \n",
    "    # Usage\n",
    "        ```python\n",
    "            lr_finder = LRFinder(min_lr=1e-5, \n",
    "                                 max_lr=1e-2, \n",
    "                                 steps_per_epoch=np.ceil(epoch_size/batch_size), \n",
    "                                 epochs=3)\n",
    "            model.fit(X_train, Y_train, callbacks=[lr_finder])\n",
    "            \n",
    "            lr_finder.plot_loss()\n",
    "        ```\n",
    "    \n",
    "    # Arguments\n",
    "        min_lr: The lower bound of the learning rate range for the experiment.\n",
    "        max_lr: The upper bound of the learning rate range for the experiment.\n",
    "        steps_per_epoch: Number of mini-batches in the dataset. Calculated as `np.ceil(epoch_size/batch_size)`. \n",
    "        epochs: Number of epochs to run experiment. Usually between 2 and 4 epochs is sufficient. \n",
    "        \n",
    "    # References\n",
    "        Blog post: jeremyjordan.me/nn-learning-rate\n",
    "        Original paper: https://arxiv.org/abs/1506.01186\n",
    "\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, min_lr=1e-5, max_lr=1e-3, steps_per_epoch=None, epochs=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.min_lr = min_lr\n",
    "        self.max_lr = max_lr\n",
    "        self.total_iterations = steps_per_epoch * epochs\n",
    "        self.iteration = 0\n",
    "        self.history = {}\n",
    "        \n",
    "    def clr(self):\n",
    "        '''Calculate the learning rate.'''\n",
    "        x = self.iteration / self.total_iterations \n",
    "        return self.min_lr + (self.max_lr-self.min_lr) * x\n",
    "        \n",
    "    def on_train_begin(self, logs=None):\n",
    "        '''Initialize the learning rate to the minimum value at the start of training.'''\n",
    "        logs = logs or {}\n",
    "        K.set_value(self.model.optimizer.lr, self.min_lr)\n",
    "        \n",
    "    def on_batch_end(self, epoch, logs=None):\n",
    "        '''Record previous batch statistics and update the learning rate.'''\n",
    "        logs = logs or {}\n",
    "        self.iteration += 1\n",
    "\n",
    "        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n",
    "        self.history.setdefault('iterations', []).append(self.iteration)\n",
    "\n",
    "        for k, v in logs.items():\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "            \n",
    "        K.set_value(self.model.optimizer.lr, self.clr())\n",
    " \n",
    "    def plot_lr(self):\n",
    "        '''Helper function to quickly inspect the learning rate schedule.'''\n",
    "        plt.plot(self.history['iterations'], self.history['lr'])\n",
    "        plt.yscale('log')\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('Learning rate')\n",
    "        plt.show()\n",
    "        \n",
    "    def plot_loss(self):\n",
    "        '''Helper function to quickly observe the learning rate experiment results.'''\n",
    "        plt.plot(self.history['lr'], self.history['loss'])\n",
    "        plt.xscale('log')\n",
    "        plt.xlabel('Learning rate')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70b5ce44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Project(cchantra/keras-tuner)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import neptune\n",
    "neptune.init(project_qualified_name='cchantra/keras-tuner',api_token='eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiI0M2NkYzQyZC01M2MzLTRhYjQtOTQ5Ny05NGY0NTU5MmU2NjUifQ==') # your credentials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff028eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c69316ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 100 Complete [00h 02m 57s]\n",
      "val_accuracy: 0.5982499718666077\n",
      "\n",
      "Best val_accuracy So Far: 0.6970000267028809\n",
      "Total elapsed time: 06h 18m 58s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "[False]\n",
      "['avg']\n",
      "[False]\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.rho\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Results summary\n",
      "Results in mytest_dir/squeezeSEAutoRandom0.4\n",
      "Showing 10 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.001\n",
      "compression: 1.0\n",
      "fire_module: 1\n",
      "use_bypass0: False\n",
      "use_bypass1: True\n",
      "pooling0: avg\n",
      "pooling1: avg\n",
      "squeeze_ratio2: 16\n",
      "SE_add2: False\n",
      "SE_add3: True\n",
      "squeeze_ratio4: 32\n",
      "SE_add4: True\n",
      "SE_add5: True\n",
      "num_fire_2: 1\n",
      "use_bypass_20: False\n",
      "use_bypass_21: True\n",
      "squeeze_ratio6: 32\n",
      "SE_add6: False\n",
      "SE_add7: False\n",
      "squeeze_ratio8: 32\n",
      "SE_add8: True\n",
      "SE_add9: False\n",
      "dropout_rate: 0.1687022971014839\n",
      "optimizer: sgd\n",
      "SE_skip2: True\n",
      "SE_skip5: True\n",
      "SE_skip6: False\n",
      "SE_skip9: False\n",
      "SE_skip3: True\n",
      "SE_skip4: True\n",
      "SE_skip7: True\n",
      "SE_skip8: False\n",
      "Score: 0.6970000267028809\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.001\n",
      "compression: 1.0\n",
      "fire_module: 1\n",
      "use_bypass0: True\n",
      "use_bypass1: True\n",
      "pooling0: avg\n",
      "pooling1: max\n",
      "squeeze_ratio2: 8\n",
      "SE_add2: False\n",
      "SE_add3: True\n",
      "squeeze_ratio4: 16\n",
      "SE_add4: False\n",
      "SE_add5: True\n",
      "num_fire_2: 2\n",
      "use_bypass_20: False\n",
      "use_bypass_21: True\n",
      "squeeze_ratio6: 8\n",
      "SE_add6: True\n",
      "SE_add7: True\n",
      "squeeze_ratio8: 8\n",
      "SE_add8: False\n",
      "SE_add9: True\n",
      "dropout_rate: 0.05667357262344828\n",
      "optimizer: sgd\n",
      "SE_skip2: False\n",
      "SE_skip5: True\n",
      "SE_skip6: True\n",
      "SE_skip9: False\n",
      "SE_skip3: False\n",
      "SE_skip4: True\n",
      "SE_skip7: False\n",
      "SE_skip8: True\n",
      "Score: 0.6930000185966492\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "compression: 1.0\n",
      "fire_module: 1\n",
      "use_bypass0: True\n",
      "use_bypass1: False\n",
      "pooling0: avg\n",
      "pooling1: max\n",
      "squeeze_ratio2: 32\n",
      "SE_add2: True\n",
      "SE_add3: False\n",
      "squeeze_ratio4: 32\n",
      "SE_add4: True\n",
      "SE_add5: False\n",
      "num_fire_2: 1\n",
      "use_bypass_20: False\n",
      "use_bypass_21: False\n",
      "squeeze_ratio6: 8\n",
      "SE_add6: False\n",
      "SE_add7: True\n",
      "squeeze_ratio8: 8\n",
      "SE_add8: True\n",
      "SE_add9: True\n",
      "dropout_rate: 0.33716067560498636\n",
      "optimizer: sgd\n",
      "SE_skip2: True\n",
      "SE_skip5: False\n",
      "SE_skip6: False\n",
      "SE_skip9: True\n",
      "SE_skip3: False\n",
      "SE_skip4: True\n",
      "SE_skip7: False\n",
      "SE_skip8: True\n",
      "Score: 0.690500020980835\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.001\n",
      "compression: 1.0\n",
      "fire_module: 1\n",
      "use_bypass0: True\n",
      "use_bypass1: False\n",
      "pooling0: max\n",
      "pooling1: avg\n",
      "squeeze_ratio2: 8\n",
      "SE_add2: True\n",
      "SE_add3: False\n",
      "squeeze_ratio4: 32\n",
      "SE_add4: True\n",
      "SE_add5: True\n",
      "num_fire_2: 1\n",
      "use_bypass_20: True\n",
      "use_bypass_21: True\n",
      "squeeze_ratio6: 8\n",
      "SE_add6: True\n",
      "SE_add7: False\n",
      "squeeze_ratio8: 8\n",
      "SE_add8: True\n",
      "SE_add9: False\n",
      "dropout_rate: 0.3831538045436255\n",
      "optimizer: sgd\n",
      "SE_skip2: False\n",
      "SE_skip5: False\n",
      "SE_skip6: False\n",
      "SE_skip9: False\n",
      "SE_skip3: False\n",
      "SE_skip4: True\n",
      "SE_skip7: True\n",
      "SE_skip8: True\n",
      "Score: 0.6897500157356262\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "compression: 1.0\n",
      "fire_module: 2\n",
      "use_bypass0: False\n",
      "use_bypass1: True\n",
      "pooling0: avg\n",
      "pooling1: avg\n",
      "squeeze_ratio2: 8\n",
      "SE_add2: True\n",
      "SE_add3: True\n",
      "squeeze_ratio4: 16\n",
      "SE_add4: False\n",
      "SE_add5: True\n",
      "num_fire_2: 0\n",
      "use_bypass_20: False\n",
      "use_bypass_21: False\n",
      "squeeze_ratio6: 8\n",
      "SE_add6: True\n",
      "SE_add7: False\n",
      "squeeze_ratio8: 16\n",
      "SE_add8: False\n",
      "SE_add9: True\n",
      "dropout_rate: 0.48534504463461636\n",
      "optimizer: sgd\n",
      "SE_skip2: True\n",
      "SE_skip5: False\n",
      "SE_skip6: True\n",
      "SE_skip9: False\n",
      "SE_skip3: False\n",
      "SE_skip4: True\n",
      "SE_skip7: False\n",
      "SE_skip8: False\n",
      "Score: 0.6884999871253967\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "compression: 1.0\n",
      "fire_module: 1\n",
      "use_bypass0: True\n",
      "use_bypass1: False\n",
      "pooling0: avg\n",
      "pooling1: avg\n",
      "squeeze_ratio2: 32\n",
      "SE_add2: False\n",
      "SE_add3: False\n",
      "squeeze_ratio4: 16\n",
      "SE_add4: True\n",
      "SE_add5: True\n",
      "num_fire_2: 2\n",
      "use_bypass_20: False\n",
      "use_bypass_21: False\n",
      "squeeze_ratio6: 8\n",
      "SE_add6: True\n",
      "SE_add7: True\n",
      "squeeze_ratio8: 8\n",
      "SE_add8: True\n",
      "SE_add9: False\n",
      "dropout_rate: 0.402458023293637\n",
      "optimizer: sgd\n",
      "SE_skip2: True\n",
      "SE_skip5: False\n",
      "SE_skip6: False\n",
      "SE_skip9: False\n",
      "SE_skip3: False\n",
      "SE_skip4: True\n",
      "SE_skip7: False\n",
      "Score: 0.6822500228881836\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.001\n",
      "compression: 1.0\n",
      "fire_module: 2\n",
      "use_bypass0: False\n",
      "use_bypass1: False\n",
      "pooling0: avg\n",
      "pooling1: max\n",
      "squeeze_ratio2: 32\n",
      "SE_add2: False\n",
      "SE_add3: False\n",
      "squeeze_ratio4: 32\n",
      "SE_add4: True\n",
      "SE_add5: True\n",
      "num_fire_2: 1\n",
      "use_bypass_20: True\n",
      "use_bypass_21: True\n",
      "squeeze_ratio6: 32\n",
      "SE_add6: False\n",
      "SE_add7: True\n",
      "squeeze_ratio8: 32\n",
      "SE_add8: True\n",
      "SE_add9: False\n",
      "dropout_rate: 0.24722901231328712\n",
      "optimizer: sgd\n",
      "SE_skip2: True\n",
      "SE_skip5: False\n",
      "SE_skip6: False\n",
      "SE_skip9: True\n",
      "SE_skip3: True\n",
      "SE_skip4: True\n",
      "SE_skip7: True\n",
      "SE_skip8: False\n",
      "Score: 0.671999990940094\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.001\n",
      "compression: 1.0\n",
      "fire_module: 2\n",
      "use_bypass0: False\n",
      "use_bypass1: False\n",
      "pooling0: avg\n",
      "pooling1: avg\n",
      "squeeze_ratio2: 8\n",
      "SE_add2: False\n",
      "SE_add3: False\n",
      "squeeze_ratio4: 8\n",
      "SE_add4: False\n",
      "SE_add5: True\n",
      "num_fire_2: 0\n",
      "use_bypass_20: False\n",
      "use_bypass_21: True\n",
      "squeeze_ratio6: 32\n",
      "SE_add6: False\n",
      "SE_add7: False\n",
      "squeeze_ratio8: 32\n",
      "SE_add8: False\n",
      "SE_add9: True\n",
      "dropout_rate: 0.3874888845784512\n",
      "optimizer: sgd\n",
      "SE_skip2: False\n",
      "SE_skip5: True\n",
      "SE_skip6: False\n",
      "SE_skip9: False\n",
      "SE_skip3: False\n",
      "SE_skip4: False\n",
      "SE_skip7: False\n",
      "SE_skip8: False\n",
      "Score: 0.6710000038146973\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.001\n",
      "compression: 1.0\n",
      "fire_module: 2\n",
      "use_bypass0: False\n",
      "use_bypass1: True\n",
      "pooling0: avg\n",
      "pooling1: max\n",
      "squeeze_ratio2: 32\n",
      "SE_add2: True\n",
      "SE_add3: True\n",
      "squeeze_ratio4: 8\n",
      "SE_add4: True\n",
      "SE_add5: False\n",
      "num_fire_2: 2\n",
      "use_bypass_20: False\n",
      "use_bypass_21: False\n",
      "squeeze_ratio6: 8\n",
      "SE_add6: True\n",
      "SE_add7: False\n",
      "squeeze_ratio8: 8\n",
      "SE_add8: False\n",
      "SE_add9: False\n",
      "dropout_rate: 0.7429475008181057\n",
      "optimizer: sgd\n",
      "SE_skip2: False\n",
      "SE_skip5: True\n",
      "SE_skip6: True\n",
      "SE_skip9: False\n",
      "SE_skip3: True\n",
      "SE_skip4: False\n",
      "SE_skip7: True\n",
      "SE_skip8: False\n",
      "Score: 0.6707500219345093\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "compression: 1.0\n",
      "fire_module: 1\n",
      "use_bypass0: True\n",
      "use_bypass1: False\n",
      "pooling0: max\n",
      "pooling1: avg\n",
      "squeeze_ratio2: 8\n",
      "SE_add2: False\n",
      "SE_add3: True\n",
      "squeeze_ratio4: 8\n",
      "SE_add4: True\n",
      "SE_add5: True\n",
      "num_fire_2: 2\n",
      "use_bypass_20: False\n",
      "use_bypass_21: False\n",
      "squeeze_ratio6: 16\n",
      "SE_add6: True\n",
      "SE_add7: False\n",
      "squeeze_ratio8: 32\n",
      "SE_add8: False\n",
      "SE_add9: True\n",
      "dropout_rate: 0.41785416424126104\n",
      "optimizer: RMSprop\n",
      "SE_skip2: False\n",
      "SE_skip5: False\n",
      "SE_skip6: True\n",
      "SE_skip9: False\n",
      "SE_skip3: False\n",
      "SE_skip4: False\n",
      "SE_skip7: True\n",
      "SE_skip8: True\n",
      "Score: 0.6707500219345093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected error in ping thread.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 699, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 445, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 440, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/http/client.py\", line 1349, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/http/client.py\", line 316, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/http/client.py\", line 277, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/ssl.py\", line 1241, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/ssl.py\", line 1099, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/site-packages/requests/adapters.py\", line 439, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 755, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/site-packages/urllib3/util/retry.py\", line 532, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/site-packages/urllib3/packages/six.py\", line 769, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 699, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 445, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 440, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/http/client.py\", line 1349, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/http/client.py\", line 316, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/http/client.py\", line 277, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/ssl.py\", line 1241, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/ssl.py\", line 1099, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/site-packages/bravado/http_future.py\", line 124, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/site-packages/bravado/http_future.py\", line 291, in _get_incoming_response\n",
      "    inner_response = self.future.result(timeout=timeout)\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/site-packages/bravado/requests_client.py\", line 266, in result\n",
      "    response = self.session.send(\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/site-packages/requests/sessions.py\", line 655, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/site-packages/requests/adapters.py\", line 498, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/site-packages/neptune/internal/threads/ping_thread.py\", line 37, in run\n",
      "    self.__backend.ping_experiment(self.__experiment)\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/site-packages/neptune/internal/api_clients/hosted_api_clients/hosted_alpha_leaderboard_api_client.py\", line 393, in ping_experiment\n",
      "    self.leaderboard_swagger_client.api.ping(experimentId=str(experiment.internal_id)).response().result\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/site-packages/bravado/http_future.py\", line 239, in response\n",
      "    six.reraise(*sys.exc_info())\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/site-packages/six.py\", line 703, in reraise\n",
      "    raise value\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/site-packages/bravado/http_future.py\", line 197, in response\n",
      "    incoming_response = self._get_incoming_response(timeout)\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/site-packages/bravado/http_future.py\", line 126, in wrapper\n",
      "    self.future._raise_connection_error(exception)\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/site-packages/bravado/http_future.py\", line 91, in _raise_connection_error\n",
      "    self._raise_error(BravadoConnectionError, 'ConnectionError', exception)\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/site-packages/bravado/http_future.py\", line 79, in _raise_error\n",
      "    six.reraise(\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/site-packages/six.py\", line 702, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/site-packages/bravado/http_future.py\", line 124, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/site-packages/bravado/http_future.py\", line 291, in _get_incoming_response\n",
      "    inner_response = self.future.result(timeout=timeout)\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/site-packages/bravado/requests_client.py\", line 266, in result\n",
      "    response = self.session.send(\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/site-packages/requests/sessions.py\", line 655, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/site-packages/requests/adapters.py\", line 498, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "bravado.http_future.RequestsFutureAdapterConnectionError\n",
      "Unexpected error in ping thread.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 699, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 445, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 440, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/http/client.py\", line 1349, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/http/client.py\", line 316, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/http/client.py\", line 277, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/ssl.py\", line 1241, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/ssl.py\", line 1099, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/site-packages/requests/adapters.py\", line 439, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 755, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/site-packages/urllib3/util/retry.py\", line 532, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/site-packages/urllib3/packages/six.py\", line 769, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 699, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 445, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 440, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/http/client.py\", line 1349, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/http/client.py\", line 316, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/http/client.py\", line 277, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/ssl.py\", line 1241, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/ssl.py\", line 1099, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/site-packages/bravado/http_future.py\", line 124, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/site-packages/bravado/http_future.py\", line 291, in _get_incoming_response\n",
      "    inner_response = self.future.result(timeout=timeout)\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/site-packages/bravado/requests_client.py\", line 266, in result\n",
      "    response = self.session.send(\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/site-packages/requests/sessions.py\", line 655, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/site-packages/requests/adapters.py\", line 498, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/site-packages/neptune/internal/threads/ping_thread.py\", line 37, in run\n",
      "    self.__backend.ping_experiment(self.__experiment)\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/site-packages/neptune/internal/api_clients/hosted_api_clients/hosted_alpha_leaderboard_api_client.py\", line 393, in ping_experiment\n",
      "    self.leaderboard_swagger_client.api.ping(experimentId=str(experiment.internal_id)).response().result\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/site-packages/bravado/http_future.py\", line 239, in response\n",
      "    six.reraise(*sys.exc_info())\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/site-packages/six.py\", line 703, in reraise\n",
      "    raise value\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/site-packages/bravado/http_future.py\", line 197, in response\n",
      "    incoming_response = self._get_incoming_response(timeout)\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/site-packages/bravado/http_future.py\", line 126, in wrapper\n",
      "    self.future._raise_connection_error(exception)\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/site-packages/bravado/http_future.py\", line 91, in _raise_connection_error\n",
      "    self._raise_error(BravadoConnectionError, 'ConnectionError', exception)\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/site-packages/bravado/http_future.py\", line 79, in _raise_error\n",
      "    six.reraise(\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/site-packages/six.py\", line 702, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/site-packages/bravado/http_future.py\", line 124, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/site-packages/bravado/http_future.py\", line 291, in _get_incoming_response\n",
      "    inner_response = self.future.result(timeout=timeout)\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/site-packages/bravado/requests_client.py\", line 266, in result\n",
      "    response = self.session.send(\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/site-packages/requests/sessions.py\", line 655, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/chantana/anaconda3/envs/tf2.5/lib/python3.9/site-packages/requests/adapters.py\", line 498, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "bravado.http_future.RequestsFutureAdapterConnectionError\n"
     ]
    }
   ],
   "source": [
    "#SqueezeSEAuto random\n",
    "hp = HyperParameters()\n",
    "\n",
    "import neptune\n",
    "\n",
    "\n",
    "PROJECT = \"squeezeSEAutoRandom\"+str(ratio)\n",
    "neptune.create_experiment(PROJECT)\n",
    "\n",
    " \n",
    "# This will override the `learning_rate` parameter with your\n",
    "# own selection of choices\n",
    "\n",
    "hp.Choice(\"learning_rate\", values=[ 1e-3, 1e-4])\n",
    "\n",
    "\n",
    "\n",
    "#fn_name = globals()[\"build_SqueezeNet_11_fixed\"](hp)\n",
    "# SqueezeNet \n",
    "\n",
    "mymodel = SqueezeNetSEAutoModel  (classes=nb_classes)\n",
    "\n",
    " \n",
    "tuner = RandomSearch(\n",
    "    #build_SqueezeNet_11_fixed,\n",
    "    #build_squeezenet_auto_model,\n",
    "    #build_model,\n",
    "    \n",
    "    hypermodel=mymodel,\n",
    "    hyperparameters = hp,\n",
    "    objective=Objective(\"val_accuracy\", direction=\"max\"),\n",
    "    max_trials=100,\n",
    "    executions_per_trial=1,\n",
    "    overwrite=True,\n",
    "    directory=\"mytest_dir\",\n",
    "    project_name=PROJECT,\n",
    "    #distribution_strategy=tf.distribute.MirroredStrategy(),\n",
    "    logger = npt_utils.NeptuneLogger(),\n",
    "     \n",
    ")\n",
    "tuner.search_space_summary()\n",
    "\n",
    "\n",
    "EPOCH = 200\n",
    "batch_size = 16\n",
    "\"\"\"\"lr_finder = LRFinder(min_lr=1e-5, \n",
    "                    max_lr=1e-3,\n",
    "                    steps_per_epoch=np.ceil(EPOCH/batch_size),\n",
    "                    epochs=3)\"\"\"\n",
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping('val_accuracy', patience=10),\n",
    "    #lr_finder,\n",
    "    #tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5'),\n",
    "    #tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "]\n",
    "\n",
    "tuner.search(x_train[:int(ratio*len(x_train))], y_train[:int(ratio*len(y_train))], epochs=EPOCH, callbacks = my_callbacks,validation_data=(x_test[:int(ratio*len(x_test))], y_test[:int(ratio*len(y_test))]))\n",
    "\n",
    "models = tuner.get_best_models() #(num_models=10)\n",
    "tuner.results_summary()\n",
    "npt_utils.log_tuner_info(tuner)\n",
    "\n",
    "\n",
    "#best_model = tuner.get_best_models(num_models=1)[0]\n",
    "#best_model.evaluate(x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfb68ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 100 Complete [00h 04m 08s]\n",
      "val_accuracy: 0.6522499918937683\n",
      "\n",
      "Best val_accuracy So Far: 0.6934999823570251\n",
      "Total elapsed time: 09h 07m 16s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "[False, False]\n",
      "['max', 'avg']\n",
      "[]\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Results summary\n",
      "Results in mytest_dir/squeezeSEAutoBayesian0.4\n",
      "Showing 10 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.001\n",
      "compression: 1.0\n",
      "fire_module: 2\n",
      "use_bypass0: False\n",
      "use_bypass1: False\n",
      "pooling0: max\n",
      "pooling1: avg\n",
      "squeeze_ratio2: 32\n",
      "SE_add2: True\n",
      "SE_add3: False\n",
      "squeeze_ratio4: 8\n",
      "SE_add4: False\n",
      "SE_add5: True\n",
      "num_fire_2: 0\n",
      "use_bypass_20: True\n",
      "use_bypass_21: False\n",
      "squeeze_ratio6: 32\n",
      "SE_add6: False\n",
      "SE_add7: False\n",
      "squeeze_ratio8: 32\n",
      "SE_add8: False\n",
      "SE_add9: True\n",
      "dropout_rate: 0.49615017077050255\n",
      "optimizer: sgd\n",
      "SE_skip2: True\n",
      "SE_skip4: True\n",
      "SE_skip6: True\n",
      "SE_skip7: False\n",
      "SE_skip9: False\n",
      "SE_skip5: False\n",
      "SE_skip3: False\n",
      "Score: 0.6934999823570251\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.001\n",
      "compression: 1.0\n",
      "fire_module: 2\n",
      "use_bypass0: False\n",
      "use_bypass1: False\n",
      "pooling0: max\n",
      "pooling1: avg\n",
      "squeeze_ratio2: 32\n",
      "SE_add2: True\n",
      "SE_add3: False\n",
      "squeeze_ratio4: 8\n",
      "SE_add4: False\n",
      "SE_add5: True\n",
      "num_fire_2: 0\n",
      "use_bypass_20: True\n",
      "use_bypass_21: False\n",
      "squeeze_ratio6: 32\n",
      "SE_add6: False\n",
      "SE_add7: False\n",
      "squeeze_ratio8: 32\n",
      "SE_add8: False\n",
      "SE_add9: True\n",
      "dropout_rate: 0.8\n",
      "optimizer: sgd\n",
      "SE_skip2: True\n",
      "SE_skip4: True\n",
      "SE_skip6: True\n",
      "SE_skip7: False\n",
      "SE_skip9: False\n",
      "SE_skip5: False\n",
      "SE_skip3: False\n",
      "Score: 0.6762499809265137\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.001\n",
      "compression: 1.0\n",
      "fire_module: 2\n",
      "use_bypass0: False\n",
      "use_bypass1: False\n",
      "pooling0: max\n",
      "pooling1: avg\n",
      "squeeze_ratio2: 32\n",
      "SE_add2: True\n",
      "SE_add3: False\n",
      "squeeze_ratio4: 8\n",
      "SE_add4: False\n",
      "SE_add5: True\n",
      "num_fire_2: 0\n",
      "use_bypass_20: True\n",
      "use_bypass_21: False\n",
      "squeeze_ratio6: 32\n",
      "SE_add6: False\n",
      "SE_add7: False\n",
      "squeeze_ratio8: 8\n",
      "SE_add8: False\n",
      "SE_add9: True\n",
      "dropout_rate: 0.8\n",
      "optimizer: sgd\n",
      "SE_skip2: True\n",
      "SE_skip4: True\n",
      "SE_skip6: True\n",
      "SE_skip7: False\n",
      "SE_skip9: False\n",
      "SE_skip5: False\n",
      "Score: 0.6759999990463257\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.001\n",
      "compression: 1.0\n",
      "fire_module: 2\n",
      "use_bypass0: False\n",
      "use_bypass1: False\n",
      "pooling0: max\n",
      "pooling1: avg\n",
      "squeeze_ratio2: 32\n",
      "SE_add2: True\n",
      "SE_add3: False\n",
      "squeeze_ratio4: 8\n",
      "SE_add4: False\n",
      "SE_add5: True\n",
      "num_fire_2: 0\n",
      "use_bypass_20: True\n",
      "use_bypass_21: False\n",
      "squeeze_ratio6: 32\n",
      "SE_add6: False\n",
      "SE_add7: False\n",
      "squeeze_ratio8: 8\n",
      "SE_add8: False\n",
      "SE_add9: True\n",
      "dropout_rate: 0.21893503494193645\n",
      "optimizer: sgd\n",
      "SE_skip2: True\n",
      "SE_skip4: True\n",
      "SE_skip6: True\n",
      "SE_skip7: False\n",
      "SE_skip9: False\n",
      "SE_skip5: False\n",
      "SE_skip3: False\n",
      "Score: 0.6742500066757202\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.001\n",
      "compression: 1.0\n",
      "fire_module: 2\n",
      "use_bypass0: False\n",
      "use_bypass1: False\n",
      "pooling0: max\n",
      "pooling1: avg\n",
      "squeeze_ratio2: 32\n",
      "SE_add2: True\n",
      "SE_add3: False\n",
      "squeeze_ratio4: 8\n",
      "SE_add4: False\n",
      "SE_add5: True\n",
      "num_fire_2: 0\n",
      "use_bypass_20: True\n",
      "use_bypass_21: False\n",
      "squeeze_ratio6: 32\n",
      "SE_add6: False\n",
      "SE_add7: False\n",
      "squeeze_ratio8: 32\n",
      "SE_add8: False\n",
      "SE_add9: True\n",
      "dropout_rate: 0.8\n",
      "optimizer: sgd\n",
      "SE_skip2: True\n",
      "SE_skip4: True\n",
      "SE_skip6: True\n",
      "SE_skip7: False\n",
      "SE_skip9: False\n",
      "SE_skip5: False\n",
      "SE_skip3: False\n",
      "Score: 0.6740000247955322\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.001\n",
      "compression: 1.0\n",
      "fire_module: 2\n",
      "use_bypass0: False\n",
      "use_bypass1: False\n",
      "pooling0: max\n",
      "pooling1: avg\n",
      "squeeze_ratio2: 32\n",
      "SE_add2: True\n",
      "SE_add3: False\n",
      "squeeze_ratio4: 8\n",
      "SE_add4: False\n",
      "SE_add5: True\n",
      "num_fire_2: 0\n",
      "use_bypass_20: True\n",
      "use_bypass_21: False\n",
      "squeeze_ratio6: 32\n",
      "SE_add6: False\n",
      "SE_add7: False\n",
      "squeeze_ratio8: 8\n",
      "SE_add8: False\n",
      "SE_add9: True\n",
      "dropout_rate: 0.8\n",
      "optimizer: sgd\n",
      "SE_skip2: True\n",
      "SE_skip4: True\n",
      "SE_skip6: True\n",
      "SE_skip7: False\n",
      "SE_skip9: False\n",
      "SE_skip5: False\n",
      "SE_skip3: False\n",
      "Score: 0.6712499856948853\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.001\n",
      "compression: 1.0\n",
      "fire_module: 2\n",
      "use_bypass0: False\n",
      "use_bypass1: False\n",
      "pooling0: max\n",
      "pooling1: avg\n",
      "squeeze_ratio2: 32\n",
      "SE_add2: True\n",
      "SE_add3: False\n",
      "squeeze_ratio4: 8\n",
      "SE_add4: False\n",
      "SE_add5: True\n",
      "num_fire_2: 0\n",
      "use_bypass_20: True\n",
      "use_bypass_21: False\n",
      "squeeze_ratio6: 32\n",
      "SE_add6: False\n",
      "SE_add7: False\n",
      "squeeze_ratio8: 32\n",
      "SE_add8: False\n",
      "SE_add9: True\n",
      "dropout_rate: 0.8\n",
      "optimizer: sgd\n",
      "SE_skip2: True\n",
      "SE_skip4: True\n",
      "SE_skip6: True\n",
      "SE_skip7: False\n",
      "SE_skip9: False\n",
      "SE_skip5: False\n",
      "SE_skip3: False\n",
      "Score: 0.6697499752044678\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.001\n",
      "compression: 1.0\n",
      "fire_module: 2\n",
      "use_bypass0: False\n",
      "use_bypass1: False\n",
      "pooling0: max\n",
      "pooling1: avg\n",
      "squeeze_ratio2: 32\n",
      "SE_add2: True\n",
      "SE_add3: False\n",
      "squeeze_ratio4: 8\n",
      "SE_add4: False\n",
      "SE_add5: True\n",
      "num_fire_2: 0\n",
      "use_bypass_20: True\n",
      "use_bypass_21: False\n",
      "squeeze_ratio6: 32\n",
      "SE_add6: False\n",
      "SE_add7: False\n",
      "squeeze_ratio8: 8\n",
      "SE_add8: False\n",
      "SE_add9: True\n",
      "dropout_rate: 0.5524395666865854\n",
      "optimizer: sgd\n",
      "SE_skip2: True\n",
      "SE_skip4: True\n",
      "SE_skip6: True\n",
      "SE_skip7: False\n",
      "SE_skip9: False\n",
      "SE_skip5: False\n",
      "SE_skip3: False\n",
      "Score: 0.6690000295639038\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.001\n",
      "compression: 1.0\n",
      "fire_module: 2\n",
      "use_bypass0: False\n",
      "use_bypass1: False\n",
      "pooling0: max\n",
      "pooling1: avg\n",
      "squeeze_ratio2: 32\n",
      "SE_add2: True\n",
      "SE_add3: False\n",
      "squeeze_ratio4: 8\n",
      "SE_add4: False\n",
      "SE_add5: True\n",
      "num_fire_2: 0\n",
      "use_bypass_20: True\n",
      "use_bypass_21: False\n",
      "squeeze_ratio6: 32\n",
      "SE_add6: False\n",
      "SE_add7: False\n",
      "squeeze_ratio8: 32\n",
      "SE_add8: False\n",
      "SE_add9: True\n",
      "dropout_rate: 0.8\n",
      "optimizer: sgd\n",
      "SE_skip2: True\n",
      "SE_skip4: True\n",
      "SE_skip6: True\n",
      "SE_skip7: False\n",
      "SE_skip9: False\n",
      "SE_skip5: False\n",
      "SE_skip3: False\n",
      "Score: 0.6685000061988831\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.001\n",
      "compression: 1.0\n",
      "fire_module: 2\n",
      "use_bypass0: False\n",
      "use_bypass1: False\n",
      "pooling0: max\n",
      "pooling1: avg\n",
      "squeeze_ratio2: 32\n",
      "SE_add2: True\n",
      "SE_add3: False\n",
      "squeeze_ratio4: 8\n",
      "SE_add4: False\n",
      "SE_add5: True\n",
      "num_fire_2: 0\n",
      "use_bypass_20: True\n",
      "use_bypass_21: False\n",
      "squeeze_ratio6: 32\n",
      "SE_add6: False\n",
      "SE_add7: False\n",
      "squeeze_ratio8: 8\n",
      "SE_add8: False\n",
      "SE_add9: True\n",
      "dropout_rate: 0.8\n",
      "optimizer: sgd\n",
      "SE_skip2: True\n",
      "SE_skip4: True\n",
      "SE_skip6: True\n",
      "SE_skip7: False\n",
      "SE_skip9: False\n",
      "SE_skip5: False\n",
      "SE_skip3: False\n",
      "Score: 0.6675000190734863\n"
     ]
    }
   ],
   "source": [
    "#SqueezeSEAuto random\n",
    "hp = HyperParameters()\n",
    "\n",
    "import neptune\n",
    "\n",
    "\n",
    "ratio = 1.0\n",
    "PROJECT = \"squeezeSEAutoBayesian\"+str(ratio)\n",
    "neptune.create_experiment(PROJECT)\n",
    "\n",
    " \n",
    "# This will override the `learning_rate` parameter with your\n",
    "# own selection of choices\n",
    "\n",
    "hp.Choice(\"learning_rate\", values=[ 1e-3, 1e-4])\n",
    "\n",
    "\n",
    "\n",
    "#fn_name = globals()[\"build_SqueezeNet_11_fixed\"](hp)\n",
    "# SqueezeNet \n",
    "\n",
    "mymodel = SqueezeNetSEAutoModel  (classes=nb_classes)\n",
    "\n",
    " \n",
    "tuner = BayesianOptimization(\n",
    "    #build_SqueezeNet_11_fixed,\n",
    "    #build_squeezenet_auto_model,\n",
    "    #build_model,\n",
    "    \n",
    "    hypermodel=mymodel,\n",
    "    hyperparameters = hp,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=100,\n",
    "    executions_per_trial=1,\n",
    "    overwrite=True,\n",
    "    directory=\"mytest_dir\",\n",
    "    project_name= PROJECT,\n",
    "    #distribution_strategy=tf.distribute.MirroredStrategy(),\n",
    "    num_initial_points=2,\n",
    "    alpha=0.0001,\n",
    "    beta=2.6,\n",
    "    seed=None,\n",
    "    tune_new_entries=True,\n",
    "    allow_new_entries=True,\n",
    "    logger = npt_utils.NeptuneLogger(),\n",
    "     \n",
    ")\n",
    "tuner.search_space_summary()\n",
    "\n",
    "\n",
    "EPOCH = 200\n",
    "batch_size = 16\n",
    "\"\"\"\"lr_finder = LRFinder(min_lr=1e-5, \n",
    "                    max_lr=1e-3,\n",
    "                    steps_per_epoch=np.ceil(EPOCH/batch_size),\n",
    "                    epochs=3)\"\"\"\n",
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping('val_accuracy', patience=10),\n",
    "    #lr_finder,\n",
    "    #tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5'),\n",
    "    #tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "]\n",
    "\n",
    "tuner.search(x_train[:int(ratio*len(x_train))], y_train[:int(ratio*len(y_train))], epochs=EPOCH, callbacks = my_callbacks,validation_data=(x_test[:int(ratio*len(x_test))], y_test[:int(ratio*len(y_test))]))\n",
    "\n",
    "models = tuner.get_best_models() #(num_models=10)\n",
    "tuner.results_summary()\n",
    "npt_utils.log_tuner_info(tuner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69afbfe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 254 Complete [00h 05m 15s]\n",
      "val_accuracy: 0.6324999928474426\n",
      "\n",
      "Best val_accuracy So Far: 0.7059999704360962\n",
      "Total elapsed time: 04h 53m 29s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "[False]\n",
      "['avg']\n",
      "[True]\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Results summary\n",
      "Results in mytest_dir/squeezeSEAutoHyper0.4\n",
      "Showing 10 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.001\n",
      "compression: 1.0\n",
      "fire_module: 1\n",
      "use_bypass0: False\n",
      "use_bypass1: True\n",
      "pooling0: avg\n",
      "pooling1: max\n",
      "squeeze_ratio2: 32\n",
      "SE_add2: False\n",
      "SE_add3: False\n",
      "squeeze_ratio4: 16\n",
      "SE_add4: True\n",
      "SE_add5: False\n",
      "num_fire_2: 1\n",
      "use_bypass_20: True\n",
      "use_bypass_21: True\n",
      "squeeze_ratio6: 8\n",
      "SE_add6: True\n",
      "SE_add7: True\n",
      "squeeze_ratio8: 32\n",
      "SE_add8: False\n",
      "SE_add9: False\n",
      "dropout_rate: 0.6700218244572\n",
      "optimizer: RMSprop\n",
      "SE_skip2: False\n",
      "SE_skip3: True\n",
      "SE_skip4: True\n",
      "SE_skip5: True\n",
      "SE_skip6: False\n",
      "SE_skip7: False\n",
      "SE_skip8: True\n",
      "SE_skip9: False\n",
      "tuner/epochs: 67\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 1\n",
      "tuner/round: 0\n",
      "Score: 0.7059999704360962\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "compression: 1.0\n",
      "fire_module: 2\n",
      "use_bypass0: False\n",
      "use_bypass1: True\n",
      "pooling0: avg\n",
      "pooling1: avg\n",
      "squeeze_ratio2: 16\n",
      "SE_add2: False\n",
      "SE_add3: False\n",
      "squeeze_ratio4: 32\n",
      "SE_add4: True\n",
      "SE_add5: True\n",
      "num_fire_2: 1\n",
      "use_bypass_20: True\n",
      "use_bypass_21: True\n",
      "squeeze_ratio6: 16\n",
      "SE_add6: True\n",
      "SE_add7: True\n",
      "squeeze_ratio8: 32\n",
      "SE_add8: True\n",
      "SE_add9: False\n",
      "dropout_rate: 0.5102759003006871\n",
      "optimizer: RMSprop\n",
      "SE_skip2: False\n",
      "SE_skip3: True\n",
      "SE_skip4: True\n",
      "SE_skip5: True\n",
      "SE_skip6: True\n",
      "SE_skip7: False\n",
      "SE_skip8: False\n",
      "tuner/epochs: 200\n",
      "tuner/initial_epoch: 67\n",
      "tuner/bracket: 4\n",
      "tuner/round: 4\n",
      "tuner/trial_id: cbec1e1f66d470d132bc29be962d9b04\n",
      "Score: 0.6934999823570251\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "compression: 1.0\n",
      "fire_module: 2\n",
      "use_bypass0: False\n",
      "use_bypass1: True\n",
      "pooling0: avg\n",
      "pooling1: avg\n",
      "squeeze_ratio2: 16\n",
      "SE_add2: False\n",
      "SE_add3: False\n",
      "squeeze_ratio4: 32\n",
      "SE_add4: True\n",
      "SE_add5: True\n",
      "num_fire_2: 1\n",
      "use_bypass_20: True\n",
      "use_bypass_21: True\n",
      "squeeze_ratio6: 16\n",
      "SE_add6: True\n",
      "SE_add7: True\n",
      "squeeze_ratio8: 32\n",
      "SE_add8: True\n",
      "SE_add9: False\n",
      "dropout_rate: 0.5102759003006871\n",
      "optimizer: RMSprop\n",
      "SE_skip2: False\n",
      "SE_skip3: True\n",
      "SE_skip4: True\n",
      "SE_skip5: True\n",
      "SE_skip6: True\n",
      "SE_skip7: False\n",
      "SE_skip8: False\n",
      "tuner/epochs: 67\n",
      "tuner/initial_epoch: 23\n",
      "tuner/bracket: 4\n",
      "tuner/round: 3\n",
      "tuner/trial_id: 2569f7c80a524ff58ea8cff1c15c0de2\n",
      "Score: 0.6919999718666077\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "compression: 1.0\n",
      "fire_module: 1\n",
      "use_bypass0: False\n",
      "use_bypass1: False\n",
      "pooling0: avg\n",
      "pooling1: avg\n",
      "squeeze_ratio2: 8\n",
      "SE_add2: True\n",
      "SE_add3: True\n",
      "squeeze_ratio4: 8\n",
      "SE_add4: True\n",
      "SE_add5: False\n",
      "num_fire_2: 2\n",
      "use_bypass_20: False\n",
      "use_bypass_21: True\n",
      "squeeze_ratio6: 8\n",
      "SE_add6: True\n",
      "SE_add7: True\n",
      "squeeze_ratio8: 8\n",
      "SE_add8: False\n",
      "SE_add9: True\n",
      "dropout_rate: 0.242828648110493\n",
      "optimizer: RMSprop\n",
      "SE_skip2: False\n",
      "SE_skip3: True\n",
      "SE_skip4: False\n",
      "SE_skip5: True\n",
      "SE_skip6: True\n",
      "SE_skip7: False\n",
      "SE_skip8: True\n",
      "SE_skip9: False\n",
      "tuner/epochs: 200\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.6850000023841858\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.001\n",
      "compression: 1.0\n",
      "fire_module: 1\n",
      "use_bypass0: False\n",
      "use_bypass1: False\n",
      "pooling0: avg\n",
      "pooling1: avg\n",
      "squeeze_ratio2: 8\n",
      "SE_add2: False\n",
      "SE_add3: False\n",
      "squeeze_ratio4: 32\n",
      "SE_add4: True\n",
      "SE_add5: True\n",
      "num_fire_2: 1\n",
      "use_bypass_20: True\n",
      "use_bypass_21: True\n",
      "squeeze_ratio6: 16\n",
      "SE_add6: False\n",
      "SE_add7: False\n",
      "squeeze_ratio8: 32\n",
      "SE_add8: False\n",
      "SE_add9: True\n",
      "dropout_rate: 0.5794988284900957\n",
      "optimizer: RMSprop\n",
      "SE_skip2: False\n",
      "SE_skip3: True\n",
      "SE_skip4: True\n",
      "SE_skip5: True\n",
      "SE_skip6: True\n",
      "SE_skip7: True\n",
      "SE_skip8: False\n",
      "SE_skip9: True\n",
      "tuner/epochs: 67\n",
      "tuner/initial_epoch: 23\n",
      "tuner/bracket: 3\n",
      "tuner/round: 2\n",
      "tuner/trial_id: a36dab380cfe31678c1161381d057329\n",
      "Score: 0.6827499866485596\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "compression: 1.0\n",
      "fire_module: 1\n",
      "use_bypass0: True\n",
      "use_bypass1: True\n",
      "pooling0: avg\n",
      "pooling1: avg\n",
      "squeeze_ratio2: 16\n",
      "SE_add2: True\n",
      "SE_add3: True\n",
      "squeeze_ratio4: 32\n",
      "SE_add4: True\n",
      "SE_add5: True\n",
      "num_fire_2: 1\n",
      "use_bypass_20: True\n",
      "use_bypass_21: True\n",
      "squeeze_ratio6: 32\n",
      "SE_add6: False\n",
      "SE_add7: False\n",
      "squeeze_ratio8: 8\n",
      "SE_add8: False\n",
      "SE_add9: False\n",
      "dropout_rate: 0.3196618250329363\n",
      "optimizer: RMSprop\n",
      "SE_skip2: False\n",
      "SE_skip3: True\n",
      "SE_skip4: True\n",
      "SE_skip5: False\n",
      "SE_skip6: True\n",
      "SE_skip7: False\n",
      "SE_skip8: False\n",
      "tuner/epochs: 67\n",
      "tuner/initial_epoch: 23\n",
      "tuner/bracket: 4\n",
      "tuner/round: 3\n",
      "tuner/trial_id: b5aa587b6b402bc8fd992c5a1d3b0408\n",
      "Score: 0.6809999942779541\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.001\n",
      "compression: 1.0\n",
      "fire_module: 1\n",
      "use_bypass0: False\n",
      "use_bypass1: False\n",
      "pooling0: avg\n",
      "pooling1: avg\n",
      "squeeze_ratio2: 8\n",
      "SE_add2: False\n",
      "SE_add3: False\n",
      "squeeze_ratio4: 32\n",
      "SE_add4: True\n",
      "SE_add5: True\n",
      "num_fire_2: 1\n",
      "use_bypass_20: True\n",
      "use_bypass_21: True\n",
      "squeeze_ratio6: 16\n",
      "SE_add6: False\n",
      "SE_add7: False\n",
      "squeeze_ratio8: 32\n",
      "SE_add8: False\n",
      "SE_add9: True\n",
      "dropout_rate: 0.5794988284900957\n",
      "optimizer: RMSprop\n",
      "SE_skip2: False\n",
      "SE_skip3: True\n",
      "SE_skip4: True\n",
      "SE_skip5: True\n",
      "SE_skip6: True\n",
      "SE_skip7: True\n",
      "SE_skip8: False\n",
      "SE_skip9: True\n",
      "tuner/epochs: 200\n",
      "tuner/initial_epoch: 67\n",
      "tuner/bracket: 3\n",
      "tuner/round: 3\n",
      "tuner/trial_id: a8feb43faedce74969b3a9febacad4ed\n",
      "Score: 0.6802499890327454\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.001\n",
      "compression: 1.0\n",
      "fire_module: 1\n",
      "use_bypass0: False\n",
      "use_bypass1: True\n",
      "pooling0: avg\n",
      "pooling1: max\n",
      "squeeze_ratio2: 32\n",
      "SE_add2: False\n",
      "SE_add3: False\n",
      "squeeze_ratio4: 16\n",
      "SE_add4: True\n",
      "SE_add5: False\n",
      "num_fire_2: 1\n",
      "use_bypass_20: True\n",
      "use_bypass_21: True\n",
      "squeeze_ratio6: 8\n",
      "SE_add6: True\n",
      "SE_add7: True\n",
      "squeeze_ratio8: 32\n",
      "SE_add8: False\n",
      "SE_add9: False\n",
      "dropout_rate: 0.6700218244572\n",
      "optimizer: RMSprop\n",
      "SE_skip2: False\n",
      "SE_skip3: True\n",
      "SE_skip4: True\n",
      "SE_skip5: True\n",
      "SE_skip6: False\n",
      "SE_skip7: False\n",
      "SE_skip8: True\n",
      "SE_skip9: False\n",
      "tuner/epochs: 200\n",
      "tuner/initial_epoch: 67\n",
      "tuner/bracket: 1\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 963de37ffaceaf04b85da7abf680a55b\n",
      "Score: 0.6787499785423279\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "compression: 1.0\n",
      "fire_module: 1\n",
      "use_bypass0: False\n",
      "use_bypass1: True\n",
      "pooling0: max\n",
      "pooling1: avg\n",
      "squeeze_ratio2: 32\n",
      "SE_add2: True\n",
      "SE_add3: True\n",
      "squeeze_ratio4: 8\n",
      "SE_add4: True\n",
      "SE_add5: True\n",
      "num_fire_2: 1\n",
      "use_bypass_20: False\n",
      "use_bypass_21: True\n",
      "squeeze_ratio6: 32\n",
      "SE_add6: False\n",
      "SE_add7: False\n",
      "squeeze_ratio8: 32\n",
      "SE_add8: True\n",
      "SE_add9: False\n",
      "dropout_rate: 0.13386064909646464\n",
      "optimizer: RMSprop\n",
      "SE_skip2: True\n",
      "SE_skip3: True\n",
      "SE_skip4: True\n",
      "SE_skip5: True\n",
      "SE_skip6: False\n",
      "SE_skip7: True\n",
      "SE_skip8: False\n",
      "SE_skip9: True\n",
      "tuner/epochs: 23\n",
      "tuner/initial_epoch: 8\n",
      "tuner/bracket: 3\n",
      "tuner/round: 1\n",
      "tuner/trial_id: bc92a3284ca986e3416cdeb20f3a5aed\n",
      "Score: 0.6769999861717224\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.001\n",
      "compression: 1.0\n",
      "fire_module: 1\n",
      "use_bypass0: False\n",
      "use_bypass1: False\n",
      "pooling0: avg\n",
      "pooling1: max\n",
      "squeeze_ratio2: 16\n",
      "SE_add2: True\n",
      "SE_add3: True\n",
      "squeeze_ratio4: 32\n",
      "SE_add4: True\n",
      "SE_add5: False\n",
      "num_fire_2: 1\n",
      "use_bypass_20: False\n",
      "use_bypass_21: True\n",
      "squeeze_ratio6: 16\n",
      "SE_add6: False\n",
      "SE_add7: True\n",
      "squeeze_ratio8: 32\n",
      "SE_add8: False\n",
      "SE_add9: True\n",
      "dropout_rate: 0.5095141520876453\n",
      "optimizer: RMSprop\n",
      "SE_skip2: False\n",
      "SE_skip3: False\n",
      "SE_skip4: True\n",
      "SE_skip5: False\n",
      "SE_skip6: False\n",
      "SE_skip7: False\n",
      "SE_skip8: True\n",
      "SE_skip9: False\n",
      "tuner/epochs: 200\n",
      "tuner/initial_epoch: 67\n",
      "tuner/bracket: 3\n",
      "tuner/round: 3\n",
      "tuner/trial_id: 825b5402ef6b49178cce01ef8166927e\n",
      "Score: 0.6747499704360962\n"
     ]
    }
   ],
   "source": [
    "#SqueezeAuto Hyperband\n",
    "hp = HyperParameters()\n",
    "\n",
    "ratio=1.0\n",
    "\n",
    "# This will override the `learning_rate` parameter with your\n",
    "# own selection of choices\n",
    "hp.Choice(\"learning_rate\", values=[ 1e-3, 1e-4])\n",
    "\n",
    "\n",
    "import neptune\n",
    "\n",
    "PROJECT = \"squeezeSEAutoHyper\"+str(ratio)\n",
    "neptune.create_experiment(PROJECT)\n",
    "\n",
    " \n",
    "#fn_name = globals()[\"build_SqueezeNet_11_fixed\"](hp)\n",
    "# SqueezeNet \n",
    "\n",
    "mymodel = SqueezeNetSEAutoModel(classes=nb_classes)\n",
    "\n",
    " \n",
    "EPOCH = 200\n",
    "batch_size = 16\n",
    "tuner = Hyperband(\n",
    "    #build_SqueezeNet_11_fixed,\n",
    "    #build_squeezenet_auto_model,\n",
    "    #build_model,\n",
    "    \n",
    "    hypermodel=mymodel,\n",
    "    hyperparameters = hp,\n",
    "    objective=\"val_accuracy\",\n",
    "    #max_trials=20,\n",
    "    executions_per_trial=1,\n",
    "    overwrite=True,\n",
    "    directory=\"mytest_dir\",\n",
    "    project_name=PROJECT,\n",
    "    #distribution_strategy=tf.distribute.MirroredStrategy(),\n",
    "    max_epochs=EPOCH,\n",
    "    logger = npt_utils.NeptuneLogger(),\n",
    "     \n",
    ")\n",
    "tuner.search_space_summary()\n",
    "\n",
    "\n",
    "\"\"\"\"lr_finder = LRFinder(min_lr=1e-5, \n",
    "                    max_lr=1e-3,\n",
    "                    steps_per_epoch=np.ceil(EPOCH/batch_size),\n",
    "                    epochs=3)\"\"\"\n",
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping('val_accuracy', patience=10),\n",
    "    #lr_finder,\n",
    "    #tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5'),\n",
    "    #tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "]\n",
    "\n",
    "tuner.search(x_train[:int(ratio*len(x_train))], y_train[:int(ratio*len(y_train))], epochs=EPOCH, callbacks = my_callbacks,validation_data=(x_test[:int(ratio*len(x_test))], y_test[:int(ratio*len(y_test))]))\n",
    "\n",
    "models = tuner.get_best_models() #(num_models=10)\n",
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4845cd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SqueezeSEAuto random\n",
    "hp = HyperParameters()\n",
    "\n",
    "import neptune\n",
    "\n",
    "\n",
    "PROJECT = \"squeezeSEAutoRandom\"+str(ratio)\n",
    "neptune.create_experiment(PROJECT)\n",
    "\n",
    " \n",
    "# This will override the `learning_rate` parameter with your\n",
    "# own selection of choices\n",
    "\n",
    "hp.Choice(\"learning_rate\", values=[ 1e-3, 1e-4])\n",
    "\n",
    "\n",
    "\n",
    "#fn_name = globals()[\"build_SqueezeNet_11_fixed\"](hp)\n",
    "# SqueezeNet \n",
    "\n",
    "mymodel = SqueezeNetSEAutoModel  (classes=nb_classes)\n",
    "\n",
    " \n",
    "tuner = RandomSearch(\n",
    "    #build_SqueezeNet_11_fixed,\n",
    "    #build_squeezenet_auto_model,\n",
    "    #build_model,\n",
    "    \n",
    "    hypermodel=mymodel,\n",
    "    hyperparameters = hp,\n",
    "    objective=Objective(\"val_accuracy\", direction=\"max\"),\n",
    "    max_trials=100,\n",
    "    executions_per_trial=1,\n",
    "    overwrite=True,\n",
    "    directory=\"mytest_dir\",\n",
    "    project_name=PROJECT,\n",
    "    #distribution_strategy=tf.distribute.MirroredStrategy(),\n",
    "    logger = npt_utils.NeptuneLogger(),\n",
    "     \n",
    ")\n",
    "tuner.search_space_summary()\n",
    "\n",
    "\n",
    "EPOCH = 200\n",
    "batch_size = 16\n",
    "\"\"\"\"lr_finder = LRFinder(min_lr=1e-5, \n",
    "                    max_lr=1e-3,\n",
    "                    steps_per_epoch=np.ceil(EPOCH/batch_size),\n",
    "                    epochs=3)\"\"\"\n",
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping('val_accuracy', patience=10),\n",
    "    #lr_finder,\n",
    "    #tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5'),\n",
    "    #tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "]\n",
    "\n",
    "tuner.search(x_train[:int(ratio*len(x_train))], y_train[:int(ratio*len(y_train))], epochs=EPOCH, callbacks = my_callbacks,validation_data=(x_test[:int(ratio*len(x_test))], y_test[:int(ratio*len(y_test))]))\n",
    "\n",
    "models = tuner.get_best_models() #(num_models=10)\n",
    "tuner.results_summary()\n",
    "npt_utils.log_tuner_info(tuner)\n",
    "\n",
    "i = 0\n",
    "while i < len(models):\n",
    "    print('model  %d size %d'%(i,hypermodel.maybe_compute_model_size(models[i])))\n",
    "    i = i+1\n",
    "    \n",
    "#best_model = tuner.get_best_models(num_models=1)[0]\n",
    "#best_model.evaluate(x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1f8bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "SqueezeSEAuto random\n",
    "hp = HyperParameters()\n",
    "\n",
    "import neptune\n",
    "\n",
    "\n",
    "ratio = 1.0\n",
    "PROJECT = \"squeezeSEAutoBayesian\"+str(ratio)\n",
    "neptune.create_experiment(PROJECT)\n",
    "\n",
    " \n",
    "# This will override the `learning_rate` parameter with your\n",
    "# own selection of choices\n",
    "\n",
    "hp.Choice(\"learning_rate\", values=[ 1e-3, 1e-4])\n",
    "\n",
    "\n",
    "\n",
    "#fn_name = globals()[\"build_SqueezeNet_11_fixed\"](hp)\n",
    "# SqueezeNet \n",
    "\n",
    "mymodel = SqueezeNetSEAutoModel  (classes=nb_classes)\n",
    "\n",
    " \n",
    "tuner = BayesianOptimization(\n",
    "    #build_SqueezeNet_11_fixed,\n",
    "    #build_squeezenet_auto_model,\n",
    "    #build_model,\n",
    "    \n",
    "    hypermodel=mymodel,\n",
    "    hyperparameters = hp,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=100,\n",
    "    executions_per_trial=1,\n",
    "    overwrite=True,\n",
    "    directory=\"mytest_dir\",\n",
    "    project_name= PROJECT,\n",
    "    #distribution_strategy=tf.distribute.MirroredStrategy(),\n",
    "    num_initial_points=2,\n",
    "    alpha=0.0001,\n",
    "    beta=2.6,\n",
    "    seed=None,\n",
    "    tune_new_entries=True,\n",
    "    allow_new_entries=True,\n",
    "    logger = npt_utils.NeptuneLogger(),\n",
    "     \n",
    ")\n",
    "tuner.search_space_summary()\n",
    "\n",
    "\n",
    "EPOCH = 200\n",
    "batch_size = 16\n",
    "\"\"\"\"lr_finder = LRFinder(min_lr=1e-5, \n",
    "                    max_lr=1e-3,\n",
    "                    steps_per_epoch=np.ceil(EPOCH/batch_size),\n",
    "                    epochs=3)\"\"\"\n",
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping('val_accuracy', patience=10),\n",
    "    #lr_finder,\n",
    "    #tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5'),\n",
    "    #tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "]\n",
    "\n",
    "tuner.search(x_train[:int(ratio*len(x_train))], y_train[:int(ratio*len(y_train))], epochs=EPOCH, callbacks = my_callbacks,validation_data=(x_test[:int(ratio*len(x_test))], y_test[:int(ratio*len(y_test))]))\n",
    "\n",
    "models = tuner.get_best_models() #(num_models=10)\n",
    "tuner.results_summary()\n",
    "npt_utils.log_tuner_info(tuner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29ead63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SqueezeAuto Hyperband\n",
    "hp = HyperParameters()\n",
    "\n",
    "ratio=1\n",
    "\n",
    "# This will override the `learning_rate` parameter with your\n",
    "# own selection of choices\n",
    "hp.Choice(\"learning_rate\", values=[ 1e-3, 1e-4])\n",
    "\n",
    "\n",
    "import neptune\n",
    "\n",
    "PROJECT = \"squeezeSEAutoHyper\"+str(ratio)\n",
    "neptune.create_experiment(PROJECT)\n",
    "\n",
    " \n",
    "#fn_name = globals()[\"build_SqueezeNet_11_fixed\"](hp)\n",
    "# SqueezeNet \n",
    "\n",
    "mymodel = SqueezeNetSEAutoModel(classes=nb_classes)\n",
    "\n",
    " \n",
    "EPOCH = 200\n",
    "batch_size = 16\n",
    "tuner = Hyperband(\n",
    "    #build_SqueezeNet_11_fixed,\n",
    "    #build_squeezenet_auto_model,\n",
    "    #build_model,\n",
    "    \n",
    "    hypermodel=mymodel,\n",
    "    hyperparameters = hp,\n",
    "    objective=\"val_accuracy\",\n",
    "    #max_trials=20,\n",
    "    executions_per_trial=1,\n",
    "    overwrite=True,\n",
    "    directory=\"mytest_dir\",\n",
    "    project_name=PROJECT,\n",
    "    #distribution_strategy=tf.distribute.MirroredStrategy(),\n",
    "    max_epochs=EPOCH,\n",
    "    logger = npt_utils.NeptuneLogger(),\n",
    "     \n",
    ")\n",
    "tuner.search_space_summary()\n",
    "\n",
    "\n",
    "\"\"\"\"lr_finder = LRFinder(min_lr=1e-5, \n",
    "                    max_lr=1e-3,\n",
    "                    steps_per_epoch=np.ceil(EPOCH/batch_size),\n",
    "                    epochs=3)\"\"\"\n",
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping('val_accuracy', patience=10),\n",
    "    #lr_finder,\n",
    "    #tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5'),\n",
    "    #tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "]\n",
    "\n",
    "tuner.search(x_train[:int(ratio*len(x_train))], y_train[:int(ratio*len(y_train))], epochs=EPOCH, callbacks = my_callbacks,validation_data=(x_test[:int(ratio*len(x_test))], y_test[:int(ratio*len(y_test))]))\n",
    "\n",
    "models = tuner.get_best_models() #(num_models=10)\n",
    "tuner.results_summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
