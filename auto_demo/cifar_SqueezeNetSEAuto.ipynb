{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version:  2.4.3\n",
      "Eager mode:  True\n",
      "WARNING:tensorflow:From <ipython-input-1-9096ef00c47e>:20: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    " \n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "import glob, os\n",
    "\n",
    "from tensorflow import keras\n",
    "import cv2\n",
    "\n",
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"GPU is\", \"available\" if tf.test.is_gpu_available() else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neptunecontrib.monitoring.kerastuner as npt_utils\n",
    "from keras_tuner import HyperParameters, Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "nb_classes = 10\n",
    "IMG_HEIGHT = 32\n",
    "IMG_WIDTH = 32\n",
    "y_train = np.squeeze(y_train)\n",
    "y_test = np.squeeze(y_test)\n",
    "\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "y_test = keras.utils.to_categorical(y_test,10)\n",
    "y_train = keras.utils.to_categorical(y_train,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32, 32, 3, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SqueezeNet Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyper paramter squeezenet\n",
    "\n",
    " \n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from keras_tuner import RandomSearch, Hyperband,SklearnTuner,BayesianOptimization\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def get_axis():\n",
    "    axis = -1 if K.image_data_format() == 'channels_last' else 1\n",
    "    return axis\n",
    "\n",
    "def create_fire_module(x, nb_squeeze_filter, name, use_bypass=False):\n",
    "    \"\"\"\n",
    "    Creates a fire module\n",
    "    \n",
    "    Arguments:\n",
    "        x                 : input\n",
    "        nb_squeeze_filter : number of filters of squeeze. The filtersize of expand is 4 times of squeeze\n",
    "        use_bypass        : if True then a bypass will be added\n",
    "        name              : name of module e.g. fire123\n",
    "    \n",
    "    Returns:\n",
    "        x                 : returns a fire module\n",
    "    \"\"\"\n",
    "    \n",
    "    nb_expand_filter = 4 * nb_squeeze_filter\n",
    "    squeeze    = layers.Conv2D(nb_squeeze_filter,(1,1), activation='relu', padding='same', name='%s_squeeze'%name)(x)\n",
    "    expand_1x1 = layers.Conv2D(nb_expand_filter, (1,1), activation='relu', padding='same', name='%s_expand_1x1'%name)(squeeze)\n",
    "    expand_3x3 = layers.Conv2D(nb_expand_filter, (3,3), activation='relu', padding='same', name='%s_expand_3x3'%name)(squeeze)\n",
    "    \n",
    "    axis = get_axis()\n",
    "    x_ret =  layers.Concatenate(axis=axis, name='%s_concatenate'%name)([expand_1x1, expand_3x3])\n",
    "    \n",
    "    if use_bypass:\n",
    "        x_ret =  layers.Add(name='%s_concatenate_bypass'%name)([x_ret, x])\n",
    "        \n",
    "    return x_ret\n",
    "\n",
    "\n",
    "def output(x, nb_classes):\n",
    "    x = layers.Conv2D(nb_classes, (1,1), strides=(1,1), padding='valid', name='conv10')(x)\n",
    "    x = layers.GlobalAveragePooling2D(name='avgpool10')(x)\n",
    "    x = layers.Activation(\"softmax\", name='softmax')(x)\n",
    "    return x\n",
    "\n",
    "def build_SqueezeNet_fixed(hp):\n",
    "    \"\"\"\n",
    "    Creating a SqueezeNet of version 1.0\n",
    "    \n",
    "    Arguments:\n",
    "        input_shape  : shape of the input images e.g. (224,224,3)\n",
    "        nb_classes   : number of classes\n",
    "        use_bypass   : if true, bypass connections will be created at fire module 3, 5, 7, and 9 (default: False)\n",
    "        dropout_rate : defines the dropout rate that is accomplished after last fire module (default: None)\n",
    "        compression  : reduce the number of feature-maps (default: 1.0)\n",
    "        \n",
    "    Returns:\n",
    "        Model        : Keras model instance\n",
    "    \"\"\"\n",
    "    use_bypass = hp.Boolean('use_bypass')\n",
    "    compression = hp.Fixed('compression',1.0)\n",
    "    \n",
    "    input_img = tf.keras.layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "\n",
    "     \n",
    "    x = tf.keras.layers.Conv2D(int(96*compression), (7,7), activation='relu', strides=(2,2), padding='same', name='conv1')(input_img)\n",
    "\n",
    "    x = tf.keras.layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool1')(x)\n",
    "    \n",
    "    x = create_fire_module(x, int(16*compression), name='fire2')\n",
    "    x = create_fire_module(x, int(16*compression), name='fire3', use_bypass=use_bypass)\n",
    "    x = create_fire_module(x, int(32*compression), name='fire4')\n",
    "    \n",
    "    x = layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool4')(x)\n",
    "    \n",
    "    x = create_fire_module(x, int(32*compression), name='fire5', use_bypass=use_bypass)\n",
    "    x = create_fire_module(x, int(48*compression), name='fire6')\n",
    "    x = create_fire_module(x, int(48*compression), name='fire7', use_bypass=use_bypass)\n",
    "    x = create_fire_module(x, int(64*compression), name='fire8')\n",
    "    \n",
    "    x =  layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool8')(x)\n",
    "    \n",
    "    x = create_fire_module(x, int(64*compression), name='fire9', use_bypass=use_bypass)\n",
    "\n",
    "    dropout_rate = hp.Choice('dropout_rate',values=[0.0,0.5,0.8])\n",
    "    \n",
    "    if dropout_rate:\n",
    "        x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "        \n",
    "    x =  output(x, nb_classes)\n",
    "    model = keras.Model(inputs=input_img, outputs=x)\n",
    "    optimizer = hp.Choice(\"optimizer\", [\"RMSprop\" \"sgd\"])\n",
    "    model.compile(\n",
    "        optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    " \n",
    "    \n",
    "def build_SqueezeNet_11_fixed(hp):\n",
    "    \"\"\"\n",
    "    Creating a SqueezeNet of version 1.1\n",
    "    \n",
    "    2.4x less computation over SqueezeNet 1.0 implemented above.\n",
    "    \n",
    "    Arguments:\n",
    "        input_shape  : shape of the input images e.g. (224,224,3)\n",
    "        nb_classes   : number of classes\n",
    "        dropout_rate : defines the dropout rate that is accomplished after last fire module (default: None)\n",
    "        compression  : reduce the number of feature-maps\n",
    "        \n",
    "    Returns:\n",
    "        Model        : Keras model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    use_bypass = hp.Boolean('use_bypass')\n",
    "    compression = hp.Fixed('compression',1.0)\n",
    "    \n",
    "    input_img =  layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "\n",
    "    \n",
    "  \n",
    "    x = layers.Conv2D(int(64*compression), (3,3), activation='relu', strides=(2,2), padding='same', name='conv1')(input_img)\n",
    "\n",
    "    x = layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool1')(x)\n",
    "    \n",
    "    x = create_fire_module(x, int(16*compression), name='fire2')\n",
    "    x = create_fire_module(x, int(16*compression), name='fire3')\n",
    "    \n",
    "    x = layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool3')(x)\n",
    "    \n",
    "    x = create_fire_module(x, int(32*compression), name='fire4')\n",
    "    x = create_fire_module(x, int(32*compression), name='fire5')\n",
    "    \n",
    "    x = layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool5')(x)\n",
    "    \n",
    "    x = create_fire_module(x, int(48*compression), name='fire6')\n",
    "    x = create_fire_module(x, int(48*compression), name='fire7')\n",
    "    x = create_fire_module(x, int(64*compression), name='fire8')\n",
    "    x = create_fire_module(x, int(64*compression), name='fire9')\n",
    "\n",
    "    dropout_rate = hp.Choice('dropout_rate',values=[0.0,0.5,0.8])\n",
    "        \n",
    "    if dropout_rate:\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "    \n",
    "    # Creating last conv10\n",
    "    x = output(x, nb_classes)\n",
    "\n",
    " \n",
    "    model = keras.Model(inputs=input_img, outputs=x)\n",
    "    optimizer = hp.Choice(\"optimizer\",[\"RMSprop\",\"sgd\"]) #[\"adam\", \"sgd\"])\n",
    "    model.compile(\n",
    "        optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squeeze_excitation_layer(input_layer, out_dim, ratio, conv=False):\n",
    "  squeeze =  layers.GlobalAveragePooling2D()(input_layer)\n",
    "\n",
    "  excitation =  layers.Dense(units=out_dim / ratio, activation='relu')(squeeze)\n",
    "  excitation =  layers.Dense(out_dim,activation='sigmoid')(excitation)\n",
    "  excitation =  tf.reshape(excitation, [-1,1,1,out_dim])\n",
    "\n",
    "  scale =  layers.multiply([input_layer, excitation])\n",
    "\n",
    "  if conv:\n",
    "    shortcut = tf.keras.layers.Conv2D(out_dim,kernel_size=1,strides=1,\n",
    "                                      padding='same',kernel_initializer='he_normal')(input_layer)\n",
    "    shortcut = tf.keras.layers.BatchNormalization()(shortcut)\n",
    "  else:\n",
    "    shortcut = input_layer\n",
    "    \n",
    "  out = scale # tf.keras.layers.add([shortcut, scale])\n",
    "  return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SqueezeNet SE Auto Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SqueezeNetSE auto model\n",
    "from keras_tuner import HyperModel\n",
    "\n",
    "\n",
    "class SqueezeNetSEAutoModel(HyperModel):\n",
    "    def __init__(self, classes):\n",
    "        self.classes = classes\n",
    "\n",
    "    def build(self, hp):\n",
    "       \n",
    "          \n",
    "        compression_val = hp.Fixed('compression',1.0)\n",
    "    \n",
    "        \n",
    "        \n",
    "        input_img =  layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "\n",
    "        \n",
    "        x = layers.Conv2D(int(96*compression_val), (3,3), activation='relu', strides=(2,2), padding='same', name='conv1')(input_img)\n",
    "\n",
    "        x = layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool1')(x)\n",
    "    \n",
    "         \n",
    "\n",
    "        j = 2\n",
    "        filter_size = 16\n",
    "\n",
    "        num_fire = hp.Int(\"fire_module\", 1,2, default=2)\n",
    "        use_bypass = [ hp.Boolean('use_bypass'+str(i)) for i in range(num_fire)]\n",
    "        pooling = [ hp.Choice('pooling'+str(i), [\"max\", \"avg\"]) for i in range(num_fire) ]\n",
    "        \n",
    "        print(use_bypass)\n",
    "        print(pooling)\n",
    "        for i in range(num_fire):\n",
    "         \n",
    "            ratio = hp.Choice(\"squeeze_ratio\"+str(j),[8,16,32], default=32)\n",
    "            x_in = x\n",
    "            x = create_fire_module(x, int(filter_size*compression_val), name='fire'+str(j), )\n",
    "            \n",
    "            se_insert = hp.Boolean(\"SE_add\"+str(j))\n",
    "            \n",
    "            if se_insert:\n",
    "                x = squeeze_excitation_layer(x, out_dim=x.shape[3], ratio=ratio)\n",
    "                \n",
    "                if hp.Boolean(\"SE_skip\"+str(j)):\n",
    "                    if x_in.shape[3] != x.shape[3] :\n",
    "                        x_in =  layers.Conv2D(x.shape[3],kernel_size=1,strides=1,\n",
    "                                      padding='same',kernel_initializer='he_normal')(x_in)\n",
    "                        x_in = tf.keras.layers.BatchNormalization()(x_in)\n",
    "                        \n",
    "                    x = tf.keras.layers.add([x_in, x])\n",
    "                                     \n",
    "            \n",
    "            ratio = hp.Choice(\"squeeze_ratio\"+str(j),[8,16,32], default=32)\n",
    "            x_in = x\n",
    "            x = create_fire_module(x, int(filter_size*compression_val), name='fire'+str(j+1),use_bypass=use_bypass[i])\n",
    "\n",
    "            se_insert = hp.Boolean(\"SE_add\"+str(j+1))\n",
    "            \n",
    "            if se_insert:\n",
    "                 \n",
    "                x = squeeze_excitation_layer(x, out_dim=x.shape[3], ratio=ratio)\n",
    "                \n",
    "                if hp.Boolean(\"SE_skip\"+str(j+1)):\n",
    "                    if x_in.shape[3] != x.shape[3] :\n",
    "                        x_in =  layers.Conv2D(x.shape[3],kernel_size=1,strides=1,\n",
    "                                      padding='same',kernel_initializer='he_normal')(x_in)\n",
    "                        x_in = tf.keras.layers.BatchNormalization()(x_in)\n",
    "                        \n",
    "                    x = tf.keras.layers.add([x_in, x])\n",
    "                     \n",
    "            \n",
    "                \n",
    "            #if hp.Choice(\"pooling\", [\"max\", \"avg\"]) == \"max\":\n",
    "            if pooling[i] == \"max\":\n",
    "\n",
    "                x =  layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool'+str(j+1))(x)\n",
    "            else:\n",
    "                x =  layers.AveragePooling2D(pool_size=(3,3), strides=(2,2), name='avgpool'+str(j+1))(x)\n",
    "\n",
    "\n",
    "            j = j+2\n",
    "            filter_size = filter_size+16\n",
    "            \n",
    "        num_fire2 = hp.Int('num_fire_2',0,2, default=2)\n",
    "        use_bypass2 = [ hp.Boolean('use_bypass_2'+str(i)) for i in range(num_fire2)]\n",
    "         \n",
    "        print(use_bypass2)\n",
    "         \n",
    "        for i in range(num_fire2): \n",
    "            \n",
    "            ratio = hp.Choice(\"squeeze_ratio\"+str(j),[8,16,32], default=32)\n",
    "            \n",
    "            x_in = x\n",
    "            x = create_fire_module(x, int(filter_size*compression_val), name='fire'+str(j))\n",
    "            \n",
    "            se_insert = hp.Boolean(\"SE_add\"+str(j))\n",
    "            \n",
    "            if se_insert:\n",
    "                x = squeeze_excitation_layer(x, out_dim=x.shape[3], ratio=ratio)\n",
    "                if hp.Boolean(\"SE_skip\"+str(j)):\n",
    "                    if x_in.shape[3] != x.shape[3] :\n",
    "                        x_in =  layers.Conv2D(x.shape[3],kernel_size=1,strides=1,\n",
    "                                          padding='same',kernel_initializer='he_normal')(x_in)\n",
    "                        x_in = tf.keras.layers.BatchNormalization()(x_in)\n",
    "                    x = tf.keras.layers.add([x_in, x])\n",
    "                \n",
    "            ratio = hp.Choice(\"squeeze_ratio\"+str(j),[8,16,32], default=32)\n",
    "            \n",
    "            x_in = x\n",
    "            x = create_fire_module(x, int(filter_size*compression_val), name='fire'+str(j+1),use_bypass=use_bypass2[i])\n",
    "            \n",
    "            se_insert = hp.Boolean(\"SE_add\"+str(j+1))\n",
    "            \n",
    "            if se_insert:\n",
    "                x = squeeze_excitation_layer(x, out_dim=x.shape[3], ratio=ratio)\n",
    "                if hp.Boolean(\"SE_skip\"+str(j+1)):\n",
    "                    if x_in.shape[3] != x.shape[3] :\n",
    "                        x_in =  layers.Conv2D(x.shape[3],kernel_size=1,strides=1,\n",
    "                                          padding='same',kernel_initializer='he_normal')(x_in)\n",
    "                        x_in = tf.keras.layers.BatchNormalization()(x_in)\n",
    "                    x = tf.keras.layers.add([x_in, x])\n",
    "                    \n",
    "            filter_size = filter_size+16\n",
    "            j = j+2\n",
    "\n",
    "            #x = create_fire_module(x, int(filter_size*compression_val), name='fire8')\n",
    "            #x = create_fire_module(x, int(filter_size*compression_val), name='fire9',use_bypass=hp.Boolean('use_bypass'))\n",
    "        \n",
    "        \n",
    "        \n",
    "        dropout_rate = hp.Float('dropout_rate',0.0,0.8)\n",
    "        if dropout_rate:\n",
    "            x = layers.Dropout(dropout_rate)(x)\n",
    "\n",
    "        x = output(x, self.classes)\n",
    "\n",
    "        model = keras.Model(inputs=input_img, outputs=x)\n",
    "\n",
    "        optimizer = hp.Choice(\"optimizer\", [\"RMSprop\", \"sgd\"])\n",
    "        model.compile(\n",
    "            optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "        )\n",
    "        return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SqueezeNet Model (Class definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SqueezeNet \n",
    "from keras_tuner import HyperModel\n",
    "\n",
    "\n",
    "class SqueezeNetModel(HyperModel):\n",
    "    def __init__(self, classes):\n",
    "        self.classes = classes\n",
    "\n",
    "    def build(self, hp):\n",
    "       \n",
    "        use_bypass = hp.Boolean('use_bypass')\n",
    "        compression = hp.Fixed('compression',1.0)\n",
    "\n",
    "        input_img = layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "\n",
    "        x = tf.keras.layers.Conv2D(int(96*compression), (7,7), activation='relu', strides=(2,2), padding='same', name='conv1')(input_img)\n",
    "\n",
    "        x = tf.keras.layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool1')(x)\n",
    "\n",
    "        x = create_fire_module(x, int(16*compression), name='fire2')\n",
    "        x = create_fire_module(x, int(16*compression), name='fire3', use_bypass=use_bypass)\n",
    "        x = create_fire_module(x, int(32*compression), name='fire4')\n",
    "\n",
    "        x = layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool4')(x)\n",
    "\n",
    "        x = create_fire_module(x, int(32*compression), name='fire5', use_bypass=use_bypass)\n",
    "        x = create_fire_module(x, int(48*compression), name='fire6')\n",
    "        x = create_fire_module(x, int(48*compression), name='fire7', use_bypass=use_bypass)\n",
    "        x = create_fire_module(x, int(64*compression), name='fire8')\n",
    "\n",
    "        x =  layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool8')(x)\n",
    "\n",
    "        x = create_fire_module(x, int(64*compression), name='fire9', use_bypass=use_bypass)\n",
    "\n",
    "        dropout_rate = hp.Choice('dropout_rate',values=[0.0,0.5,0.8])\n",
    "\n",
    "        if dropout_rate:\n",
    "            x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "\n",
    "        x =  output(x, self.classes)\n",
    "        model = keras.Model(inputs=input_img, outputs=x)\n",
    "        optimizer = hp.Choice(\"optimizer\", [\"RMSprop\", \"sgd\"]) # adam is not good\n",
    "        model.compile(\n",
    "            optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "        )\n",
    "        return model\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SqueezeNet 11 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SqueezeNet 11 model\n",
    "from keras_tuner import HyperModel\n",
    "\n",
    "\n",
    "class SqueezeNet11Model(HyperModel):\n",
    "    def __init__(self, classes):\n",
    "        self.classes = classes\n",
    "\n",
    "    def build(self, hp):\n",
    "       \n",
    "        use_bypass = hp.Boolean('use_bypass')\n",
    "        compression = hp.Fixed('compression',1.0)\n",
    "\n",
    "        input_img =  layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "\n",
    "\n",
    "        x = layers.Conv2D(int(64*compression), (3,3), activation='relu', strides=(2,2), padding='same', name='conv1')(input_img)\n",
    "\n",
    "        x = layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool1')(x)\n",
    "\n",
    "        x = create_fire_module(x, int(16*compression), name='fire2')\n",
    "        x = create_fire_module(x, int(16*compression), name='fire3')\n",
    "\n",
    "        x = layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool3')(x)\n",
    "\n",
    "        x = create_fire_module(x, int(32*compression), name='fire4')\n",
    "        x = create_fire_module(x, int(32*compression), name='fire5')\n",
    "\n",
    "        x = layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool5')(x)\n",
    "\n",
    "        x = create_fire_module(x, int(48*compression), name='fire6')\n",
    "        x = create_fire_module(x, int(48*compression), name='fire7')\n",
    "        x = create_fire_module(x, int(64*compression), name='fire8')\n",
    "        x = create_fire_module(x, int(64*compression), name='fire9')\n",
    "\n",
    "        dropout_rate = hp.Choice('dropout_rate',values=[0.1,0.5,0.8])\n",
    "\n",
    "        if dropout_rate:\n",
    "            x = layers.Dropout(dropout_rate)(x)\n",
    "\n",
    "        # Creating last conv10\n",
    "        x = output(x, self.classes)\n",
    "        model = keras.Model(inputs=input_img, outputs=x)\n",
    "        optimizer = hp.Choice(\"optimizer\",     [\"sgd\",\"RMSprop\"])\n",
    "        model.compile(\n",
    "            optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "        )\n",
    "        return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://gist.github.com/jeremyjordan/ac0229abd4b2b7000aca1643e88e0f02\n",
    "\n",
    "#learning rate callbacks\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "\n",
    "class LRFinder(Callback):\n",
    "    \n",
    "    '''\n",
    "    A simple callback for finding the optimal learning rate range for your model + dataset. \n",
    "    \n",
    "    # Usage\n",
    "        ```python\n",
    "            lr_finder = LRFinder(min_lr=1e-5, \n",
    "                                 max_lr=1e-2, \n",
    "                                 steps_per_epoch=np.ceil(epoch_size/batch_size), \n",
    "                                 epochs=3)\n",
    "            model.fit(X_train, Y_train, callbacks=[lr_finder])\n",
    "            \n",
    "            lr_finder.plot_loss()\n",
    "        ```\n",
    "    \n",
    "    # Arguments\n",
    "        min_lr: The lower bound of the learning rate range for the experiment.\n",
    "        max_lr: The upper bound of the learning rate range for the experiment.\n",
    "        steps_per_epoch: Number of mini-batches in the dataset. Calculated as `np.ceil(epoch_size/batch_size)`. \n",
    "        epochs: Number of epochs to run experiment. Usually between 2 and 4 epochs is sufficient. \n",
    "        \n",
    "    # References\n",
    "        Blog post: jeremyjordan.me/nn-learning-rate\n",
    "        Original paper: https://arxiv.org/abs/1506.01186\n",
    "\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, min_lr=1e-5, max_lr=1e-3, steps_per_epoch=None, epochs=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.min_lr = min_lr\n",
    "        self.max_lr = max_lr\n",
    "        self.total_iterations = steps_per_epoch * epochs\n",
    "        self.iteration = 0\n",
    "        self.history = {}\n",
    "        \n",
    "    def clr(self):\n",
    "        '''Calculate the learning rate.'''\n",
    "        x = self.iteration / self.total_iterations \n",
    "        return self.min_lr + (self.max_lr-self.min_lr) * x\n",
    "        \n",
    "    def on_train_begin(self, logs=None):\n",
    "        '''Initialize the learning rate to the minimum value at the start of training.'''\n",
    "        logs = logs or {}\n",
    "        K.set_value(self.model.optimizer.lr, self.min_lr)\n",
    "        \n",
    "    def on_batch_end(self, epoch, logs=None):\n",
    "        '''Record previous batch statistics and update the learning rate.'''\n",
    "        logs = logs or {}\n",
    "        self.iteration += 1\n",
    "\n",
    "        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n",
    "        self.history.setdefault('iterations', []).append(self.iteration)\n",
    "\n",
    "        for k, v in logs.items():\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "            \n",
    "        K.set_value(self.model.optimizer.lr, self.clr())\n",
    " \n",
    "    def plot_lr(self):\n",
    "        '''Helper function to quickly inspect the learning rate schedule.'''\n",
    "        plt.plot(self.history['iterations'], self.history['lr'])\n",
    "        plt.yscale('log')\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('Learning rate')\n",
    "        plt.show()\n",
    "        \n",
    "    def plot_loss(self):\n",
    "        '''Helper function to quickly observe the learning rate experiment results.'''\n",
    "        plt.plot(self.history['lr'], self.history['loss'])\n",
    "        plt.xscale('log')\n",
    "        plt.xlabel('Learning rate')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Project(cchantra/keras-tuner)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import neptune\n",
    "neptune.init(project_qualified_name='yyy',api_token='xx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search schemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 100 Complete [00h 02m 19s]\n",
      "val_accuracy: 0.5120000243186951\n",
      "\n",
      "Best val_accuracy So Far: 0.5720000267028809\n",
      "Total elapsed time: 03h 16m 32s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "[True]\n",
      "['avg']\n",
      "[False]\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.rho\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Results summary\n",
      "Results in mytest_dir/squeezeSEAutoRandom0.1\n",
      "Showing 10 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "compression: 1.0\n",
      "fire_module: 1\n",
      "use_bypass0: True\n",
      "use_bypass1: True\n",
      "pooling0: avg\n",
      "pooling1: avg\n",
      "squeeze_ratio2: 8\n",
      "SE_add2: True\n",
      "SE_add3: True\n",
      "squeeze_ratio4: 32\n",
      "SE_add4: True\n",
      "SE_add5: False\n",
      "num_fire_2: 1\n",
      "use_bypass_20: False\n",
      "use_bypass_21: False\n",
      "squeeze_ratio6: 32\n",
      "SE_add6: True\n",
      "SE_add7: False\n",
      "squeeze_ratio8: 16\n",
      "SE_add8: False\n",
      "SE_add9: False\n",
      "dropout_rate: 0.3880199711045407\n",
      "optimizer: RMSprop\n",
      "SE_skip2: False\n",
      "SE_skip4: True\n",
      "SE_skip5: True\n",
      "SE_skip3: False\n",
      "SE_skip6: False\n",
      "SE_skip7: True\n",
      "SE_skip8: False\n",
      "SE_skip9: False\n",
      "Score: 0.5720000267028809\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "compression: 1.0\n",
      "fire_module: 2\n",
      "use_bypass0: False\n",
      "use_bypass1: False\n",
      "pooling0: max\n",
      "pooling1: max\n",
      "squeeze_ratio2: 8\n",
      "SE_add2: False\n",
      "SE_add3: True\n",
      "squeeze_ratio4: 32\n",
      "SE_add4: True\n",
      "SE_add5: True\n",
      "num_fire_2: 0\n",
      "use_bypass_20: False\n",
      "use_bypass_21: True\n",
      "squeeze_ratio6: 16\n",
      "SE_add6: True\n",
      "SE_add7: False\n",
      "squeeze_ratio8: 16\n",
      "SE_add8: False\n",
      "SE_add9: True\n",
      "dropout_rate: 0.6117045884217738\n",
      "optimizer: RMSprop\n",
      "SE_skip2: False\n",
      "SE_skip4: True\n",
      "SE_skip5: True\n",
      "SE_skip3: False\n",
      "SE_skip6: False\n",
      "SE_skip7: False\n",
      "SE_skip8: True\n",
      "SE_skip9: False\n",
      "Score: 0.5550000071525574\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "compression: 1.0\n",
      "fire_module: 2\n",
      "use_bypass0: True\n",
      "use_bypass1: False\n",
      "pooling0: avg\n",
      "pooling1: max\n",
      "squeeze_ratio2: 8\n",
      "SE_add2: False\n",
      "SE_add3: True\n",
      "squeeze_ratio4: 32\n",
      "SE_add4: True\n",
      "SE_add5: True\n",
      "num_fire_2: 1\n",
      "use_bypass_20: False\n",
      "use_bypass_21: True\n",
      "squeeze_ratio6: 8\n",
      "SE_add6: True\n",
      "SE_add7: False\n",
      "squeeze_ratio8: 8\n",
      "SE_add8: False\n",
      "SE_add9: True\n",
      "dropout_rate: 0.5432970251051814\n",
      "optimizer: RMSprop\n",
      "SE_skip2: True\n",
      "SE_skip4: False\n",
      "SE_skip5: True\n",
      "SE_skip3: False\n",
      "SE_skip6: True\n",
      "SE_skip7: True\n",
      "SE_skip8: True\n",
      "SE_skip9: True\n",
      "Score: 0.546999990940094\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "compression: 1.0\n",
      "fire_module: 1\n",
      "use_bypass0: False\n",
      "use_bypass1: True\n",
      "pooling0: avg\n",
      "pooling1: avg\n",
      "squeeze_ratio2: 16\n",
      "SE_add2: True\n",
      "SE_add3: False\n",
      "squeeze_ratio4: 8\n",
      "SE_add4: True\n",
      "SE_add5: False\n",
      "num_fire_2: 1\n",
      "use_bypass_20: False\n",
      "use_bypass_21: True\n",
      "squeeze_ratio6: 8\n",
      "SE_add6: True\n",
      "SE_add7: True\n",
      "squeeze_ratio8: 16\n",
      "SE_add8: True\n",
      "SE_add9: False\n",
      "dropout_rate: 0.15024434312520152\n",
      "optimizer: sgd\n",
      "SE_skip2: True\n",
      "SE_skip4: False\n",
      "SE_skip5: False\n",
      "SE_skip3: False\n",
      "SE_skip6: False\n",
      "SE_skip7: False\n",
      "SE_skip8: True\n",
      "SE_skip9: False\n",
      "Score: 0.5389999747276306\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "compression: 1.0\n",
      "fire_module: 1\n",
      "use_bypass0: False\n",
      "use_bypass1: True\n",
      "pooling0: max\n",
      "pooling1: avg\n",
      "squeeze_ratio2: 16\n",
      "SE_add2: True\n",
      "SE_add3: True\n",
      "squeeze_ratio4: 32\n",
      "SE_add4: False\n",
      "SE_add5: False\n",
      "num_fire_2: 1\n",
      "use_bypass_20: True\n",
      "use_bypass_21: True\n",
      "squeeze_ratio6: 32\n",
      "SE_add6: True\n",
      "SE_add7: False\n",
      "squeeze_ratio8: 32\n",
      "SE_add8: False\n",
      "SE_add9: True\n",
      "dropout_rate: 0.4608421242629961\n",
      "optimizer: RMSprop\n",
      "SE_skip2: True\n",
      "SE_skip4: True\n",
      "SE_skip5: True\n",
      "SE_skip3: True\n",
      "SE_skip6: True\n",
      "SE_skip7: True\n",
      "SE_skip8: False\n",
      "SE_skip9: False\n",
      "Score: 0.5360000133514404\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "compression: 1.0\n",
      "fire_module: 1\n",
      "use_bypass0: False\n",
      "use_bypass1: True\n",
      "pooling0: avg\n",
      "pooling1: avg\n",
      "squeeze_ratio2: 16\n",
      "SE_add2: True\n",
      "SE_add3: False\n",
      "squeeze_ratio4: 32\n",
      "SE_add4: True\n",
      "SE_add5: False\n",
      "num_fire_2: 1\n",
      "use_bypass_20: True\n",
      "use_bypass_21: False\n",
      "squeeze_ratio6: 16\n",
      "SE_add6: False\n",
      "SE_add7: True\n",
      "squeeze_ratio8: 32\n",
      "SE_add8: True\n",
      "SE_add9: True\n",
      "dropout_rate: 0.26519882389812494\n",
      "optimizer: RMSprop\n",
      "SE_skip2: True\n",
      "SE_skip4: False\n",
      "SE_skip5: True\n",
      "SE_skip3: True\n",
      "SE_skip6: True\n",
      "SE_skip7: False\n",
      "SE_skip8: True\n",
      "SE_skip9: True\n",
      "Score: 0.5350000262260437\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "compression: 1.0\n",
      "fire_module: 2\n",
      "use_bypass0: True\n",
      "use_bypass1: True\n",
      "pooling0: avg\n",
      "pooling1: avg\n",
      "squeeze_ratio2: 32\n",
      "SE_add2: False\n",
      "SE_add3: False\n",
      "squeeze_ratio4: 16\n",
      "SE_add4: True\n",
      "SE_add5: True\n",
      "num_fire_2: 2\n",
      "use_bypass_20: True\n",
      "use_bypass_21: False\n",
      "squeeze_ratio6: 32\n",
      "SE_add6: True\n",
      "SE_add7: False\n",
      "squeeze_ratio8: 16\n",
      "SE_add8: True\n",
      "SE_add9: True\n",
      "dropout_rate: 0.5513866434202542\n",
      "optimizer: RMSprop\n",
      "SE_skip2: True\n",
      "SE_skip4: True\n",
      "SE_skip5: False\n",
      "SE_skip3: True\n",
      "SE_skip6: False\n",
      "SE_skip7: True\n",
      "SE_skip8: True\n",
      "SE_skip9: True\n",
      "Score: 0.5320000052452087\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.001\n",
      "compression: 1.0\n",
      "fire_module: 2\n",
      "use_bypass0: False\n",
      "use_bypass1: True\n",
      "pooling0: max\n",
      "pooling1: max\n",
      "squeeze_ratio2: 32\n",
      "SE_add2: True\n",
      "SE_add3: False\n",
      "squeeze_ratio4: 16\n",
      "SE_add4: True\n",
      "SE_add5: False\n",
      "num_fire_2: 1\n",
      "use_bypass_20: False\n",
      "use_bypass_21: True\n",
      "squeeze_ratio6: 16\n",
      "SE_add6: False\n",
      "SE_add7: True\n",
      "squeeze_ratio8: 16\n",
      "SE_add8: True\n",
      "SE_add9: False\n",
      "dropout_rate: 0.12795166399672775\n",
      "optimizer: sgd\n",
      "SE_skip2: True\n",
      "SE_skip4: True\n",
      "SE_skip5: True\n",
      "SE_skip3: False\n",
      "SE_skip6: False\n",
      "SE_skip7: True\n",
      "SE_skip8: False\n",
      "SE_skip9: False\n",
      "Score: 0.5320000052452087\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.001\n",
      "compression: 1.0\n",
      "fire_module: 2\n",
      "use_bypass0: False\n",
      "use_bypass1: True\n",
      "pooling0: avg\n",
      "pooling1: max\n",
      "squeeze_ratio2: 8\n",
      "SE_add2: True\n",
      "SE_add3: True\n",
      "squeeze_ratio4: 16\n",
      "SE_add4: False\n",
      "SE_add5: False\n",
      "num_fire_2: 0\n",
      "use_bypass_20: False\n",
      "use_bypass_21: True\n",
      "squeeze_ratio6: 16\n",
      "SE_add6: False\n",
      "SE_add7: False\n",
      "squeeze_ratio8: 8\n",
      "SE_add8: True\n",
      "SE_add9: True\n",
      "dropout_rate: 0.12499924496431492\n",
      "optimizer: RMSprop\n",
      "SE_skip2: True\n",
      "SE_skip4: True\n",
      "SE_skip5: True\n",
      "SE_skip3: False\n",
      "SE_skip6: True\n",
      "SE_skip7: False\n",
      "SE_skip8: True\n",
      "SE_skip9: False\n",
      "Score: 0.5320000052452087\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "compression: 1.0\n",
      "fire_module: 1\n",
      "use_bypass0: False\n",
      "use_bypass1: False\n",
      "pooling0: avg\n",
      "pooling1: avg\n",
      "squeeze_ratio2: 16\n",
      "SE_add2: False\n",
      "SE_add3: False\n",
      "squeeze_ratio4: 8\n",
      "SE_add4: True\n",
      "SE_add5: False\n",
      "num_fire_2: 2\n",
      "use_bypass_20: True\n",
      "use_bypass_21: False\n",
      "squeeze_ratio6: 32\n",
      "SE_add6: False\n",
      "SE_add7: True\n",
      "squeeze_ratio8: 8\n",
      "SE_add8: False\n",
      "SE_add9: True\n",
      "dropout_rate: 0.28875897386999566\n",
      "optimizer: RMSprop\n",
      "SE_skip2: False\n",
      "SE_skip4: True\n",
      "SE_skip5: True\n",
      "SE_skip3: False\n",
      "SE_skip6: False\n",
      "SE_skip7: False\n",
      "SE_skip8: False\n",
      "SE_skip9: True\n",
      "Score: 0.531000018119812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected error in ping thread.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 600, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 384, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 2, in raise_from\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 380, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/http/client.py\", line 1321, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/http/client.py\", line 296, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/http/client.py\", line 257, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/socket.py\", line 589, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/urllib3/contrib/pyopenssl.py\", line 299, in recv_into\n",
      "    raise SocketError(str(e))\n",
      "OSError: (104, 'ECONNRESET')\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/requests/adapters.py\", line 449, in send\n",
      "    timeout=timeout\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 638, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/urllib3/util/retry.py\", line 367, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/urllib3/packages/six.py\", line 685, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 600, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 384, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 2, in raise_from\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 380, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/http/client.py\", line 1321, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/http/client.py\", line 296, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/http/client.py\", line 257, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/socket.py\", line 589, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/urllib3/contrib/pyopenssl.py\", line 299, in recv_into\n",
      "    raise SocketError(str(e))\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', OSError(\"(104, 'ECONNRESET')\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/bravado/http_future.py\", line 124, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/bravado/http_future.py\", line 291, in _get_incoming_response\n",
      "    inner_response = self.future.result(timeout=timeout)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/bravado/requests_client.py\", line 270, in result\n",
      "    **settings\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/requests/sessions.py\", line 646, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/requests/adapters.py\", line 498, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', OSError(\"(104, 'ECONNRESET')\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/neptune/internal/threads/ping_thread.py\", line 37, in run\n",
      "    self.__backend.ping_experiment(self.__experiment)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/neptune/internal/api_clients/hosted_api_clients/hosted_alpha_leaderboard_api_client.py\", line 393, in ping_experiment\n",
      "    self.leaderboard_swagger_client.api.ping(experimentId=str(experiment.internal_id)).response().result\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/bravado/http_future.py\", line 239, in response\n",
      "    six.reraise(*sys.exc_info())\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/six.py\", line 703, in reraise\n",
      "    raise value\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/bravado/http_future.py\", line 197, in response\n",
      "    incoming_response = self._get_incoming_response(timeout)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/bravado/http_future.py\", line 126, in wrapper\n",
      "    self.future._raise_connection_error(exception)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/bravado/http_future.py\", line 91, in _raise_connection_error\n",
      "    self._raise_error(BravadoConnectionError, 'ConnectionError', exception)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/bravado/http_future.py\", line 82, in _raise_error\n",
      "    sys.exc_info()[2],\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/six.py\", line 702, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/bravado/http_future.py\", line 124, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/bravado/http_future.py\", line 291, in _get_incoming_response\n",
      "    inner_response = self.future.result(timeout=timeout)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/bravado/requests_client.py\", line 270, in result\n",
      "    **settings\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/requests/sessions.py\", line 646, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/requests/adapters.py\", line 498, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "bravado.http_future.RequestsFutureAdapterConnectionError\n",
      "Unexpected error in ping thread.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 600, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 384, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 2, in raise_from\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 380, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/http/client.py\", line 1321, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/http/client.py\", line 296, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/http/client.py\", line 257, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/socket.py\", line 589, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/urllib3/contrib/pyopenssl.py\", line 299, in recv_into\n",
      "    raise SocketError(str(e))\n",
      "OSError: (104, 'ECONNRESET')\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/requests/adapters.py\", line 449, in send\n",
      "    timeout=timeout\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 638, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/urllib3/util/retry.py\", line 367, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/urllib3/packages/six.py\", line 685, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 600, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 384, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 2, in raise_from\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 380, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/http/client.py\", line 1321, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/http/client.py\", line 296, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/http/client.py\", line 257, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/socket.py\", line 589, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/urllib3/contrib/pyopenssl.py\", line 299, in recv_into\n",
      "    raise SocketError(str(e))\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', OSError(\"(104, 'ECONNRESET')\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/bravado/http_future.py\", line 124, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/bravado/http_future.py\", line 291, in _get_incoming_response\n",
      "    inner_response = self.future.result(timeout=timeout)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/bravado/requests_client.py\", line 270, in result\n",
      "    **settings\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/requests/sessions.py\", line 646, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/requests/adapters.py\", line 498, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', OSError(\"(104, 'ECONNRESET')\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/neptune/internal/threads/ping_thread.py\", line 37, in run\n",
      "    self.__backend.ping_experiment(self.__experiment)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/neptune/internal/api_clients/hosted_api_clients/hosted_alpha_leaderboard_api_client.py\", line 393, in ping_experiment\n",
      "    self.leaderboard_swagger_client.api.ping(experimentId=str(experiment.internal_id)).response().result\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/bravado/http_future.py\", line 239, in response\n",
      "    six.reraise(*sys.exc_info())\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/six.py\", line 703, in reraise\n",
      "    raise value\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/bravado/http_future.py\", line 197, in response\n",
      "    incoming_response = self._get_incoming_response(timeout)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/bravado/http_future.py\", line 126, in wrapper\n",
      "    self.future._raise_connection_error(exception)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/bravado/http_future.py\", line 91, in _raise_connection_error\n",
      "    self._raise_error(BravadoConnectionError, 'ConnectionError', exception)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/bravado/http_future.py\", line 82, in _raise_error\n",
      "    sys.exc_info()[2],\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/six.py\", line 702, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/bravado/http_future.py\", line 124, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/bravado/http_future.py\", line 291, in _get_incoming_response\n",
      "    inner_response = self.future.result(timeout=timeout)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/bravado/requests_client.py\", line 270, in result\n",
      "    **settings\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/requests/sessions.py\", line 646, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/requests/adapters.py\", line 498, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "bravado.http_future.RequestsFutureAdapterConnectionError\n",
      "Unexpected error in ping thread.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 600, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 384, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 2, in raise_from\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 380, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/http/client.py\", line 1321, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/http/client.py\", line 296, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/http/client.py\", line 257, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/socket.py\", line 589, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/urllib3/contrib/pyopenssl.py\", line 299, in recv_into\n",
      "    raise SocketError(str(e))\n",
      "OSError: (104, 'ECONNRESET')\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/requests/adapters.py\", line 449, in send\n",
      "    timeout=timeout\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 638, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/urllib3/util/retry.py\", line 367, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/urllib3/packages/six.py\", line 685, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 600, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 384, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 2, in raise_from\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 380, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/http/client.py\", line 1321, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/http/client.py\", line 296, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/http/client.py\", line 257, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/socket.py\", line 589, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/urllib3/contrib/pyopenssl.py\", line 299, in recv_into\n",
      "    raise SocketError(str(e))\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', OSError(\"(104, 'ECONNRESET')\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/bravado/http_future.py\", line 124, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/bravado/http_future.py\", line 291, in _get_incoming_response\n",
      "    inner_response = self.future.result(timeout=timeout)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/bravado/requests_client.py\", line 270, in result\n",
      "    **settings\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/requests/sessions.py\", line 646, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/requests/adapters.py\", line 498, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', OSError(\"(104, 'ECONNRESET')\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/neptune/internal/threads/ping_thread.py\", line 37, in run\n",
      "    self.__backend.ping_experiment(self.__experiment)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/neptune/internal/api_clients/hosted_api_clients/hosted_alpha_leaderboard_api_client.py\", line 393, in ping_experiment\n",
      "    self.leaderboard_swagger_client.api.ping(experimentId=str(experiment.internal_id)).response().result\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/bravado/http_future.py\", line 239, in response\n",
      "    six.reraise(*sys.exc_info())\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/six.py\", line 703, in reraise\n",
      "    raise value\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/bravado/http_future.py\", line 197, in response\n",
      "    incoming_response = self._get_incoming_response(timeout)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/bravado/http_future.py\", line 126, in wrapper\n",
      "    self.future._raise_connection_error(exception)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/bravado/http_future.py\", line 91, in _raise_connection_error\n",
      "    self._raise_error(BravadoConnectionError, 'ConnectionError', exception)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/bravado/http_future.py\", line 82, in _raise_error\n",
      "    sys.exc_info()[2],\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/six.py\", line 702, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/bravado/http_future.py\", line 124, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/bravado/http_future.py\", line 291, in _get_incoming_response\n",
      "    inner_response = self.future.result(timeout=timeout)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/bravado/requests_client.py\", line 270, in result\n",
      "    **settings\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/requests/sessions.py\", line 646, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/requests/adapters.py\", line 498, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "bravado.http_future.RequestsFutureAdapterConnectionError\n",
      "Unexpected error in ping thread.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 600, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 384, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 2, in raise_from\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 380, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/http/client.py\", line 1321, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/http/client.py\", line 296, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/http/client.py\", line 257, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/socket.py\", line 589, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/urllib3/contrib/pyopenssl.py\", line 299, in recv_into\n",
      "    raise SocketError(str(e))\n",
      "OSError: (104, 'ECONNRESET')\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/requests/adapters.py\", line 449, in send\n",
      "    timeout=timeout\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 638, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/urllib3/util/retry.py\", line 367, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/urllib3/packages/six.py\", line 685, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 600, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 384, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 2, in raise_from\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 380, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/http/client.py\", line 1321, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/http/client.py\", line 296, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/http/client.py\", line 257, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/socket.py\", line 589, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/urllib3/contrib/pyopenssl.py\", line 299, in recv_into\n",
      "    raise SocketError(str(e))\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', OSError(\"(104, 'ECONNRESET')\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/bravado/http_future.py\", line 124, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/bravado/http_future.py\", line 291, in _get_incoming_response\n",
      "    inner_response = self.future.result(timeout=timeout)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/bravado/requests_client.py\", line 270, in result\n",
      "    **settings\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/requests/sessions.py\", line 646, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/requests/adapters.py\", line 498, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', OSError(\"(104, 'ECONNRESET')\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/neptune/internal/threads/ping_thread.py\", line 37, in run\n",
      "    self.__backend.ping_experiment(self.__experiment)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/neptune/internal/api_clients/hosted_api_clients/hosted_alpha_leaderboard_api_client.py\", line 393, in ping_experiment\n",
      "    self.leaderboard_swagger_client.api.ping(experimentId=str(experiment.internal_id)).response().result\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/bravado/http_future.py\", line 239, in response\n",
      "    six.reraise(*sys.exc_info())\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/six.py\", line 703, in reraise\n",
      "    raise value\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/bravado/http_future.py\", line 197, in response\n",
      "    incoming_response = self._get_incoming_response(timeout)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/bravado/http_future.py\", line 126, in wrapper\n",
      "    self.future._raise_connection_error(exception)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/bravado/http_future.py\", line 91, in _raise_connection_error\n",
      "    self._raise_error(BravadoConnectionError, 'ConnectionError', exception)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/bravado/http_future.py\", line 82, in _raise_error\n",
      "    sys.exc_info()[2],\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/six.py\", line 702, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/bravado/http_future.py\", line 124, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/bravado/http_future.py\", line 291, in _get_incoming_response\n",
      "    inner_response = self.future.result(timeout=timeout)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/bravado/requests_client.py\", line 270, in result\n",
      "    **settings\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/requests/sessions.py\", line 646, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/requests/adapters.py\", line 498, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "bravado.http_future.RequestsFutureAdapterConnectionError\n",
      "Unexpected error in ping thread.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 600, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 384, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 2, in raise_from\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 380, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/http/client.py\", line 1321, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/http/client.py\", line 296, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/http/client.py\", line 257, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/socket.py\", line 589, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/urllib3/contrib/pyopenssl.py\", line 299, in recv_into\n",
      "    raise SocketError(str(e))\n",
      "OSError: (104, 'ECONNRESET')\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/requests/adapters.py\", line 449, in send\n",
      "    timeout=timeout\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 638, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/urllib3/util/retry.py\", line 367, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/urllib3/packages/six.py\", line 685, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 600, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 384, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 2, in raise_from\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 380, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/http/client.py\", line 1321, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/http/client.py\", line 296, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/http/client.py\", line 257, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/socket.py\", line 589, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/urllib3/contrib/pyopenssl.py\", line 299, in recv_into\n",
      "    raise SocketError(str(e))\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', OSError(\"(104, 'ECONNRESET')\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/bravado/http_future.py\", line 124, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/bravado/http_future.py\", line 291, in _get_incoming_response\n",
      "    inner_response = self.future.result(timeout=timeout)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/bravado/requests_client.py\", line 270, in result\n",
      "    **settings\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/requests/sessions.py\", line 646, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/requests/adapters.py\", line 498, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', OSError(\"(104, 'ECONNRESET')\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/neptune/internal/threads/ping_thread.py\", line 37, in run\n",
      "    self.__backend.ping_experiment(self.__experiment)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/neptune/internal/api_clients/hosted_api_clients/hosted_alpha_leaderboard_api_client.py\", line 393, in ping_experiment\n",
      "    self.leaderboard_swagger_client.api.ping(experimentId=str(experiment.internal_id)).response().result\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/bravado/http_future.py\", line 239, in response\n",
      "    six.reraise(*sys.exc_info())\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/six.py\", line 703, in reraise\n",
      "    raise value\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/bravado/http_future.py\", line 197, in response\n",
      "    incoming_response = self._get_incoming_response(timeout)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/bravado/http_future.py\", line 126, in wrapper\n",
      "    self.future._raise_connection_error(exception)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/bravado/http_future.py\", line 91, in _raise_connection_error\n",
      "    self._raise_error(BravadoConnectionError, 'ConnectionError', exception)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/bravado/http_future.py\", line 82, in _raise_error\n",
      "    sys.exc_info()[2],\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/six.py\", line 702, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/bravado/http_future.py\", line 124, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/bravado/http_future.py\", line 291, in _get_incoming_response\n",
      "    inner_response = self.future.result(timeout=timeout)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/bravado/requests_client.py\", line 270, in result\n",
      "    **settings\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/requests/sessions.py\", line 646, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/chantana/anaconda3/lib/python3.7/site-packages/requests/adapters.py\", line 498, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "bravado.http_future.RequestsFutureAdapterConnectionError\n"
     ]
    }
   ],
   "source": [
    "#SqueezeSEAuto random\n",
    "hp = HyperParameters()\n",
    "\n",
    "import neptune\n",
    "\n",
    "ratio = 0.1\n",
    "PROJECT = \"squeezeSEAutoRandom\"+str(ratio)\n",
    "neptune.create_experiment(PROJECT)\n",
    "\n",
    " \n",
    "# This will override the `learning_rate` parameter with your\n",
    "# own selection of choices\n",
    "\n",
    "hp.Choice(\"learning_rate\", values=[ 1e-3, 1e-4])\n",
    "\n",
    "\n",
    "\n",
    "#fn_name = globals()[\"build_SqueezeNet_11_fixed\"](hp)\n",
    "# SqueezeNet \n",
    "\n",
    "mymodel = SqueezeNetSEAutoModel  (classes=nb_classes)\n",
    "\n",
    " \n",
    "tuner = RandomSearch(\n",
    "    #build_SqueezeNet_11_fixed,\n",
    "    #build_squeezenet_auto_model,\n",
    "    #build_model,\n",
    "    \n",
    "    hypermodel=mymodel,\n",
    "    hyperparameters = hp,\n",
    "    objective=Objective(\"val_accuracy\", direction=\"max\"),\n",
    "    max_trials=100,\n",
    "    executions_per_trial=1,\n",
    "    overwrite=True,\n",
    "    directory=\"mytest_dir\",\n",
    "    project_name=PROJECT,\n",
    "    #distribution_strategy=tf.distribute.MirroredStrategy(),\n",
    "    logger = npt_utils.NeptuneLogger(),\n",
    "     \n",
    ")\n",
    "tuner.search_space_summary()\n",
    "\n",
    "ratio = 0.1\n",
    "EPOCH = 200\n",
    "batch_size = 16\n",
    "\"\"\"\"lr_finder = LRFinder(min_lr=1e-5, \n",
    "                    max_lr=1e-3,\n",
    "                    steps_per_epoch=np.ceil(EPOCH/batch_size),\n",
    "                    epochs=3)\"\"\"\n",
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping('val_accuracy', patience=10),\n",
    "    #lr_finder,\n",
    "    #tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5'),\n",
    "    #tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "]\n",
    "\n",
    "tuner.search(x_train[:int(ratio*len(x_train))], y_train[:int(ratio*len(y_train))], epochs=EPOCH, callbacks = my_callbacks,validation_data=(x_test[:int(ratio*len(x_test))], y_test[:int(ratio*len(y_test))]))\n",
    "\n",
    "models = tuner.get_best_models() #(num_models=10)\n",
    "tuner.results_summary()\n",
    "npt_utils.log_tuner_info(tuner)\n",
    "\n",
    "\n",
    "#best_model = tuner.get_best_models(num_models=1)[0]\n",
    "#best_model.evaluate(x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SqueezeSEAuto random\n",
    "hp = HyperParameters()\n",
    "\n",
    "import neptune\n",
    "\n",
    "ratio = 0.1\n",
    "PROJECT = \"squeezeSEAutoBayesian\"+str(ratio)\n",
    "neptune.create_experiment(PROJECT)\n",
    "\n",
    " \n",
    "# This will override the `learning_rate` parameter with your\n",
    "# own selection of choices\n",
    "\n",
    "hp.Choice(\"learning_rate\", values=[ 1e-3, 1e-4])\n",
    "\n",
    "\n",
    "\n",
    "#fn_name = globals()[\"build_SqueezeNet_11_fixed\"](hp)\n",
    "# SqueezeNet \n",
    "\n",
    "mymodel = SqueezeNetSEAutoModel  (classes=nb_classes)\n",
    "\n",
    " \n",
    "tuner = BayesianOptimization(\n",
    "    #build_SqueezeNet_11_fixed,\n",
    "    #build_squeezenet_auto_model,\n",
    "    #build_model,\n",
    "    \n",
    "    hypermodel=mymodel,\n",
    "    hyperparameters = hp,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=100,\n",
    "    executions_per_trial=1,\n",
    "    overwrite=True,\n",
    "    directory=\"mytest_dir\",\n",
    "    project_name= PROJECT,\n",
    "    #distribution_strategy=tf.distribute.MirroredStrategy(),\n",
    "    num_initial_points=2,\n",
    "    alpha=0.0001,\n",
    "    beta=2.6,\n",
    "    seed=None,\n",
    "    tune_new_entries=True,\n",
    "    allow_new_entries=True,\n",
    "    logger = npt_utils.NeptuneLogger(),\n",
    "     \n",
    ")\n",
    "tuner.search_space_summary()\n",
    "\n",
    "\n",
    "EPOCH = 200\n",
    "batch_size = 16\n",
    "\"\"\"\"lr_finder = LRFinder(min_lr=1e-5, \n",
    "                    max_lr=1e-3,\n",
    "                    steps_per_epoch=np.ceil(EPOCH/batch_size),\n",
    "                    epochs=3)\"\"\"\n",
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping('val_accuracy', patience=10),\n",
    "    #lr_finder,\n",
    "    #tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5'),\n",
    "    #tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "]\n",
    "\n",
    "tuner.search(x_train[:int(ratio*len(x_train))], y_train[:int(ratio*len(y_train))], epochs=EPOCH, callbacks = my_callbacks,validation_data=(x_test[:int(ratio*len(x_test))], y_test[:int(ratio*len(y_test))]))\n",
    "\n",
    "models = tuner.get_best_models() #(num_models=10)\n",
    "tuner.results_summary()\n",
    "npt_utils.log_tuner_info(tuner)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/cchantra/keras-tuner/e/KER-59\n",
      "[False, False]\n",
      "['max', 'max']\n",
      "[False, False]\n",
      "Search space summary\n",
      "Default search space size: 24\n",
      "learning_rate (Choice)\n",
      "{'default': 0.001, 'conditions': [], 'values': [0.001, 0.0001], 'ordered': True}\n",
      "compression (Fixed)\n",
      "{'conditions': [], 'value': 1.0}\n",
      "fire_module (Int)\n",
      "{'default': 2, 'conditions': [], 'min_value': 1, 'max_value': 2, 'step': 1, 'sampling': None}\n",
      "use_bypass0 (Boolean)\n",
      "{'default': False, 'conditions': []}\n",
      "use_bypass1 (Boolean)\n",
      "{'default': False, 'conditions': []}\n",
      "pooling0 (Choice)\n",
      "{'default': 'max', 'conditions': [], 'values': ['max', 'avg'], 'ordered': False}\n",
      "pooling1 (Choice)\n",
      "{'default': 'max', 'conditions': [], 'values': ['max', 'avg'], 'ordered': False}\n",
      "squeeze_ratio2 (Choice)\n",
      "{'default': 32, 'conditions': [], 'values': [8, 16, 32], 'ordered': True}\n",
      "SE_add2 (Boolean)\n",
      "{'default': False, 'conditions': []}\n",
      "SE_add3 (Boolean)\n",
      "{'default': False, 'conditions': []}\n",
      "squeeze_ratio4 (Choice)\n",
      "{'default': 32, 'conditions': [], 'values': [8, 16, 32], 'ordered': True}\n",
      "SE_add4 (Boolean)\n",
      "{'default': False, 'conditions': []}\n",
      "SE_add5 (Boolean)\n",
      "{'default': False, 'conditions': []}\n",
      "num_fire_2 (Int)\n",
      "{'default': 2, 'conditions': [], 'min_value': 0, 'max_value': 2, 'step': 1, 'sampling': None}\n",
      "use_bypass_20 (Boolean)\n",
      "{'default': False, 'conditions': []}\n",
      "use_bypass_21 (Boolean)\n",
      "{'default': False, 'conditions': []}\n",
      "squeeze_ratio6 (Choice)\n",
      "{'default': 32, 'conditions': [], 'values': [8, 16, 32], 'ordered': True}\n",
      "SE_add6 (Boolean)\n",
      "{'default': False, 'conditions': []}\n",
      "SE_add7 (Boolean)\n",
      "{'default': False, 'conditions': []}\n",
      "squeeze_ratio8 (Choice)\n",
      "{'default': 32, 'conditions': [], 'values': [8, 16, 32], 'ordered': True}\n",
      "SE_add8 (Boolean)\n",
      "{'default': False, 'conditions': []}\n",
      "SE_add9 (Boolean)\n",
      "{'default': False, 'conditions': []}\n",
      "dropout_rate (Float)\n",
      "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 0.8, 'step': None, 'sampling': None}\n",
      "optimizer (Choice)\n",
      "{'default': 'RMSprop', 'conditions': [], 'values': ['RMSprop', 'sgd'], 'ordered': False}\n",
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "learning_rate     |0.001             |?                 \n",
      "compression       |1                 |?                 \n",
      "fire_module       |2                 |?                 \n",
      "use_bypass0       |False             |?                 \n",
      "use_bypass1       |True              |?                 \n",
      "pooling0          |max               |?                 \n",
      "pooling1          |avg               |?                 \n",
      "squeeze_ratio2    |8                 |?                 \n",
      "SE_add2           |False             |?                 \n",
      "SE_add3           |True              |?                 \n",
      "squeeze_ratio4    |16                |?                 \n",
      "SE_add4           |False             |?                 \n",
      "SE_add5           |True              |?                 \n",
      "num_fire_2        |2                 |?                 \n",
      "use_bypass_20     |True              |?                 \n",
      "use_bypass_21     |False             |?                 \n",
      "squeeze_ratio6    |8                 |?                 \n",
      "SE_add6           |True              |?                 \n",
      "SE_add7           |False             |?                 \n",
      "squeeze_ratio8    |8                 |?                 \n",
      "SE_add8           |True              |?                 \n",
      "SE_add9           |False             |?                 \n",
      "dropout_rate      |0.037644          |?                 \n",
      "optimizer         |sgd               |?                 \n",
      "tuner/epochs      |3                 |?                 \n",
      "tuner/initial_e...|0                 |?                 \n",
      "tuner/bracket     |4                 |?                 \n",
      "tuner/round       |0                 |?                 \n",
      "\n",
      "[False, True]\n",
      "['max', 'avg']\n",
      "[True, False]\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": " Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node model/conv1/Relu (defined at /home/chantana/anaconda3/lib/python3.7/site-packages/keras_tuner/engine/tuner.py:147) ]] [Op:__inference_train_function_10245]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-5a6305f639ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m ]\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratio\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratio\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_callbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratio\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratio\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#(num_models=10)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras_tuner/engine/base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_search_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras_tuner/tuners/hyperband.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0mfit_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"epochs\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tuner/epochs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m             \u001b[0mfit_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"initial_epoch\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tuner/initial_epoch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHyperband\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_build_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras_tuner/engine/multi_execution_tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mcopied_fit_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopied_fit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_values\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirection\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"min\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[0;34m(self, trial, fit_args, fit_kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \"\"\"\n\u001b[1;32m    146\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1093\u001b[0m                 _r=1):\n\u001b[1;32m   1094\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1095\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1096\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node model/conv1/Relu (defined at /home/chantana/anaconda3/lib/python3.7/site-packages/keras_tuner/engine/tuner.py:147) ]] [Op:__inference_train_function_10245]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "#SqueezeAuto Hyper\n",
    "hp = HyperParameters()\n",
    "\n",
    "\n",
    "# This will override the `learning_rate` parameter with your\n",
    "# own selection of choices\n",
    "hp.Choice(\"learning_rate\", values=[ 1e-3, 1e-4])\n",
    "\n",
    "\n",
    "import neptune\n",
    "ratio = 0.1\n",
    "PROJECT = \"squeezeSEAutoHyper\"+str(ratio)\n",
    "neptune.create_experiment(PROJECT)\n",
    "\n",
    " \n",
    "#fn_name = globals()[\"build_SqueezeNet_11_fixed\"](hp)\n",
    "# SqueezeNet \n",
    "\n",
    "mymodel = SqueezeNetSEAutoModel(classes=nb_classes)\n",
    "\n",
    " \n",
    "EPOCH = 200\n",
    "batch_size = 16\n",
    "tuner = Hyperband(\n",
    "    #build_SqueezeNet_11_fixed,\n",
    "    #build_squeezenet_auto_model,\n",
    "    #build_model,\n",
    "    \n",
    "    hypermodel=mymodel,\n",
    "    hyperparameters = hp,\n",
    "    objective=\"val_accuracy\",\n",
    "    #max_trials=20,\n",
    "    executions_per_trial=1,\n",
    "    overwrite=True,\n",
    "    directory=\"mytest_dir\",\n",
    "    project_name=PROJECT,\n",
    "    #distribution_strategy=tf.distribute.MirroredStrategy(),\n",
    "    max_epochs=EPOCH,\n",
    "    logger = npt_utils.NeptuneLogger(),\n",
    "     \n",
    ")\n",
    "tuner.search_space_summary()\n",
    "\n",
    "\n",
    "\"\"\"\"lr_finder = LRFinder(min_lr=1e-5, \n",
    "                    max_lr=1e-3,\n",
    "                    steps_per_epoch=np.ceil(EPOCH/batch_size),\n",
    "                    epochs=3)\"\"\"\n",
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping('val_accuracy', patience=10),\n",
    "    #lr_finder,\n",
    "    #tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5'),\n",
    "    #tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "]\n",
    "\n",
    "tuner.search(x_train[:int(ratio*len(x_train))], y_train[:int(ratio*len(y_train))], epochs=EPOCH, callbacks = my_callbacks,validation_data=(x_test[:int(ratio*len(x_test))], y_test[:int(ratio*len(y_test))]))\n",
    "\n",
    "models = tuner.get_best_models() #(num_models=10)\n",
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20 Complete [00h 03m 25s]\n",
      "val_accuracy: 0.5385000109672546\n",
      "\n",
      "Best val_accuracy So Far: 0.5565000176429749\n",
      "Total elapsed time: 01h 07m 08s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "[True]\n",
      "['avg']\n",
      "[False, False]\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.rho\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Results summary\n",
      "Results in mytest_dir/squeezeAutoBayesian\n",
      "Showing 10 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "compression: 1.0\n",
      "fire_module: 1\n",
      "use_bypass0: True\n",
      "use_bypass1: True\n",
      "pooling0: avg\n",
      "pooling1: avg\n",
      "num_fire_2: 2\n",
      "use_bypass_20: False\n",
      "use_bypass_21: False\n",
      "dropout_rate: 0.0\n",
      "optimizer: sgd\n",
      "Score: 0.5565000176429749\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "compression: 1.0\n",
      "fire_module: 1\n",
      "use_bypass0: True\n",
      "use_bypass1: True\n",
      "pooling0: avg\n",
      "pooling1: avg\n",
      "num_fire_2: 2\n",
      "use_bypass_20: False\n",
      "use_bypass_21: False\n",
      "dropout_rate: 0.0\n",
      "optimizer: sgd\n",
      "Score: 0.5550000071525574\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "compression: 1.0\n",
      "fire_module: 1\n",
      "use_bypass0: True\n",
      "use_bypass1: True\n",
      "pooling0: avg\n",
      "pooling1: avg\n",
      "num_fire_2: 2\n",
      "use_bypass_20: False\n",
      "use_bypass_21: False\n",
      "dropout_rate: 0.0\n",
      "optimizer: sgd\n",
      "Score: 0.5540000200271606\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "compression: 1.0\n",
      "fire_module: 1\n",
      "use_bypass0: True\n",
      "use_bypass1: True\n",
      "pooling0: avg\n",
      "pooling1: avg\n",
      "num_fire_2: 2\n",
      "use_bypass_20: False\n",
      "use_bypass_21: False\n",
      "dropout_rate: 0.0\n",
      "optimizer: sgd\n",
      "Score: 0.5509999990463257\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.001\n",
      "compression: 1.0\n",
      "fire_module: 1\n",
      "use_bypass0: True\n",
      "use_bypass1: True\n",
      "pooling0: max\n",
      "pooling1: avg\n",
      "num_fire_2: 2\n",
      "use_bypass_20: False\n",
      "use_bypass_21: False\n",
      "dropout_rate: 0.0\n",
      "optimizer: sgd\n",
      "Score: 0.546999990940094\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.001\n",
      "compression: 1.0\n",
      "fire_module: 1\n",
      "use_bypass0: True\n",
      "use_bypass1: True\n",
      "pooling0: max\n",
      "pooling1: max\n",
      "num_fire_2: 2\n",
      "use_bypass_20: False\n",
      "use_bypass_21: False\n",
      "dropout_rate: 0.0\n",
      "optimizer: sgd\n",
      "Score: 0.5460000038146973\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "compression: 1.0\n",
      "fire_module: 1\n",
      "use_bypass0: True\n",
      "use_bypass1: True\n",
      "pooling0: avg\n",
      "pooling1: avg\n",
      "num_fire_2: 2\n",
      "use_bypass_20: False\n",
      "use_bypass_21: False\n",
      "dropout_rate: 0.0\n",
      "optimizer: sgd\n",
      "Score: 0.5460000038146973\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "compression: 1.0\n",
      "fire_module: 1\n",
      "use_bypass0: True\n",
      "use_bypass1: True\n",
      "pooling0: avg\n",
      "pooling1: avg\n",
      "num_fire_2: 2\n",
      "use_bypass_20: False\n",
      "use_bypass_21: False\n",
      "dropout_rate: 0.0\n",
      "optimizer: sgd\n",
      "Score: 0.5460000038146973\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "compression: 1.0\n",
      "fire_module: 1\n",
      "use_bypass0: True\n",
      "use_bypass1: True\n",
      "pooling0: max\n",
      "pooling1: avg\n",
      "num_fire_2: 2\n",
      "use_bypass_20: False\n",
      "use_bypass_21: False\n",
      "dropout_rate: 0.0\n",
      "optimizer: sgd\n",
      "Score: 0.5450000166893005\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.001\n",
      "compression: 1.0\n",
      "fire_module: 1\n",
      "use_bypass0: False\n",
      "use_bypass1: True\n",
      "pooling0: max\n",
      "pooling1: avg\n",
      "num_fire_2: 2\n",
      "use_bypass_20: False\n",
      "use_bypass_21: False\n",
      "dropout_rate: 0.0\n",
      "optimizer: sgd\n",
      "Score: 0.5450000166893005\n"
     ]
    }
   ],
   "source": [
    "#SqueezeAuto Bayes\n",
    "hp = HyperParameters()\n",
    "\n",
    "\n",
    "# This will override the `learning_rate` parameter with your\n",
    "# own selection of choices\n",
    "hp.Choice(\"learning_rate\", values=[ 1e-3, 1e-4])\n",
    "\n",
    "\n",
    "import neptune\n",
    "\n",
    "\n",
    "neptune.create_experiment(\"squeezeAutoBaysian\")\n",
    "#fn_name = globals()[\"build_SqueezeNet_11_fixed\"](hp)\n",
    "# SqueezeNet \n",
    "\n",
    "mymodel = SqueezeNetAutoModel(classes=nb_classes)\n",
    "\n",
    " \n",
    "    \n",
    "ratio = 0.2\n",
    "EPOCH = 200\n",
    "batch_size = 16\n",
    "tuner = BayesianOptimization(\n",
    "    #build_SqueezeNet_11_fixed,\n",
    "    #build_squeezenet_auto_model,\n",
    "    #build_model,\n",
    "    \n",
    "    hypermodel=mymodel,\n",
    "    hyperparameters = hp,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=100,\n",
    "    executions_per_trial=1,\n",
    "    overwrite=True,\n",
    "    directory=\"mytest_dir\",\n",
    "    project_name=\"squeezeAutoBayesian\",\n",
    "    #distribution_strategy=tf.distribute.MirroredStrategy(),\n",
    "    num_initial_points=2,\n",
    "    alpha=0.0001,\n",
    "    beta=2.6,\n",
    "    seed=None,\n",
    "    tune_new_entries=True,\n",
    "    allow_new_entries=True,\n",
    "    logger = npt_utils.NeptuneLogger(),\n",
    "     \n",
    ")\n",
    "tuner.search_space_summary()\n",
    "\n",
    "\n",
    "\"\"\"\"lr_finder = LRFinder(min_lr=1e-5, \n",
    "                    max_lr=1e-3,\n",
    "                    steps_per_epoch=np.ceil(EPOCH/batch_size),\n",
    "                    epochs=3)\"\"\"\n",
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping('val_accuracy', patience=10),\n",
    "    #lr_finder,\n",
    "    #tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5'),\n",
    "    #tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "]\n",
    "\n",
    "tuner.search(x_train[:int(ratio*len(x_train))], y_train[:int(ratio*len(y_train))], epochs=EPOCH, callbacks = my_callbacks,validation_data=(x_test[:int(ratio*len(x_test))], y_test[:int(ratio*len(y_test))]))\n",
    "\n",
    "models = tuner.get_best_models() #(num_models=10)\n",
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 17 Complete [00h 07m 19s]\n",
      "val_accuracy: 0.5065000057220459\n",
      "\n",
      "Best val_accuracy So Far: 0.5379999876022339\n",
      "Total elapsed time: 01h 22m 10s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.rho\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Results summary\n",
      "Results in mytest_dir/squeeze11Random\n",
      "Showing 10 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "use_bypass: False\n",
      "compression: 1.0\n",
      "dropout_rate: 0.1\n",
      "optimizer: sgd\n",
      "Score: 0.5379999876022339\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "use_bypass: True\n",
      "compression: 1.0\n",
      "dropout_rate: 0.1\n",
      "optimizer: sgd\n",
      "Score: 0.5335000157356262\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "use_bypass: False\n",
      "compression: 1.0\n",
      "dropout_rate: 0.5\n",
      "optimizer: sgd\n",
      "Score: 0.5304999947547913\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.001\n",
      "use_bypass: True\n",
      "compression: 1.0\n",
      "dropout_rate: 0.5\n",
      "optimizer: sgd\n",
      "Score: 0.5295000076293945\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.001\n",
      "use_bypass: False\n",
      "compression: 1.0\n",
      "dropout_rate: 0.1\n",
      "optimizer: sgd\n",
      "Score: 0.5254999995231628\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.001\n",
      "use_bypass: True\n",
      "compression: 1.0\n",
      "dropout_rate: 0.1\n",
      "optimizer: sgd\n",
      "Score: 0.5205000042915344\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.001\n",
      "use_bypass: False\n",
      "compression: 1.0\n",
      "dropout_rate: 0.1\n",
      "optimizer: RMSprop\n",
      "Score: 0.5149999856948853\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.001\n",
      "use_bypass: False\n",
      "compression: 1.0\n",
      "dropout_rate: 0.8\n",
      "optimizer: sgd\n",
      "Score: 0.5065000057220459\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "use_bypass: False\n",
      "compression: 1.0\n",
      "dropout_rate: 0.1\n",
      "optimizer: RMSprop\n",
      "Score: 0.5049999952316284\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "use_bypass: False\n",
      "compression: 1.0\n",
      "dropout_rate: 0.8\n",
      "optimizer: sgd\n",
      "Score: 0.4984999895095825\n"
     ]
    },
    {
     "ename": "NeptuneException",
     "evalue": "\n\u001b[95m\n----ClientHttpError-----------------------------------------------------------------------\n\u001b[0m\nNeptune server returned status \u001b[91m400\u001b[0m.\n\nServer response was:\n\u001b[91m{\"title\":\"Length of stream does not match given range\",\"code\":400,\"errorType\":\"BAD_REQUEST\"}\u001b[0m\n\nVerify the correctness of your call or contact Neptune support.\n\n\u001b[92mNeed help?\u001b[0m-> https://docs.neptune.ai/getting-started/getting-help\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/neptune/new/internal/backends/utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/neptune/new/internal/backends/hosted_file_operations.py\u001b[0m in \u001b[0;36mupload_raw_data\u001b[0;34m(http_client, url, data, path_params, query_params, headers)\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNeptuneStorageLimitException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m     \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    939\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: 400 Client Error:  for url: https://app.neptune.ai/api/leaderboard/v1/attributes/upload?experimentId=0ed151da-ce96-4ee7-9129-b59baa8e4a3b&attribute=artifacts%2Fsqueeze11Random%2Ftrial_a7203d5012cf9f216452d8f06c2f85b4%2Ftrial.json&ext=",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mClientHttpError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/neptune/internal/api_clients/hosted_api_clients/hosted_alpha_leaderboard_api_client.py\u001b[0m in \u001b[0;36m_execute_upload_operation\u001b[0;34m(self, experiment, upload_operation)\u001b[0m\n\u001b[1;32m    576\u001b[0m                     \u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupload_operation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m                     ext=upload_operation.ext)\n\u001b[0m\u001b[1;32m    578\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupload_operation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha_operation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUploadFileContent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/neptune/new/internal/backends/hosted_file_operations.py\u001b[0m in \u001b[0;36mupload_file_attribute\u001b[0;34m(swagger_client, run_uuid, attribute, source, ext)\u001b[0m\n\u001b[1;32m     63\u001b[0m                          \u001b[0;34m\"attribute\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mattribute\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                          \u001b[0;34m\"ext\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m                      })\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/neptune/new/internal/backends/hosted_file_operations.py\u001b[0m in \u001b[0;36m_upload_loop\u001b[0;34m(file_chunk_stream, response_handler, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile_chunk_stream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_loop_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_chunk_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0mresponse_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/neptune/new/internal/backends/hosted_file_operations.py\u001b[0m in \u001b[0;36m_upload_loop_chunk\u001b[0;34m(chunk, file_chunk_stream, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mheaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"X-File-Permissions\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_chunk_stream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermissions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mupload_raw_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/neptune/new/internal/backends/utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;36m400\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mstatus_code\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mClientHttpError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mClientHttpError\u001b[0m: \n\u001b[95m\n----ClientHttpError-----------------------------------------------------------------------\n\u001b[0m\nNeptune server returned status \u001b[91m400\u001b[0m.\n\nServer response was:\n\u001b[91m{\"title\":\"Length of stream does not match given range\",\"code\":400,\"errorType\":\"BAD_REQUEST\"}\u001b[0m\n\nVerify the correctness of your call or contact Neptune support.\n\n\u001b[92mNeed help?\u001b[0m-> https://docs.neptune.ai/getting-started/getting-help\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mNeptuneException\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-3d2c49fd9ac1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#(num_models=10)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m \u001b[0mnpt_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_tuner_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuner\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/neptunecontrib/monitoring/kerastuner.py\u001b[0m in \u001b[0;36mlog_tuner_info\u001b[0;34m(tuner, experiment, log_project_dir)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlog_project_dir\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_artifact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproject_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_property\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best_parameters'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_hyperparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/neptune/__init__.py\u001b[0m in \u001b[0;36mlog_artifact\u001b[0;34m(artifact, destination)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0mAlias\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mmeth\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mneptune\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_artifact\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \"\"\"\n\u001b[0;32m--> 385\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mget_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_artifact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martifact\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestination\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/neptune/experiments.py\u001b[0m in \u001b[0;36mlog_artifact\u001b[0;34m(self, artifact, destination)\u001b[0m\n\u001b[1;32m    621\u001b[0m                 \u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_artifact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'images/wrong_prediction_1.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'images/my_image_1.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m         \"\"\"\n\u001b[0;32m--> 623\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_artifact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martifact\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestination\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdelete_artifacts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/neptune/internal/api_clients/hosted_api_clients/hosted_alpha_leaderboard_api_client.py\u001b[0m in \u001b[0;36mlog_artifact\u001b[0;34m(self, experiment, artifact, destination)\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martifact\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_destination\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_dir_artifacts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martifact\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestination\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_artifact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_destination\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/neptune/internal/api_clients/hosted_api_clients/hosted_alpha_leaderboard_api_client.py\u001b[0m in \u001b[0;36mlog_artifact\u001b[0;34m(self, experiment, artifact, destination)\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Artifact must be a local path or an IO object\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_upload_operations_with_400_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/neptune/internal/api_clients/hosted_api_clients/hosted_alpha_leaderboard_api_client.py\u001b[0m in \u001b[0;36m_execute_upload_operations_with_400_retry\u001b[0;34m(self, experiment, upload_operation)\u001b[0m\n\u001b[1;32m    603\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_upload_operation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupload_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mClientHttpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"Length of stream does not match given range\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/neptune/internal/api_clients/hosted_api_clients/hosted_alpha_leaderboard_api_client.py\u001b[0m in \u001b[0;36m_execute_upload_operation\u001b[0;34m(self, experiment, upload_operation)\u001b[0m\n\u001b[1;32m    593\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mNeptuneException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Upload operation in neither File or FileSet\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0malpha_exceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNeptuneException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mNeptuneException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNeptuneException\u001b[0m: \n\u001b[95m\n----ClientHttpError-----------------------------------------------------------------------\n\u001b[0m\nNeptune server returned status \u001b[91m400\u001b[0m.\n\nServer response was:\n\u001b[91m{\"title\":\"Length of stream does not match given range\",\"code\":400,\"errorType\":\"BAD_REQUEST\"}\u001b[0m\n\nVerify the correctness of your call or contact Neptune support.\n\n\u001b[92mNeed help?\u001b[0m-> https://docs.neptune.ai/getting-started/getting-help\n"
     ]
    }
   ],
   "source": [
    "#SqueezeNet 11 Random\n",
    "\n",
    "from keras_tuner import HyperParameters\n",
    "hp = HyperParameters()\n",
    "\n",
    "import neptune\n",
    "\n",
    "\n",
    "neptune.create_experiment(\"squeeze11Random\")\n",
    "\n",
    "# This will override the `learning_rate` parameter with your\n",
    "# own selection of choices\n",
    "hp.Choice(\"learning_rate\", values=[ 1e-3, 1e-4])\n",
    "\n",
    "\n",
    "\n",
    "#fn_name = globals()[\"build_SqueezeNet_11_fixed\"](hp)\n",
    "# SqueezeNet \n",
    "\n",
    "mymodel = SqueezeNet11Model(classes=nb_classes)\n",
    "\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    #build_SqueezeNet_11_fixed,\n",
    "    #build_squeezenet_auto_model,\n",
    "    #build_model,\n",
    "    \n",
    "    hypermodel=mymodel,\n",
    "    hyperparameters = hp,\n",
    "    objective=Objective(\"val_accuracy\", direction=\"max\"),\n",
    "    max_trials=100,\n",
    "    executions_per_trial=1,\n",
    "    overwrite=True,\n",
    "    directory=\"mytest_dir\",\n",
    "    project_name=\"squeeze11Random\",\n",
    "    #distribution_strategy=tf.distribute.MirroredStrategy(),\n",
    "    logger = npt_utils.NeptuneLogger(),\n",
    "     \n",
    ")\n",
    "tuner.search_space_summary()\n",
    "\n",
    "ratio = 0.2\n",
    "EPOCH = 200\n",
    "batch_size = 16\n",
    "\"\"\"\"lr_finder = LRFinder(min_lr=1e-5, \n",
    "                    max_lr=1e-3,\n",
    "                    steps_per_epoch=np.ceil(EPOCH/batch_size),\n",
    "                    epochs=3)\"\"\"\n",
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping('val_accuracy', patience=10),\n",
    "    #lr_finder,\n",
    "    #tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5'),\n",
    "    #tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "]\n",
    "\n",
    "tuner.search(x_train[:int(ratio*len(x_train))], y_train[:int(ratio*len(y_train))], epochs=EPOCH, callbacks = my_callbacks,validation_data=(x_test[:int(ratio*len(x_test))], y_test[:int(ratio*len(y_test))]))\n",
    "\n",
    "models = tuner.get_best_models() #(num_models=10)\n",
    "tuner.results_summary()\n",
    "npt_utils.log_tuner_info(tuner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 24 Complete [00h 00m 21s]\n",
      "val_accuracy: 0.18299999833106995\n",
      "\n",
      "Best val_accuracy So Far: 0.265500009059906\n",
      "Total elapsed time: 00h 08m 11s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Results summary\n",
      "Results in mytest_dir/squeeze110.2\n",
      "Showing 10 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.001\n",
      "use_bypass: False\n",
      "compression: 1.0\n",
      "dropout_rate: 0.1\n",
      "optimizer: RMSprop\n",
      "tuner/epochs: 3\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 4\n",
      "tuner/round: 0\n",
      "Score: 0.265500009059906\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "use_bypass: True\n",
      "compression: 1.0\n",
      "dropout_rate: 0.1\n",
      "optimizer: RMSprop\n",
      "tuner/epochs: 3\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 4\n",
      "tuner/round: 0\n",
      "Score: 0.26249998807907104\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "use_bypass: True\n",
      "compression: 1.0\n",
      "dropout_rate: 0.5\n",
      "optimizer: RMSprop\n",
      "tuner/epochs: 3\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 4\n",
      "tuner/round: 0\n",
      "Score: 0.2515000104904175\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "use_bypass: False\n",
      "compression: 1.0\n",
      "dropout_rate: 0.5\n",
      "optimizer: RMSprop\n",
      "tuner/epochs: 3\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 4\n",
      "tuner/round: 0\n",
      "Score: 0.24799999594688416\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "use_bypass: True\n",
      "compression: 1.0\n",
      "dropout_rate: 0.1\n",
      "optimizer: sgd\n",
      "tuner/epochs: 3\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 4\n",
      "tuner/round: 0\n",
      "Score: 0.2460000067949295\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.001\n",
      "use_bypass: True\n",
      "compression: 1.0\n",
      "dropout_rate: 0.1\n",
      "optimizer: RMSprop\n",
      "tuner/epochs: 3\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 4\n",
      "tuner/round: 0\n",
      "Score: 0.24199999868869781\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "use_bypass: True\n",
      "compression: 1.0\n",
      "dropout_rate: 0.5\n",
      "optimizer: sgd\n",
      "tuner/epochs: 3\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 4\n",
      "tuner/round: 0\n",
      "Score: 0.23250000178813934\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.001\n",
      "use_bypass: True\n",
      "compression: 1.0\n",
      "dropout_rate: 0.5\n",
      "optimizer: sgd\n",
      "tuner/epochs: 3\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 4\n",
      "tuner/round: 0\n",
      "Score: 0.22699999809265137\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "use_bypass: False\n",
      "compression: 1.0\n",
      "dropout_rate: 0.1\n",
      "optimizer: sgd\n",
      "tuner/epochs: 3\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 4\n",
      "tuner/round: 0\n",
      "Score: 0.21899999678134918\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "use_bypass: False\n",
      "compression: 1.0\n",
      "dropout_rate: 0.1\n",
      "optimizer: RMSprop\n",
      "tuner/epochs: 3\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 4\n",
      "tuner/round: 0\n",
      "Score: 0.21699999272823334\n"
     ]
    }
   ],
   "source": [
    "#Squeeze11 Hyper\n",
    "hp = HyperParameters()\n",
    "\n",
    "\n",
    "# This will override the `learning_rate` parameter with your\n",
    "# own selection of choices\n",
    "hp.Choice(\"learning_rate\", values=[ 1e-3, 1e-4])\n",
    "\n",
    "\n",
    "import neptune\n",
    "\n",
    "\n",
    "ratio = 0.2\n",
    "PROJECT = \"squeeze11\"+str(ratio)\n",
    "neptune.create_experiment(PROJECT)\n",
    " \n",
    "#fn_name = globals()[\"build_SqueezeNet_11_fixed\"](hp)\n",
    "# SqueezeNet \n",
    "\n",
    "mymodel = SqueezeNet11Model(classes=nb_classes)\n",
    "\n",
    "ratio = 0.2\n",
    "EPOCH = 200\n",
    "batch_size = 16\n",
    "tuner = Hyperband(\n",
    "    #build_SqueezeNet_11_fixed,\n",
    "    #build_squeezenet_auto_model,\n",
    "    #build_model,\n",
    "    \n",
    "    hypermodel=mymodel,\n",
    "    hyperparameters = hp,\n",
    "    objective=\"val_accuracy\",\n",
    "    #max_trials=20,\n",
    "    executions_per_trial=1,\n",
    "    overwrite=True,\n",
    "    directory=\"mytest_dir\",\n",
    "    project_name=PROJECT,\n",
    "    #distribution_strategy=tf.distribute.MirroredStrategy(),\n",
    "    max_epochs=EPOCH,\n",
    "    logger = npt_utils.NeptuneLogger(),\n",
    "     \n",
    ")\n",
    "tuner.search_space_summary()\n",
    "\n",
    "\n",
    "\"\"\"\"lr_finder = LRFinder(min_lr=1e-5, \n",
    "                    max_lr=1e-3,\n",
    "                    steps_per_epoch=np.ceil(EPOCH/batch_size),\n",
    "                    epochs=3)\"\"\"\n",
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping('val_accuracy', patience=10),\n",
    "    #lr_finder,\n",
    "    #tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5'),\n",
    "    #tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "]\n",
    "\n",
    "tuner.search(x_train[:int(ratio*len(x_train))], y_train[:int(ratio*len(y_train))], epochs=EPOCH, callbacks = my_callbacks,validation_data=(x_test[:int(ratio*len(x_test))], y_test[:int(ratio*len(y_test))]))\n",
    "\n",
    "models = tuner.get_best_models() #(num_models=10)\n",
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 200 Complete [00h 04m 14s]\n",
      "val_accuracy: 0.5170000195503235\n",
      "\n",
      "Best val_accuracy So Far: 0.5559999942779541\n",
      "Total elapsed time: 18h 12m 21s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.rho\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Results summary\n",
      "Results in mytest_dir/squeeze11Bayesian\n",
      "Showing 10 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "use_bypass: True\n",
      "compression: 1.0\n",
      "dropout_rate: 0.8\n",
      "optimizer: sgd\n",
      "Score: 0.5559999942779541\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "use_bypass: True\n",
      "compression: 1.0\n",
      "dropout_rate: 0.8\n",
      "optimizer: sgd\n",
      "Score: 0.550000011920929\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.001\n",
      "use_bypass: True\n",
      "compression: 1.0\n",
      "dropout_rate: 0.8\n",
      "optimizer: sgd\n",
      "Score: 0.546999990940094\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "use_bypass: False\n",
      "compression: 1.0\n",
      "dropout_rate: 0.8\n",
      "optimizer: sgd\n",
      "Score: 0.5450000166893005\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "use_bypass: False\n",
      "compression: 1.0\n",
      "dropout_rate: 0.8\n",
      "optimizer: sgd\n",
      "Score: 0.5440000295639038\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.001\n",
      "use_bypass: False\n",
      "compression: 1.0\n",
      "dropout_rate: 0.8\n",
      "optimizer: sgd\n",
      "Score: 0.5435000061988831\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.001\n",
      "use_bypass: True\n",
      "compression: 1.0\n",
      "dropout_rate: 0.8\n",
      "optimizer: sgd\n",
      "Score: 0.5419999957084656\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "use_bypass: True\n",
      "compression: 1.0\n",
      "dropout_rate: 0.8\n",
      "optimizer: sgd\n",
      "Score: 0.5419999957084656\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "use_bypass: True\n",
      "compression: 1.0\n",
      "dropout_rate: 0.8\n",
      "optimizer: sgd\n",
      "Score: 0.5389999747276306\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "use_bypass: False\n",
      "compression: 1.0\n",
      "dropout_rate: 0.8\n",
      "optimizer: sgd\n",
      "Score: 0.5389999747276306\n"
     ]
    }
   ],
   "source": [
    "#SqueezeAuto Bayes\n",
    "hp = HyperParameters()\n",
    "\n",
    "\n",
    "# This will override the `learning_rate` parameter with your\n",
    "# own selection of choices\n",
    "hp.Choice(\"learning_rate\", values=[ 1e-3, 1e-4])\n",
    "\n",
    "\n",
    "import neptune\n",
    "\n",
    "\n",
    "neptune.create_experiment(\"squeeze11Baysian\")\n",
    "#fn_name = globals()[\"build_SqueezeNet_11_fixed\"](hp)\n",
    "# SqueezeNet \n",
    "\n",
    "mymodel = SqueezeNet11Model(classes=nb_classes)\n",
    "\n",
    " \n",
    "    \n",
    "ratio = 0.2\n",
    "EPOCH = 200\n",
    "batch_size = 16\n",
    "tuner = BayesianOptimization(\n",
    "    #build_SqueezeNet_11_fixed,\n",
    "    #build_squeezenet_auto_model,\n",
    "    #build_model,\n",
    "    \n",
    "    hypermodel=mymodel,\n",
    "    hyperparameters = hp,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=200,\n",
    "    executions_per_trial=1,\n",
    "    overwrite=True,\n",
    "    directory=\"mytest_dir\",\n",
    "    project_name=\"squeeze11Bayesian\",\n",
    "    #distribution_strategy=tf.distribute.MirroredStrategy(),\n",
    "    num_initial_points=2,\n",
    "    alpha=0.0001,\n",
    "    beta=2.6,\n",
    "    seed=None,\n",
    "    tune_new_entries=True,\n",
    "    allow_new_entries=True,\n",
    "    logger = npt_utils.NeptuneLogger(),\n",
    "     \n",
    ")\n",
    "tuner.search_space_summary()\n",
    "\n",
    "\n",
    "\"\"\"\"lr_finder = LRFinder(min_lr=1e-5, \n",
    "                    max_lr=1e-3,\n",
    "                    steps_per_epoch=np.ceil(EPOCH/batch_size),\n",
    "                    epochs=3)\"\"\"\n",
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping('val_accuracy', patience=10),\n",
    "    #lr_finder,\n",
    "    #tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5'),\n",
    "    #tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "]\n",
    "\n",
    "tuner.search(x_train[:int(ratio*len(x_train))], y_train[:int(ratio*len(y_train))], epochs=EPOCH, callbacks = my_callbacks,validation_data=(x_test[:int(ratio*len(x_test))], y_test[:int(ratio*len(y_test))]))\n",
    "\n",
    "models = tuner.get_best_models() #(num_models=10)\n",
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    }
   ],
   "source": [
    "if tf.config.list_physical_devices('GPU'):\n",
    "  strategy = tf.distribute.MirroredStrategy()\n",
    "else:  # Use the Default Strategy\n",
    "  strategy = tf.distribute.get_strategy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 17 Complete [00h 01m 11s]\n",
      "val_accuracy: 0.10849999636411667\n",
      "\n",
      "Best val_accuracy So Far: 0.5090000033378601\n",
      "Total elapsed time: 00h 48m 43s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Results summary\n",
      "Results in mytest_dir/squeezeRandom0.2\n",
      "Showing 10 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "use_bypass: False\n",
      "compression: 1.0\n",
      "dropout_rate: 0.5\n",
      "optimizer: sgd\n",
      "Score: 0.5090000033378601\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.001\n",
      "use_bypass: False\n",
      "compression: 1.0\n",
      "dropout_rate: 0.8\n",
      "optimizer: sgd\n",
      "Score: 0.5084999799728394\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.001\n",
      "use_bypass: False\n",
      "compression: 1.0\n",
      "dropout_rate: 0.5\n",
      "optimizer: sgd\n",
      "Score: 0.5080000162124634\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "use_bypass: False\n",
      "compression: 1.0\n",
      "dropout_rate: 0.8\n",
      "optimizer: sgd\n",
      "Score: 0.5009999871253967\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "use_bypass: False\n",
      "compression: 1.0\n",
      "dropout_rate: 0.0\n",
      "optimizer: sgd\n",
      "Score: 0.4945000112056732\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.001\n",
      "use_bypass: False\n",
      "compression: 1.0\n",
      "dropout_rate: 0.0\n",
      "optimizer: sgd\n",
      "Score: 0.4724999964237213\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.001\n",
      "use_bypass: True\n",
      "compression: 1.0\n",
      "dropout_rate: 0.5\n",
      "optimizer: sgd\n",
      "Score: 0.4690000116825104\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.001\n",
      "use_bypass: False\n",
      "compression: 1.0\n",
      "dropout_rate: 0.0\n",
      "optimizer: RMSprop\n",
      "Score: 0.46700000762939453\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.001\n",
      "use_bypass: True\n",
      "compression: 1.0\n",
      "dropout_rate: 0.0\n",
      "optimizer: sgd\n",
      "Score: 0.43950000405311584\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "use_bypass: False\n",
      "compression: 1.0\n",
      "dropout_rate: 0.8\n",
      "optimizer: RMSprop\n",
      "Score: 0.10849999636411667\n"
     ]
    }
   ],
   "source": [
    "#SqueezeNet Random\n",
    " \n",
    "from keras_tuner import HyperParameters\n",
    "hp = HyperParameters()\n",
    "import neptune\n",
    "\n",
    "\n",
    "ratio = 0.2\n",
    "PROJECT = \"squeezeRandom\"+str(ratio)\n",
    "neptune.create_experiment(PROJECT)\n",
    "# This will override the `learning_rate` parameter with your\n",
    "# own selection of choices\n",
    "hp.Choice(\"learning_rate\", values=[ 1e-3, 1e-4])\n",
    "\n",
    "\n",
    "\n",
    "#fn_name = globals()[\"build_SqueezeNet_11_fixed\"](hp)\n",
    "# SqueezeNet \n",
    "\n",
    "mymodel = SqueezeNetModel(classes=nb_classes)\n",
    "\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    #build_SqueezeNet_11_fixed,\n",
    "    #build_squeezenet_auto_model,\n",
    "    #build_model,\n",
    "    \n",
    "    hypermodel=mymodel,\n",
    "    hyperparameters = hp,\n",
    "    objective=Objective(\"val_accuracy\", direction=\"max\"),\n",
    "    max_trials=100,\n",
    "    executions_per_trial=1,\n",
    "    overwrite=True,\n",
    "    directory=\"mytest_dir\",\n",
    "    project_name=PROJECT,\n",
    "     \n",
    "    #distribution_strategy=strategy,\n",
    "    logger = npt_utils.NeptuneLogger(),\n",
    "     \n",
    ")\n",
    "tuner.search_space_summary()\n",
    "\n",
    " \n",
    "EPOCH = 200\n",
    "batch_size = 16\n",
    "\"\"\"\"lr_finder = LRFinder(min_lr=1e-5, \n",
    "                    max_lr=1e-3,\n",
    "                    steps_per_epoch=np.ceil(EPOCH/batch_size),\n",
    "                    epochs=3)\"\"\"\n",
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping('val_accuracy', patience=10),\n",
    "    #lr_finder,\n",
    "    #tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5'),\n",
    "    #tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "]\n",
    "\n",
    "tuner.search(x_train[:int(ratio*len(x_train))], y_train[:int(ratio*len(y_train))], epochs=EPOCH, callbacks = my_callbacks,validation_data=(x_test[:int(ratio*len(x_test))], y_test[:int(ratio*len(y_test))]))\n",
    "\n",
    "models = tuner.get_best_models() #(num_models=10)\n",
    "tuner.results_summary()\n",
    "\n",
    "npt_utils.log_tuner_info(tuner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy at 0x7f6fcff485f8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Squeeze11 Hyper\n",
    "hp = HyperParameters()\n",
    "\n",
    "\n",
    "# This will override the `learning_rate` parameter with your\n",
    "# own selection of choices\n",
    "hp.Choice(\"learning_rate\", values=[ 1e-3, 1e-4])\n",
    "\n",
    "\n",
    "import neptune\n",
    "\n",
    "\n",
    "ratio = 0.2\n",
    "PROJECT = \"squeeze11\"+str(ratio)\n",
    "neptune.create_experiment(PROJECT)\n",
    " \n",
    "#fn_name = globals()[\"build_SqueezeNet_11_fixed\"](hp)\n",
    "# SqueezeNet \n",
    "\n",
    "mymodel = SqueezeNetModel(classes=nb_classes)\n",
    "\n",
    "ratio = 0.2\n",
    "EPOCH = 200\n",
    "batch_size = 16\n",
    "tuner = Hyperband(\n",
    "    #build_SqueezeNet_11_fixed,\n",
    "    #build_squeezenet_auto_model,\n",
    "    #build_model,\n",
    "    \n",
    "    hypermodel=mymodel,\n",
    "    hyperparameters = hp,\n",
    "    objective=\"val_accuracy\",\n",
    "    #max_trials=20,\n",
    "    executions_per_trial=1,\n",
    "    overwrite=True,\n",
    "    directory=\"mytest_dir\",\n",
    "    project_name=PROJECT,\n",
    "    #distribution_strategy=tf.distribute.MirroredStrategy(),\n",
    "    max_epochs=EPOCH,\n",
    "    logger = npt_utils.NeptuneLogger(),\n",
    "     \n",
    ")\n",
    "tuner.search_space_summary()\n",
    "\n",
    "\n",
    "\"\"\"\"lr_finder = LRFinder(min_lr=1e-5, \n",
    "                    max_lr=1e-3,\n",
    "                    steps_per_epoch=np.ceil(EPOCH/batch_size),\n",
    "                    epochs=3)\"\"\"\n",
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping('val_accuracy', patience=10),\n",
    "    #lr_finder,\n",
    "    #tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5'),\n",
    "    #tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "]\n",
    "\n",
    "tuner.search(x_train[:int(ratio*len(x_train))], y_train[:int(ratio*len(y_train))], epochs=EPOCH, callbacks = my_callbacks,validation_data=(x_test[:int(ratio*len(x_test))], y_test[:int(ratio*len(y_test))]))\n",
    "\n",
    "models = tuner.get_best_models() #(num_models=10)\n",
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/cchantra/keras-tuner/e/KER-39\n",
      "https://app.neptune.ai/cchantra/keras-tuner/e/KER-40\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'max_trials'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-9e98ec01bc32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m#distribution_strategy=tf.distribute.MirroredStrategy(),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnpt_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNeptuneLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m )\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras_tuner/tuners/hyperband.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, hypermodel, objective, max_epochs, factor, hyperband_iterations, seed, hyperparameters, tune_new_entries, allow_new_entries, **kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m         )\n\u001b[1;32m    361\u001b[0m         super(Hyperband, self).__init__(\n\u001b[0;32m--> 362\u001b[0;31m             \u001b[0moracle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhypermodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m         )\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras_tuner/engine/multi_execution_tuner.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, oracle, hypermodel, executions_per_trial, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moracle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhypermodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutions_per_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMultiExecutionTuner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhypermodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             raise ValueError(\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'max_trials'"
     ]
    }
   ],
   "source": [
    "#SqueezeNet Hyper\n",
    "hp = HyperParameters()\n",
    "\n",
    "import neptune\n",
    "\n",
    "\n",
    "ratio = 0.2\n",
    "PROJECT = \"squeezeHyper\"+str(ratio)\n",
    "neptune.create_experiment(PROJECT)\n",
    "\n",
    "neptune.create_experiment(PROJECT)\n",
    "\n",
    "# This will override the `learning_rate` parameter with your\n",
    "# own selection of choices\n",
    "hp.Choice(\"learning_rate\", values=[ 1e-3, 1e-4])\n",
    "\n",
    "\n",
    "\n",
    "#fn_name = globals()[\"build_SqueezeNet_11_fixed\"](hp)\n",
    "# SqueezeNet \n",
    "\n",
    "mymodel = SqueezeNetModel(classes=nb_classes)\n",
    "\n",
    "EPOCH = 200\n",
    "batch_size = 16\n",
    "tuner = Hyperband(\n",
    "    #build_SqueezeNet_11_fixed,\n",
    "    #build_squeezenet_auto_model,\n",
    "    #build_model,\n",
    "    \n",
    "    hypermodel=mymodel,\n",
    "    max_trials=100,\n",
    "    hyperparameters = hp,\n",
    "    objective=Objective(\"val_accuracy\", direction=\"max\"),\n",
    "    #max_trials=100,\n",
    "    executions_per_trial=1,\n",
    "    overwrite=True,\n",
    "    directory=\"mytest_dir\",\n",
    "    project_name=PROJECT,\n",
    "    #distribution_strategy=tf.distribute.MirroredStrategy(),\n",
    "    max_epochs=EPOCH,\n",
    "    logger = npt_utils.NeptuneLogger(),\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "tuner.search_space_summary()\n",
    "\n",
    "\n",
    "\"\"\"\"lr_finder = LRFinder(min_lr=1e-5, \n",
    "                    max_lr=1e-3,\n",
    "                    steps_per_epoch=np.ceil(EPOCH/batch_size),\n",
    "                    epochs=3)\"\"\"\n",
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping('val_accuracy', patience=10),\n",
    "    #lr_finder,\n",
    "    #tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5'),\n",
    "    #tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "]\n",
    "\n",
    "tuner.search(x_train[:int(ratio*len(x_train))], y_train[:int(ratio*len(y_train))], epochs=EPOCH, callbacks = my_callbacks,validation_data=(x_test[:int(ratio*len(x_test))], y_test[:int(ratio*len(y_test))]))\n",
    "\n",
    "models = tuner.get_best_models() #(num_models=10)\n",
    "tuner.results_summary()\n",
    "npt_utils.log_tuner_info(tuner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 100 Complete [00h 02m 26s]\n",
      "val_accuracy: 0.47699999809265137\n",
      "\n",
      "Best val_accuracy So Far: 0.5199999809265137\n",
      "Total elapsed time: 05h 48m 29s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Results summary\n",
      "Results in mytest_dir/squeezeBayesian0.2\n",
      "Showing 10 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "use_bypass: False\n",
      "compression: 1.0\n",
      "dropout_rate: 0.0\n",
      "optimizer: sgd\n",
      "Score: 0.5199999809265137\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "use_bypass: False\n",
      "compression: 1.0\n",
      "dropout_rate: 0.0\n",
      "optimizer: sgd\n",
      "Score: 0.515999972820282\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "use_bypass: False\n",
      "compression: 1.0\n",
      "dropout_rate: 0.0\n",
      "optimizer: sgd\n",
      "Score: 0.515500009059906\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "use_bypass: False\n",
      "compression: 1.0\n",
      "dropout_rate: 0.0\n",
      "optimizer: sgd\n",
      "Score: 0.515500009059906\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "use_bypass: False\n",
      "compression: 1.0\n",
      "dropout_rate: 0.0\n",
      "optimizer: sgd\n",
      "Score: 0.5145000219345093\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.001\n",
      "use_bypass: False\n",
      "compression: 1.0\n",
      "dropout_rate: 0.0\n",
      "optimizer: sgd\n",
      "Score: 0.5134999752044678\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.001\n",
      "use_bypass: False\n",
      "compression: 1.0\n",
      "dropout_rate: 0.0\n",
      "optimizer: sgd\n",
      "Score: 0.5134999752044678\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.001\n",
      "use_bypass: False\n",
      "compression: 1.0\n",
      "dropout_rate: 0.0\n",
      "optimizer: sgd\n",
      "Score: 0.5120000243186951\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.001\n",
      "use_bypass: False\n",
      "compression: 1.0\n",
      "dropout_rate: 0.0\n",
      "optimizer: sgd\n",
      "Score: 0.5109999775886536\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "use_bypass: False\n",
      "compression: 1.0\n",
      "dropout_rate: 0.0\n",
      "optimizer: sgd\n",
      "Score: 0.5099999904632568\n"
     ]
    }
   ],
   "source": [
    "#SqueezeAuto Bayes\n",
    "hp = HyperParameters()\n",
    "\n",
    "\n",
    "\n",
    "# This will override the `learning_rate` parameter with your\n",
    "# own selection of choices\n",
    "hp.Choice(\"learning_rate\", values=[ 1e-3, 1e-4])\n",
    "\n",
    "\n",
    "import neptune\n",
    "\n",
    "ratio = 0.2\n",
    "PROJECT = \"squeezeBayesian\"+str(ratio)\n",
    "neptune.create_experiment(PROJECT)\n",
    "\n",
    " \n",
    "#fn_name = globals()[\"build_SqueezeNet_11_fixed\"](hp)\n",
    "# SqueezeNet \n",
    "\n",
    "mymodel = SqueezeNetModel(classes=nb_classes)\n",
    "\n",
    " \n",
    "    \n",
    "EPOCH = 200\n",
    "batch_size = 16\n",
    "tuner = BayesianOptimization(\n",
    "    #build_SqueezeNet_11_fixed,\n",
    "    #build_squeezenet_auto_model,\n",
    "    #build_model,\n",
    "    \n",
    "    hypermodel=mymodel,\n",
    "    hyperparameters = hp,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=100,\n",
    "    executions_per_trial=1,\n",
    "    overwrite=True,\n",
    "    directory=\"mytest_dir\",\n",
    "    project_name=PROJECT,\n",
    "    #distribution_strategy=tf.distribute.MirroredStrategy(),\n",
    "    num_initial_points=2,\n",
    "    alpha=0.0001,\n",
    "    beta=2.6,\n",
    "    seed=None,\n",
    "    tune_new_entries=True,\n",
    "    allow_new_entries=True,\n",
    "    logger = npt_utils.NeptuneLogger(),\n",
    "     \n",
    ")\n",
    "tuner.search_space_summary()\n",
    "\n",
    "\n",
    "\"\"\"\"lr_finder = LRFinder(min_lr=1e-5, \n",
    "                    max_lr=1e-3,\n",
    "                    steps_per_epoch=np.ceil(EPOCH/batch_size),\n",
    "                    epochs=3)\"\"\"\n",
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping('val_accuracy', patience=10),\n",
    "    #lr_finder,\n",
    "    #tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5'),\n",
    "    #tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "]\n",
    "\n",
    "tuner.search(x_train[:int(ratio*len(x_train))], y_train[:int(ratio*len(y_train))], epochs=EPOCH, callbacks = my_callbacks,validation_data=(x_test[:int(ratio*len(x_test))], y_test[:int(ratio*len(y_test))]))\n",
    "\n",
    "models = tuner.get_best_models() #(num_models=10)\n",
    "tuner.results_summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
